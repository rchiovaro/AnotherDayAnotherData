job_title,category,company_name,inferred_city,inferred_state,inferred_country,post_date,job_description,job_type,job_board,uniq_id
Data Scientist with Machine Learning Experience,life physical and social science, DISYS ,#N/A,#N/A,#N/A,2019-06-04,"  Hi, My name is Nikita and I am a Technical Recruiter with Digital Intelligence Systems LLC (DISYS). Which is based in more than 35 offices worldwide. Our direct client has couple of openings for Data Scientist Engineer with Machine Learning exp   Position : Data Scientist Engineer with Machine Learning exp Location : Richmond, Virginia Duration:: 6+ Months Contract Basic Qualifications: Bachelor's Degree or military experience At least 2 years experience using Python and/or Scala At least 5 years experience using SQL Regards Nikita Tyagi | |Bachelor's Degree or military experience|At least 2 years experience using Python and/or Scala|At least 5 years experience using SQL",Contract,careerbuilder,a9708235c0e0db529ec10eacc5b5c949
PHC Data Scientist,Engineering-or-architecture,Genentech,South san francisco,California,United states,2019-06-14,"Read what people are saying about working here. 
The Position

As a DATA SCIENTIST within our Personalized HealthCare function you will work with meaningful data to generate impactful evidence and insights on our molecules/ medicines and patients, that support R&D, advance scientific and medical knowledge, and enable personalized patient care and access. You will collaborate with peers within the function and across the organization to develop evidence generation strategies, identify evidence gaps and data sources, design and execute studies, and implement analyses to address molecule and disease area questions. The data will be varied in type -- patient-level clinical data, supplemented with deep patient data such as omics (e.g. genomics, proteomic), imaging, digital health, etc. Source data will be diverse -- real-world data, including patient registries, electronic medical records, claims, biobanks, and clinical trials. The evidence and insights will be used to inform the research and development of our molecules, and support healthcare decisions by patients, physicians, health authorities, payers, and policy-makers. You will also contribute to functional, crossfunctional, enterprise-wide or external initiatives that shape our business and healthcare environments. This will require a good understanding of molecule and disease area strategies, healthcare environments, as well as strong scientific and technical data science expertise. You will need strong strategic, collaboration and communication skills, as well as an entrepreneurial mindset, to transform the way we use data and analytics to develop and deliver medicines for our patients.

As Data Scientist you will typically be responsible for a molecule/indication and partner with cross-functional teams and external partners with considerable independence.

Responsibilities

IDENTIFY EVIDENCE NEEDS & RECOMMEND DATA SOLUTIONS: Ask the right scientific questions, understand the evidence needs for research and development, regulatory and market access, and ideate and make recommendations on fit-for-purpose data and analytics solutions.

DEVELOP DATA STRATEGY & GAIN ACCESS TO DATA: Develop strategic plans to access fit-for-purpose data sources to support evidence generation, and gain access to data through collaboration or data generation.

DIVE INTO DATA: Develop a comprehensive and deep understanding of the data we work with and foster learning with colleagues using analytical tools and applications to broaden data accessibility and advance our proficiency/efficiency in understanding and using the data appropriately.

BE AN EXPERT IN APPLYING METHODS: Stay current with and adopt emergent analytical methodologies, tools and applications to ensure fit-for-purpose and impactful approaches.

PRODUCE HIGH QUALITY ANALYSES: Apply rigor in study design and analytical methods; plan for data processing; design a fit-for-purpose analysis plan, assess effective ways of presenting and delivering the results to maximize impact and interpretability; implement and/or oversee the study, including its reporting; ensure compliance with applicable pharma industry regulations and standards.

INTERPRET AND SHARE RESULTS: Communicate findings to internal stakeholders, regulatory, health technology assessment (HTA) bodies and scientific communities; publish results; participate in external meetings and forums to present your insights (e.g. congress/conference).

COLLABORATE & SHAPE: Collaborate and contribute to functional, cross-functional, enterprise-wide or external data science communities, networks, collaboratives, initiatives or goals on knowledge-sharing, methodologies, innovations, technology, IT infrastructure, policy-shaping, processes, etc. to enable broader and more effective use of data and analytics to support business.

Minimum Qualifications

MSc, PhD or similar qualification in a quantitative data science discipline (e.g., statistics/ biostatistics, epidemiology, bioinformatics, health economics, computational biology, computer science, mathematics, outcomes research, public health, biology, medicine, psychology)

Demonstrated track record of developing and execution of data science research projects, patient-level data analyses (e.g., real world data, surveys, clinical trials, registries, claims, genomic or imaging data) with publications and presentations

Demonstrated experience with managing project scope and driving delivery in an evolving environment requiring proactivity and effective problem-solving and prioritization when faced with challenges

Demonstrated strong collaboration skills and excellent communication skills

Demonstrated entrepreneurial mindset and self-direction, ability to teach others and willingness to learn new techniques

Proficiency in English, both written and verbal

For Senior & Principal Data Scientist: Track record of effectively working in a matrix environment with global, international team members coming from scientific, business and operational backgrounds, using influence without authority

PREFERRED/ADDITIONAL QUALIFICATIONS

PhD degree in a quantitative or health sciences discipline as listed in Minimum Qualifications

Senior & Principal Data Scientist: 6+ years of relevant work experience

Proven ability to translate and communicate complex study design and findings to diverse audiences

#LI-PDBW1

Who We Are

A member of the Roche Group, Genentech has been at the forefront of the biotechnology industry

for more than 40 years, using human genetic information to develop novel medicines for serious and

life-threatening diseases. Genentech has multiple therapies on the market for cancer & other serious

illnesses. Please take this opportunity to learn about Genentech where we believe that our employees

are our most important asset & are dedicated to remaining a great place to work.

The next step is yours. To apply today, click on the ""Apply online"" button.

Genentech is an equal opportunity employer & prohibits unlawful discrimination based on race, color, religion, gender, sexual orientation, gender identity/expression, national origin/ancestry, age, disability, marital & veteran status. For more information about equal employment opportunity, visit our .
 The Position

As a DATA SCIENTIST within our Personalized HealthCare function you will work with meaningful data to generate impactful evidence and insights on our molecules/ medicines and patients, that support R&D, advance scientific and medical knowledge, and enable personalized patient care and access. You will collaborate with peers within the function and across the organization to develop evidence generation strategies, identify evidence gaps and data sources, design and execute studies, and implement analyses to address molecule and disease area questions. The data will be varied in type -- patient-level clinical data, supplemented with deep patient data such as omics (e.g. genomics, proteomic), imaging, digital health, etc. Source data will be diverse -- real-world data, including patient registries, electronic medical records, claims, biobanks, and clinical trials. The evidence and insights will be used to inform the research and development of our molecules, and support healthcare decisions by patients, physicians, health authorities, payers, and policy-makers. You will also contribute to functional, crossfunctional, enterprise-wide or external initiatives that shape our business and healthcare environments. This will require a good understanding of molecule and disease area strategies, healthcare environments, as well as strong scientific and technical data science expertise. You will need strong strategic, collaboration and communication skills, as well as an entrepreneurial mindset, to transform the way we use data and analytics to develop and deliver medicines for our patients.

As Data Scientist you will typically be responsible for a molecule/indication and partner with cross-functional teams and external partners with considerable independence.

Responsibilities

IDENTIFY EVIDENCE NEEDS & RECOMMEND DATA SOLUTIONS: Ask the right scientific questions, understand the evidence needs for research and development, regulatory and market access, and ideate and make recommendations on fit-for-purpose data and analytics solutions.

DEVELOP DATA STRATEGY & GAIN ACCESS TO DATA: Develop strategic plans to access fit-for-purpose data sources to support evidence generation, and gain access to data through collaboration or data generation.

DIVE INTO DATA: Develop a comprehensive and deep understanding of the data we work with and foster learning with colleagues using analytical tools and applications to broaden data accessibility and advance our proficiency/efficiency in understanding and using the data appropriately.

BE AN EXPERT IN APPLYING METHODS: Stay current with and adopt emergent analytical methodologies, tools and applications to ensure fit-for-purpose and impactful approaches.

PRODUCE HIGH QUALITY ANALYSES: Apply rigor in study design and analytical methods; plan for data processing; design a fit-for-purpose analysis plan, assess effective ways of presenting and delivering the results to maximize impact and interpretability; implement and/or oversee the study, including its reporting; ensure compliance with applicable pharma industry regulations and standards.

INTERPRET AND SHARE RESULTS: Communicate findings to internal stakeholders, regulatory, health technology assessment (HTA) bodies and scientific communities; publish results; participate in external meetings and forums to present your insights (e.g. congress/conference).

COLLABORATE & SHAPE: Collaborate and contribute to functional, cross-functional, enterprise-wide or external data science communities, networks, collaboratives, initiatives or goals on knowledge-sharing, methodologies, innovations, technology, IT infrastructure, policy-shaping, processes, etc. to enable broader and more effective use of data and analytics to support business.

Minimum Qualifications

MSc, PhD or similar qualification in a quantitative data science discipline (e.g., statistics/ biostatistics, epidemiology, bioinformatics, health economics, computational biology, computer science, mathematics, outcomes research, public health, biology, medicine, psychology)

Demonstrated track record of developing and execution of data science research projects, patient-level data analyses (e.g., real world data, surveys, clinical trials, registries, claims, genomic or imaging data) with publications and presentations

Demonstrated experience with managing project scope and driving delivery in an evolving environment requiring proactivity and effective problem-solving and prioritization when faced with challenges

Demonstrated strong collaboration skills and excellent communication skills

Demonstrated entrepreneurial mindset and self-direction, ability to teach others and willingness to learn new techniques

Proficiency in English, both written and verbal

For Senior & Principal Data Scientist: Track record of effectively working in a matrix environment with global, international team members coming from scientific, business and operational backgrounds, using influence without authority

PREFERRED/ADDITIONAL QUALIFICATIONS

PhD degree in a quantitative or health sciences discipline as listed in Minimum Qualifications

Senior & Principal Data Scientist: 6+ years of relevant work experience

Proven ability to translate and communicate complex study design and findings to diverse audiences

#LI-PDBW1

Who We Are

A member of the Roche Group, Genentech has been at the forefront of the biotechnology industry

for more than 40 years, using human genetic information to develop novel medicines for serious and

life-threatening diseases. Genentech has multiple therapies on the market for cancer & other serious

illnesses. Please take this opportunity to learn about Genentech where we believe that our employees

are our most important asset & are dedicated to remaining a great place to work.

The next step is yours. To apply today, click on the ""Apply online"" button.

Genentech is an equal opportunity employer & prohibits unlawful discrimination based on race, color, religion, gender, sexual orientation, gender identity/expression, national origin/ancestry, age, disability, marital & veteran status. For more information about equal employment opportunity, visit our . Genentech, now a member of the Roche Group, is a leading biotechnology company that discovers, develops, manufactures and commercializes ...",Undefined,indeed,4724ecc02b28a44e8f8ed82b6a8b1de8
Data Engineer AWS Product BI,Engineering-or-architecture,"Amazon.com Services, Inc.",Seattle,Washington,United states,2019-06-11,"Read what people are saying about working here. 

Basic Qualifications

Bachelor's Degree in Computer Science or a related technical field, and solid years of relevant experience.

A strong grasp of SQL and at least one scripting or programming language.

5+ years of experience with and detailed knowledge of data warehouse technical architectures, infrastructure components, ETL/ ELT and reporting/analytic tools and environments, data structures.

2+ years of large IT project delivery for BI oriented projects.

2+ years of working with very large data warehousing environment

Amazon is looking for an outstanding Data Engineer to join the AWS Product BI team. This is your opportunity to be a core part of the team that has direct impact on the day-to-day decision making in the many AWS Product teams like EC2, S3 and IoT.

Since early 2006, AWS has provided companies of all sizes with an infrastructure platform in the cloud. AWS is a high-growth, fast-moving division within Amazon with a start-up mentality where new and diverse challenges arise every day. On the AWS Product BI team you will be surrounded by people that are exceptionally talented, bright, and driven, and believe that world class BI is critical to our success. To help build this growing team, you must be highly analytical and possess a strong passion for analytics and accountability, set high standards with a focus on superior business success. We take working hard, having fun, and making history seriously. AWS sets the standard for functionality, cost, and performance for many cloud based services, but it’s still early days for cloud computing, and there are boundless opportunities to continue to redefine the world of cloud computing - come help us make history!

As a Data engineer on this team, you will get the exciting opportunity to work on very large data sets in one of the world's largest and most complex data warehouse environments. You will work closely with the business and technical teams in analysis on many non-standard and unique business problems and use creative-problem solving to deliver actionable output. Our team is serious about great design and redefining best practices with a cloud-based approach to scalability and automation. A successful candidate will be a self-starter, comfortable with ambiguity, with strong attention to detail, an ability to work in a fast-paced and ever-changing environment, and an ability to work effectively with cross-functional teams.

Key responsibilities include

Designing, developing, troubleshooting, evaluating, deploying, and documenting data management and business intelligence systems, enabling stakeholders to manage the business and make effective decisions.

Building secure, available, scalable, stable, and cost-effective data solutions using data storage technologies, distributed file system, data processing, and business intelligence best practices.

Working with business customers in understanding the business requirements and implementing solutions to support analytical and reporting needs.

Designing and planning for solutions in the various engineering subject areas as it relates to data storage and movement solutions: data warehousing, enterprise system data architecture, data design (e.g., Logical and Physical Modeling), data persistence technologies, data processing, data management, and data analysis.

Ensuring completeness and compatibility of the technical infrastructure to support system performance, availability and architecture requirements

Reviewing and participating in testing of the data design, tool design, data extracts/transforms, networks and hardware selections

Preferred Qualifications

Experience in designing and delivering cross functional custom reporting solutions.

- Experience with Massively Parallel Processing (MPP) databases - Redshift, Teradata, etc

Experience with distributed systems and NoSQL databases

Experience with Big Data technologies e.g. Hadoop, Hive, Oozie, Presto, Hue, Spark, Scala and more!

Excellent oral and written communication skills including the ability to communicate effectively with both technical and non-technical stakeholders.

Proven ability to meet tight deadlines, multi-task, and prioritize workload

A work ethic based on a strong desire to exceed expectations.

Strong analytical skills

 
Basic Qualifications

Bachelor's Degree in Computer Science or a related technical field, and solid years of relevant experience.

A strong grasp of SQL and at least one scripting or programming language.

5+ years of experience with and detailed knowledge of data warehouse technical architectures, infrastructure components, ETL/ ELT and reporting/analytic tools and environments, data structures.

2+ years of large IT project delivery for BI oriented projects.

2+ years of working with very large data warehousing environment

Amazon is looking for an outstanding Data Engineer to join the AWS Product BI team. This is your opportunity to be a core part of the team that has direct impact on the day-to-day decision making in the many AWS Product teams like EC2, S3 and IoT.

Since early 2006, AWS has provided companies of all sizes with an infrastructure platform in the cloud. AWS is a high-growth, fast-moving division within Amazon with a start-up mentality where new and diverse challenges arise every day. On the AWS Product BI team you will be surrounded by people that are exceptionally talented, bright, and driven, and believe that world class BI is critical to our success. To help build this growing team, you must be highly analytical and possess a strong passion for analytics and accountability, set high standards with a focus on superior business success. We take working hard, having fun, and making history seriously. AWS sets the standard for functionality, cost, and performance for many cloud based services, but it’s still early days for cloud computing, and there are boundless opportunities to continue to redefine the world of cloud computing - come help us make history!

As a Data engineer on this team, you will get the exciting opportunity to work on very large data sets in one of the world's largest and most complex data warehouse environments. You will work closely with the business and technical teams in analysis on many non-standard and unique business problems and use creative-problem solving to deliver actionable output. Our team is serious about great design and redefining best practices with a cloud-based approach to scalability and automation. A successful candidate will be a self-starter, comfortable with ambiguity, with strong attention to detail, an ability to work in a fast-paced and ever-changing environment, and an ability to work effectively with cross-functional teams.

Key responsibilities include

Designing, developing, troubleshooting, evaluating, deploying, and documenting data management and business intelligence systems, enabling stakeholders to manage the business and make effective decisions.

Building secure, available, scalable, stable, and cost-effective data solutions using data storage technologies, distributed file system, data processing, and business intelligence best practices.

Working with business customers in understanding the business requirements and implementing solutions to support analytical and reporting needs.

Designing and planning for solutions in the various engineering subject areas as it relates to data storage and movement solutions: data warehousing, enterprise system data architecture, data design (e.g., Logical and Physical Modeling), data persistence technologies, data processing, data management, and data analysis.

Ensuring completeness and compatibility of the technical infrastructure to support system performance, availability and architecture requirements

Reviewing and participating in testing of the data design, tool design, data extracts/transforms, networks and hardware selections

Preferred Qualifications

Experience in designing and delivering cross functional custom reporting solutions.

- Experience with Massively Parallel Processing (MPP) databases - Redshift, Teradata, etc

Experience with distributed systems and NoSQL databases

Experience with Big Data technologies e.g. Hadoop, Hive, Oozie, Presto, Hue, Spark, Scala and more!

Excellent oral and written communication skills including the ability to communicate effectively with both technical and non-technical stakeholders.

Proven ability to meet tight deadlines, multi-task, and prioritize workload

A work ethic based on a strong desire to exceed expectations.

Strong analytical skills

 Amazon is guided by four principles: customer obsession rather than competitor focus, passion for invention, commitment to operational ex...",Undefined,indeed,d2fb191de6f2d58ff9c087366d061e22
Data Engineer,Computer-or-internet,PNC Financial Services Group,Dallas,Texas,United states,2019-06-08,"Read what people are saying about working here. 

Position Overview

At PNC, our people are our greatest differentiator and competitive advantage in the markets we serve. We are all united in delivering the best experience for our customers.

As a Data Engineer (hadoop) within PNC's Technology and Innovation organization, can be based in Pittsburgh, PA; Cleveland or Columbus, OH; Dallas, TX; Overland Park, KS; Atlanta, GA; Boston, MA; Chicago, IL; or within any PNC footprint nationwide

The following skills are preferred:

Experience in Hadoop Architecture & Development – Cloudera preferred

Experience in Data Engineering – Spark, HIVE, Map Reduce, Sqoop, etc.

Proficiency in writing SQL on mainstream RDBMSs like Oracle, Teradata etc.

The following skills are a plus:

Hands on experience with large Data Warehousing (Hadoop) or Business Intelligence Implementations

Proficiency with ingestion tools, Sqoop and/or Informatica is preferred

Agile software development environment experience

Preferences/Skills:

Cloudera preferred - Hue, HIVE, Spark, Map Reduce, Sqoop, Impala, Kafka, Flume, Oozie etc.

Proficiency in writing SQL on mainstream RDBMSs like Oracle, Teradata, SQL Server etc.

Good communication skills

Job Profile

Develops, supports and implements data services for multiple applications to meet business objectives and user requirements. Uses technical knowledge and industry experience to design, build and maintain technology solutions.

Works closely with users, developers, operations and business partners to define data service requirements and the data preparation process development.

Designs and builds data service infrastructure on multiple data platforms, according to key business processes and the overall workflow.

Develops and implements data solutions for multiple applications to ensure its scalability, availability and maintainability.

Implements data migration and transformation activities/processes to ensure the accuracy and security of data solutions.

Core Competencies

Manages Risk - Working Experience

Assesses and effectively manages all of the risks associated with their business objectives and activities to ensure activities are in alignment with the bank's and unit's risk appetite and risk management framework.

Customer Focus - Extensive Experience

Knowledge of the values and practices that align customer needs and satisfaction as primary considerations in all business decisions, and ability to leverage that information in creating customized customer solutions.

Job Specific Competencies

Database Structures - Working Experience

Knowledge of and the ability to utilize appropriate database structures to organize and store data in a particular manner.

Problem Solving - Extensive Experience

Knowledge of approaches, tools, techniques for recognizing, anticipating, and resolving organizational, operational or process problems; ability to apply this knowledge appropriately to diverse situations.

Business Intelligence - Extensive Experience

Knowledge of and ability to utilize business processes and technologies for gathering, storing, analyzing, and providing access to data that helps the organization make better business decisions.

Software Development Life Cycle - Extensive Experience

Knowledge of and experience with using a structured methodology for delivering new or enhanced software products to the marketplace.

APPLICATION DELIVERY PROCESS - Working Experience

Knowledge of major tasks, deliverables, and formal application delivery methodologies; ability to utilize these in order to deliver new or enhanced applications.

Data Architecture - Basic Experience

Knowledge and ability to create models and standards to govern which data is collected, and how it is stored, arranged, integrated, and put to use in data systems and in organizations.

Effective Communications - Extensive Experience

Understanding of effective communication concepts, tools and techniques; ability to effectively transmit, receive, and accurately interpret ideas, information, and needs through the application of appropriate communication behaviors.

Data Analysis - Software - Working Experience

Knowledge of the investigation, evaluation, interpretation, and classification of data; the ability to identify, collect and analyze data to facilitate the development, implementation and application of software systems.

Big Data Management and Analytics - Extensive Experience

Knowledge and ability to plan and execute, big data management and analytics.

Required Education and Experience

Roles at this level typically require a university / college degree, with 3+ years of relevant / direct industry experience. Certifications are often desired. In lieu of a degree, a comparable combination of education and experience (including military service) may be considered.

EEO Statement

PNC provides equal employment opportunity to qualified persons regardless of race, color, sex, religion, national origin, age, sexual orientation, gender identity, disability, veteran status, or other categories protected by law

 

Position Overview

At PNC, our people are our greatest differentiator and competitive advantage in the markets we serve. We are all united in delivering the best experience for our customers.

As a Data Engineer (hadoop) within PNC's Technology and Innovation organization, can be based in Pittsburgh, PA; Cleveland or Columbus, OH; Dallas, TX; Overland Park, KS; Atlanta, GA; Boston, MA; Chicago, IL; or within any PNC footprint nationwide

The following skills are preferred:

Experience in Hadoop Architecture & Development – Cloudera preferred

Experience in Data Engineering – Spark, HIVE, Map Reduce, Sqoop, etc.

Proficiency in writing SQL on mainstream RDBMSs like Oracle, Teradata etc.

The following skills are a plus:

Hands on experience with large Data Warehousing (Hadoop) or Business Intelligence Implementations

Proficiency with ingestion tools, Sqoop and/or Informatica is preferred

Agile software development environment experience

Preferences/Skills:

Cloudera preferred - Hue, HIVE, Spark, Map Reduce, Sqoop, Impala, Kafka, Flume, Oozie etc.

Proficiency in writing SQL on mainstream RDBMSs like Oracle, Teradata, SQL Server etc.

Good communication skills

Job Profile

Develops, supports and implements data services for multiple applications to meet business objectives and user requirements. Uses technical knowledge and industry experience to design, build and maintain technology solutions.

Works closely with users, developers, operations and business partners to define data service requirements and the data preparation process development.

Designs and builds data service infrastructure on multiple data platforms, according to key business processes and the overall workflow.

Develops and implements data solutions for multiple applications to ensure its scalability, availability and maintainability.

Implements data migration and transformation activities/processes to ensure the accuracy and security of data solutions.

Core Competencies

Manages Risk - Working Experience

Assesses and effectively manages all of the risks associated with their business objectives and activities to ensure activities are in alignment with the bank's and unit's risk appetite and risk management framework.

Customer Focus - Extensive Experience

Knowledge of the values and practices that align customer needs and satisfaction as primary considerations in all business decisions, and ability to leverage that information in creating customized customer solutions.

Job Specific Competencies

Database Structures - Working Experience

Knowledge of and the ability to utilize appropriate database structures to organize and store data in a particular manner.

Problem Solving - Extensive Experience

Knowledge of approaches, tools, techniques for recognizing, anticipating, and resolving organizational, operational or process problems; ability to apply this knowledge appropriately to diverse situations.

Business Intelligence - Extensive Experience

Knowledge of and ability to utilize business processes and technologies for gathering, storing, analyzing, and providing access to data that helps the organization make better business decisions.

Software Development Life Cycle - Extensive Experience

Knowledge of and experience with using a structured methodology for delivering new or enhanced software products to the marketplace.

APPLICATION DELIVERY PROCESS - Working Experience

Knowledge of major tasks, deliverables, and formal application delivery methodologies; ability to utilize these in order to deliver new or enhanced applications.

Data Architecture - Basic Experience

Knowledge and ability to create models and standards to govern which data is collected, and how it is stored, arranged, integrated, and put to use in data systems and in organizations.

Effective Communications - Extensive Experience

Understanding of effective communication concepts, tools and techniques; ability to effectively transmit, receive, and accurately interpret ideas, information, and needs through the application of appropriate communication behaviors.

Data Analysis - Software - Working Experience

Knowledge of the investigation, evaluation, interpretation, and classification of data; the ability to identify, collect and analyze data to facilitate the development, implementation and application of software systems.

Big Data Management and Analytics - Extensive Experience

Knowledge and ability to plan and execute, big data management and analytics.

Required Education and Experience

Roles at this level typically require a university / college degree, with 3+ years of relevant / direct industry experience. Certifications are often desired. In lieu of a degree, a comparable combination of education and experience (including military service) may be considered.

EEO Statement

PNC provides equal employment opportunity to qualified persons regardless of race, color, sex, religion, national origin, age, sexual orientation, gender identity, disability, veteran status, or other categories protected by law
 For more than 160 years, we have been committed to supporting our customers, communities, employees and shareholders. At PNC, we are prou...",Undefined,indeed,3838d80564de325a8d1e4c18f09d626f
Data Scientist,Manufacturing-or-mechanical,Williamson-Dickie Mfg. Co.,Fort worth,Texas,United states,2019-06-11,"Summary:

The primary purpose of this position is to design and build statistical models and to use simulation tools to address business problems and support complex business decisions. Regular activities include data collection, pre-processing of data, analysis, and presentation of information using data visualization techniques and technology. This role will utilize machine learning based tools and artificial intelligence to automate certain supply chain processes. Over time, this work will build the next generation operations function.

Responsibilities:

Engage in the business to understand strategic direction, comprehend key challenges and opportunities, and lead hypothesis development of likely solution sets to test.

Research, design and develop statistical learning models for data analysis, to inform Supply Chain decisions with deep insights from models and analysis.

Collaborate cross-functionally throughout the Workwear organization to execute data analysis and projects.

Communicate results and ideas to key decision makers.

Present information using data visualization technology.

Keep up to date with the latest technology trends with machine learning, artificial intelligence, neural networks, natural language processing, etc. to further enhance supply chain operations.

Qualifications:

Bachelor’s degree from an accredited university in Computer Science, Statistics, Applied Mathematics or related field. Master's degree preferred.

5 years+ experience in data analytics, data mining and statistical analysis.

Excellent pattern recognition and predictive modeling skills.

Ability to program in languages such as Python, R, Java would be an asset.

An understanding of how to leverage open source tools to automate certain analytical processes.

An understanding of machine learning tools/processes to improve analytical efficiency.

Working knowledge of statistical programming such as Python or R, and a working knowledge of database querying languages like SQL.

Solid understanding of statistical tests, causal analysis, classification, distributions, confidence tests, regression, sampling, etc.

Familiarization with machine learning methods, algorithms, etc.

Familiarization with data visualization tools such as Tableau, Alteryx, GitHub, etc.

Effective communication skills (verbal and written). Able to make the technical understandable.

Basic understanding of the wholesale apparel supply chain business.

 

Summary:

The primary purpose of this position is to design and build statistical models and to use simulation tools to address business problems and support complex business decisions. Regular activities include data collection, pre-processing of data, analysis, and presentation of information using data visualization techniques and technology. This role will utilize machine learning based tools and artificial intelligence to automate certain supply chain processes. Over time, this work will build the next generation operations function.

Responsibilities:

Engage in the business to understand strategic direction, comprehend key challenges and opportunities, and lead hypothesis development of likely solution sets to test.

Research, design and develop statistical learning models for data analysis, to inform Supply Chain decisions with deep insights from models and analysis.

Collaborate cross-functionally throughout the Workwear organization to execute data analysis and projects.

Communicate results and ideas to key decision makers.

Present information using data visualization technology.

Keep up to date with the latest technology trends with machine learning, artificial intelligence, neural networks, natural language processing, etc. to further enhance supply chain operations.

Qualifications:

Bachelor’s degree from an accredited university in Computer Science, Statistics, Applied Mathematics or related field. Master's degree preferred.

5 years+ experience in data analytics, data mining and statistical analysis.

Excellent pattern recognition and predictive modeling skills.

Ability to program in languages such as Python, R, Java would be an asset.

An understanding of how to leverage open source tools to automate certain analytical processes.

An understanding of machine learning tools/processes to improve analytical efficiency.

Working knowledge of statistical programming such as Python or R, and a working knowledge of database querying languages like SQL.

Solid understanding of statistical tests, causal analysis, classification, distributions, confidence tests, regression, sampling, etc.

Familiarization with machine learning methods, algorithms, etc.

Familiarization with data visualization tools such as Tableau, Alteryx, GitHub, etc.

Effective communication skills (verbal and written). Able to make the technical understandable.

Basic understanding of the wholesale apparel supply chain business.",Undefined,indeed,87049b2600ed154cd84ca71cf5da2335
Big data Engineer,#N/A,NPV Staffing,Phoenix,Arizona,United states,2019-06-08,"Position: Big data Engineer Location: Phoenix ,AZ Duration: 8 -12 month contract with possible long term extension Interview Process: 1st round Skype - 2nd round web ex - 3rd round Zoom/Skype with Client (onsite if candidate is local) Visa: Any Visa will be accepted Required: 5-10 years of experience Java Big data (hive, hadoop, SQL, spark, mapreduce, etc.) Streaming experience. SQL. Thank You, Akhilesh Kumar 929-800-2316 NPV Staffing LLC | Williamsville, NY Email : Akhilesh.kumar@npvstaffing.com | www.npvstaffing.com",Contract,dice,181d19adcb0f73e60903aef46d6e02a4
Senior Data Scientist,science jobs,Harnham,London,#N/A,United kingdom,2019-06-09,"Senior Data Scientist 
 
London 
 
£55,000-£65,000 + 10% benefits + 15% bonus
 
Are you enthusiastic about exploring innovative machine learning techniques to create solutions? Are you proactive about trying new approaches and pioneering techniques in all areas across data science? As a Senior Data Scientist, you will get the opportunity  to play around with huge amounts of world data - from location to financial data - to pioneer machine learning solutions in Python and SQL.
 
THIS COMPANY:
 
This household name company builds strong partnerships with huge brands to gain data in all areas. Joining this completely Greenfield brand-new data science team within data and analytics, you will get the opportunity to play around with big data and champion  data-driven approaches in machine learning, including NLP, linear and logistic regression.
 
THE ROLE:
 
Working closely with all areas of the business - including CRM, marketing and insights and finance - you will be researching and developing cutting-edge machine learning solutions to complex business problems.

Researching into new concepts and implementing them across projects

Effectively delivering technical concepts to non-technical senior management and stakeholders

Mentoring and coaching responsibilities

YOUR SKILLS AND EXPERIENCE:
 
If you are a Senior Data Scientist already but looking for that career progression to take on more people management (mentoring and coaching) and project ownership responsibilities, then this is the role for you:

Extensive experience using Python and SQL to build and productionise machine learning models, preferably within an R&D focused team

The successful Senior Data Scientist will have commercial experience effectively delivering technical concepts to non-technical stakeholders and senior management

The ideal Senior Data Scientist will have experience mentoring and coaching junior data scientists

THE BENEFITS:

£55,000-£65,000

10% benefits

15% bonus

HOW TO APPLY:
 
Please register your interest by sending your CV to Kian Dixon via the Apply link on this page. For more information about similar roles, please get in touch!",Full Time,reed,97c03d14e1407bf8c66f42f54c7b3e2b
Data Scientist - Digital Bank,marketing jobs,Harnham,London,#N/A,United kingdom,2019-06-15,"Data Scientist - Digital Bank

London

£70,000 - £75,000
 
THE COMPANY
 
Harnham are currently working exclusively with a leading challenger bank who are looking to hire a Data Scientist to lead their efforts on data-driven marketing.
 
This is currently a blank slate for the business and there will be a huge opportunity for impact!
 
As a business they are growing rapidly and have one of the best data and software teams in Europe. They offer lots in the way of interesting work, varied projects, well-being and also learning and development.
 
They often feature in tech magazines for their great work and attitude, and have hired some impressive industry experts to help them on their mission of disrupting the retail banking market.
 
See below for more details on the role!

THE ROLE
 
As a Data Scientist in this team you will be involved in:

Leading data-driven marketing strategies (customer acquisition, CRM, online/offline marketing strategy, attribution)

Introducing new and innovative machine learning techniques to the business

Identifying new opportunities for the business with regards to marketing strategy

Collaboration - with a number of people across the business

End to end data science product work

The team will triple over the next 2 years and so there is an opportunity to build/lead a team if wanted!

SKILLS AND EXPERTISE
 
To be considered for this position you must have the following:

An MSc in a STEM topic (e.g. Statistics, Mathematics, Machine Learning, Computer Science etc.)

Hands-on programming experience with Python and SQL

Experience across several areas of marketing (e.g. customer acquisition/retention/CRM)

Digital marketing experience is a plus

Experience of working in a fast-paced and scaling business is beneficial, but not necessary

BENEFITS
 
As a Data Scientist, you could earn up to £75,000 + generous share options
 
HOW TO APPLY
 
To be considered for this opportunity, please submit your details using the Apply button on this page. For more information about similar Data Science positions please contact Nick Mandella at Harnham.
 
KEYWORDS
 
Python, SQL, Data science, data scientist, machine learning, fintech, start-up, tech, technology, digital bank, predictive analytics, marketing, customer, attribution, acquisition, retention.",Full Time,reed,73817b7ad0827a3efca3d66363a217c3
Senior Data Scientist/Analytic Consultant 5,business and financial operations,Wells Fargo,Minneapolis,Minnesota,United states,2019-06-09,"Job Description At Wells Fargo, we want to satisfy our customers’ financial needs and help them succeed financially. We’re looking for talented people who will put our customers at the center of everything we do. Join our diverse and inclusive team where you’ll feel valued and inspired to contribute your unique skills and experience. Help us build a better Wells Fargo. It all begins with outstanding talent. It all begins with you. Enterprise Finance drives financial management for the company and maintains and enhances risk and financial controls. Key functions within Enterprise Finance include finance and accounting; Treasury; corporate development, mergers, and acquisitions; Data Management and Insights, the Customer Remediation Center of Excellence, Enterprise Shared Services, Business Process Management, and Corporate Strategy. Enterprise Finance informs shareholders, regulators, taxing authorities, team members, and leaders of the company’s financial performance through earnings releases, investor meetings and conferences, and meetings with regulators and credit rating agencies, following appropriate reporting guidelines. They also maintain and enhance risk and financial controls and lead many of the company’s shared services functions including corporate properties, security, and global services. The Data Management and Insights organization (‘DMI’) is building a best in-class data science team, focused on delivering enterprise-wide data driven insights based in both traditional and emerging analytical techniques.  Our team supports the DMI service model by providing LOBs with machine learning and predictive analytic consulting and guidance. KEY RESPONSIBILITIES INCLUDE: • Lead machine learning projects, including working with business partners to define the scope and deliverable, developing the analytic plan and time line, leading deployment and delivering results • Provide technical advice to other members of the team and across the organization on topics including machine learning code, machine learning algorithms and traversing across multiple big data platforms • Identify and lead the evaluation of new software techniques and technologies, including delivery of results • Identify new applications for machine learning across the company and work with business partners to pilot Required Qualifications 3+ years of Python experience 3+ years of SQL experience 3 + years of experience using quantitative machine learning techniques 8+ years of experience in one or a combination of the following: reporting, analytics, or modeling; or a Masters degree or higher in a quantitative field such as applied math, statistics, engineering, physics, accounting, finance, economics, econometrics, computer sciences, or business/social and behavioral sciences with a quantitative emphasis and 5+ years of experience in one or a combination of the following: reporting, analytics, or modeling Desired Qualifications Experience with Tensorflow, Theano or Keras Excellent verbal, written, and interpersonal communication skills Extensive knowledge and understanding of research and analysis Strong analytical skills with high attention to detail and accuracy Other Desired Qualifications • Solid understanding  of and 5+  years  of experience applying machine learning techniques such as neural networks, random forest, GBM and SVM, to form a story • Experience with signal processing or optimization techniques • Advanced knowledge of statistical techniques (e.g. sampling, probability, multivariate data analysis, regression, PCA, time-series analysis) • Strong ability to retrieve, combine and transform data from numerous information systems • Strong acumen in diagnosing and resolving data issues • Experience working with big data infrastructure with tools such as Hive, Spark and h2o • Exceptional analytical, critical thinking, quantitative reasoning skills, and problem-solving skills.  Ability to relate complex analysis and insights to effective business strategy. • Oher advanced statistical tools such as SAS, R and Weka   Disclaimer All offers for employment with Wells Fargo are contingent upon the candidate having successfully completed a criminal background check. Wells Fargo will consider qualified candidates with criminal histories in a manner consistent with the requirements of applicable local, state and Federal law, including Section 19 of the Federal Deposit Insurance Act. Relevant military experience is considered for veterans and transitioning service men and women. Wells Fargo is an Affirmative Action and Equal Opportunity Employer, Minority/Female/Disabled/Veteran/Gender Identity/Sexual Orientation.",Full Time,careerbuilder,7b8a9a15c6f17fe7b496c1227cb060f1
Data Scientist (TS/SCI),military jobs,CyberCoders,Springfield,Virginia,United states,2019-06-15,"Based in Springfield, VA you will be working full-time at one of our Federal contractor clients acting as the domain knowledge expert, helping to build large scale systems using Python and various math and scientific libraries.  Currently, we are in need of multiple Scientist with TS/SCI clearance to join our team ASAP!     What You Will Be Doing   -Develops, modifies, applies, and maintains standards for software quality operating methods, processes, systems and procedures.
- Conducts software inspection, testing, verification and validation. 
-Implements software development and maintenance processes and methods. 
-Ensures measures meet acceptable reliability standards. 
-Develops overall operating criteria to ensure implementation of the software quality program according to project, process and contract requirements and objectives. 
-Ensures that project and process control.   What You Need for this Position   -Must have Domain Python expertise
- MUST HAVE Active TS/SCI clearance
- Experience with Documentation and implementation of algorithms for analyzing the performance wireless networks and extracting performance data from network hardware. 
-Experience with at least one of the following libraries such as numpy, scipy, and scikit-learn; 
-Experience with linear algebra and mathematical optimization and algorithm complexity. 
- MUST HAVE experitse in one intelligence or counter intelligence domain pertaining to- remote sensing, radar imagery, radio frequency, semantic change detection, etc!!!   What's In It for You   -Competitive base salary 
-Full medical benefits/dental/vision
-21 PTO days
-10 paid holidays
-401(k)    So, if you are a Data Scientist with TS/SCI, please apply today or send me your resume to Rachel.Hilton@CyberCoders.com!  

Security Clearance will be needed - therefore, only US citizens can be considered. 

Job Summary

                             
                     
                         Location 
                             Springfield, VA 22009 
                     
                 
                             
                     
                         Job type 
                         Full Time, Employee 
                     
                 
                 
                     
                         Posted 
                         2 Days ago 
                     
                 
                 
                     
                         Industries 
                         Government and Military 
                     
                 
                 
                     
                         Education level 
                         Professional 
                     
                 
                 
                     
                         Career level 
                         Entry Level 
                     
                 
                             
                     
                         Reference code 
                         RH1-1519004109",Full Time,monster,9d0b80bc554991d8cf3bdfa0a109fe45
Data Scientist,life physical and social science,Robert Half Technology,El segundo,California,United states,2019-06-09,"Ref ID: 00320-9501998232 Classification: Software Engineer Compensation: $125,000.00 to $135,000.00 per year ****FOR immediate consideration please email Valerie.nielsen@rht.com with a copy of your resume**** The Position: Data Scientist Target Salary: 140,000 Location: El Segundo, CA Please note: this is a direct hire (not contract) Data Scientist We are looking for a hands-on, Data Scientist to support our client rsquo;s product within the entertainment sector. Company is a very stable firm-based in El Segundo, CA. As the Data Scientist you will work closely with the team, testing and maintaining their environment. MUST have 4+ years of professional working experience.",Full Time,careerbuilder,1303df814b34601ca6bd073a6175d347
Data Engineer,Consulting,FinXL,North sydney,New south wales,Australia,2019-06-22,"North Sydney NSW

Contract

Location:

North Sydney

Job Type:

Contract

Specialisation:

Telecommunications

Reference:

(JL)43399

FinXL IT Professional Services is an established, innovative Australian company, providing technology enabled business solutions and consulting services across a number of industries. These include; Government, Telecommunications, Commercial and Finance. We currently have more than 1200 consultants assisting our clients across Australia and are continuing to grow at a rapid pace. Through the delivery of services and implementation of new systems, processes and technology, we assist our clients to gain competitive advantage and reach new heights.

The Role

Our client, a large North Sydney based telecommunication organisation, is looking for a Data Engineer .

Support the development and delivery of data science solutions across the Corporate Portfolio

Manipulate, process and extract value from large disconnected data sets

Build processes supporting data transformation, data structures, metadata, dependency and workload management

Identify and mitigate Data Quality Issues

Experience building/optimizing data pipelines, architectures and data sets using Spark or Hive

Who you are

You will have the following skills/experience

Strong project based data engineering capability

Strong programming skills (Python, Scala, Java or JavaScript)

Experience in Spark or Hive

Experience with Data Science tools such as R, H2O, Jupyter

Strong SQL expertise.

Experience with AWS cloud services

Experience with relational SQL and NoSQL databases

Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.

What’s on offer

This is a 6 months+ engagement with a high profile organisation with highly competitive remuneration on offer.

What’s next

If you would like to be considered, please send your application to Julia Leung on julial@finxl.com.au
 Location:

North Sydney

Job Type:

Contract

Specialisation:

Telecommunications

Reference:

(JL)43399

FinXL IT Professional Services is an established, innovative Australian company, providing technology enabled business solutions and consulting services across a number of industries. These include; Government, Telecommunications, Commercial and Finance. We currently have more than 1200 consultants assisting our clients across Australia and are continuing to grow at a rapid pace. Through the delivery of services and implementation of new systems, processes and technology, we assist our clients to gain competitive advantage and reach new heights.

The Role

Our client, a large North Sydney based telecommunication organisation, is looking for a Data Engineer .

Support the development and delivery of data science solutions across the Corporate Portfolio

Manipulate, process and extract value from large disconnected data sets

Build processes supporting data transformation, data structures, metadata, dependency and workload management

Identify and mitigate Data Quality Issues

Experience building/optimizing data pipelines, architectures and data sets using Spark or Hive

Who you are

You will have the following skills/experience

Strong project based data engineering capability

Strong programming skills (Python, Scala, Java or JavaScript)

Experience in Spark or Hive

Experience with Data Science tools such as R, H2O, Jupyter

Strong SQL expertise.

Experience with AWS cloud services

Experience with relational SQL and NoSQL databases

Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.

What’s on offer

This is a 6 months+ engagement with a high profile organisation with highly competitive remuneration on offer.

What’s next

If you would like to be considered, please send your application to Julia Leung on julial@finxl.com.au",Undefined,indeed,0d6a23de829e26e7cda654815c1c9554
Data Scientist,part time,"Queen Mary, University of London",London,#N/A,United kingdom,2019-06-05,"Data Scientist 
 
Ref:       QMUL18795 
Region:       London 
Main Site:       Charterhouse Square 
QMUL Faculty:       School Of Medicine &amp; Dentistry 
Org 1      :       Wolfson Institute of Preventive Medicine 
Org 2      :       Wolfson Institute of Preventive Medicine 
Org 3      :       Centre for Cancer Prevention 
Full Time / Part Time:       Full Time  
 Data Scientist 
   Applications are now invited for a Data Scientist with experience of data management and statistics.The primary focus of the data scientist is to carry out statistical analyses of large scale electronic health records from the HEAT, CAPP3 and other aspirin trials which will lead to substantive new findings relevant to understanding and improving of aspirin’s adverse effects.This is an important project to understand who is likely to benefit most from taking aspirin and who is at greater risk of bleeding side effects.      This post will be based in the Centre for Cancer Prevention, Wolfson Institute of Preventive Medicine, Charterhouse Squarewithin the Barts and The London School of Medicine and Dentistry, Queen Mary, University of London . We have recently received prestigious funding from a Cancer Research UK Catalyst award for the Aspirin for Cancer Prevention Project (AsCaP). This is an international, multi-disciplinary collaboration with 9 institutions in Harvard, Rome, Edinburgh, Heidelberg, Chieti, Newcastle and Londonto establish a partnership between population researchers and basic scientists to study the role of aspirin in cancer prevention and adjuvant treatment.  We are looking to add a data scientist to a high-performing group focusing on bioinformatics, basic science, statistics and epidemiology to support research to explain the mechanisms of aspirin in cancer prevention.     Applicants must be educated to PhD level and have experience of analysis techniques appropriate to large scale datasets. Applicants must have a high level of statistical and computational proficiency using appropriate statistical software packages to process data (e.g. R, Stata).  The post-holder will be expected to take an active role in the analysis and modelling of both publicly available (e.g. online or UK Biobank) and local NGS datasets (including large Aspirin clinical trials). Key techniques are likely to include development of statistical pipelines, building multivariate risk scores and assessing potential causal relationships. The post-holder will be expected to carry out analysis of study data in collaboration with the Centre’s statisticians and write up the results for publication.     The appointee must have excellent organisational, written and communication skills.They must have the ability to apply extensive working knowledge to address complex problems and challenges and have a comprehensive understanding and working knowledge of governance and legislation for the conduct of research (including GDPR).     The post is full time and fixed term for until 31 March 2023 and we are particularly seeking applicants who will forge a pathway to personal independence. Starting salary will be in the range £33,615 - £39,483 per annum inclusive of London Allowance. Benefits include 30 days annual leave and pension scheme.      Candidates must be able to demonstrate their eligibility to work in the UK in accordance with the Immigration, Asylum and Nationality Act 2006. Where required this may include entry clearance or continued leave to remain under the Points Based Immigration Scheme.   The Centre for Cancer Prevention requires applicants to provide all certificates at interview to confirm their qualifications (as specified in the Job Description).         Informal enquiries should be addressed to Dr Belinda Nedjai, Senior Research Fellow:          Details about the Institute can be found at      Application enquiries should be directed to          To apply, please visit the Human Resources website on  and search for QMUL18795         The closing date for applications is midnight on 14 July 2019.         Interviews: TBC July 2019         Valuing Diversity and Committed to Equality  

Please click on the link below for more information about this role:      

Job Summary

                             
                     
                         Location 
                             London 
                     
                 
                             
                     
                         Posted 
                         20 Days ago 
                     
                 
                             
                     
                         Reference code 
                         139631",Undefined,monster,3df42f8bdc21c8e1e8379a713ecf660b
Principal Data Scientist,computer jobs,Northrop Grumman,Melbourne,Florida,United states,2019-06-10,"At Northrop Grumman, our employeeshave incredible opportunities to work on revolutionary systems in air and spacethat impact people's lives around the world today, and for generations to come.Our work preserves freedom and democracy, and advances human discovery and ourunderstanding of the universe. We look for people who have bold new ideas,courage and a pioneering spirit to join forces to invent the future, and have alot of fun along the way. Our culture thrives on intellectual curiosity,cognitive diversity and bringing your whole self to work - and we have aninsatiable drive to do what others think is impossible. Our employees are notonly part of history, they're  making  history. 

 
Northrop Grumman Aerospace Systemshas an opening for a 
Principal Data Scientist  to join our team ofqualified, diverse individuals. This position will be in 
Melbourne, FL.  

 

 

Essential Functions:  

 
Data Scientist/Analyst - Flight Test Data Analyst to support Japan IPT. 

 
Flight Test Data Analyst (FTDA) is responsible for reduction, analysis,transmission, and reporting of flight test data for E-2 international flighttest program, specifically Japan E-2D Wet-Outer Wing Panel (WOWP) program.Candidate shall display professionalism, motivation, strong leadership skills,and ability to work independently. Should be able to function as a key dataanalyst expert of the flight test team and will interface directly with otherflight test engineers, aircrew, flight test leadership, and US Navy technicalarea experts.  

 

Responsibilities: 

 

 
*Data reduction, analysis, transmission, andreporting of all ground and flight test activities on the E-2 internationalprograms.  

 
*Position is located in Melbourne, FL but willprocess data coming from Melbourne FL and St. Augustine FL.  

 
*Attending flight briefs and debriefs.  

 
*Reducing aircraft-recorded and telemetry-recordeddata into usable engineering data for post-flight analysis.  

 
*Developing in-house data analysis tools, as well aslearning existing tools (MATLAB, IADS).  

 
*Analyzing flight test data for specificationcompliance and data validity. Generating flight test data releases.  

 
*Transmitting raw and processed data to the customer. 

 
*Supporting formal flight test data reviews and reportingrequirements.  

 
*Real-time telemetry support as directed by theFlight Test Lead(s).  

 


 


 


 
The selected candidate should thrive in a fast-paced work environmentwith high expectations, significantly diverse assignments, collaborative/teamsettings across all levels. 

 


 
MELENG 

 
SITEAS 

 


         
 

 

Basic Qualifications:   

  

 
*Bachelor'sDegree in a Science, Technology, Engineering or Mathematics (STEM) discipline from an accrediteduniversity and 5+ years relevant experience OR 
*Master'sDegree in a Science, Technology, Engineering or Mathematics (STEM) disciplinefrom an accredited university and 3+ years of relevant experience. 
*Must beable to obtain and maintain a DoD Secret security clearance. 
*Mustpossess a full understanding of all aspects of flight testing to includerequirements definition, instrumentation, data processing, test planning, testexecution and test reporting. 
*Candidateshould have previous experience on a flight test team with emphasis onreal-time telemetry operations. 


 

 

Preferred Qualifications:  

 
*Fixed-wingflight test experience is highly desirable. 
*Militaryaircraft flight test experience. 
*Familiarwith flight test operations. 
*Priorexperience and familiarity with E-2 aircraft and E-2 flight test is preferred. 
*Experiencewith IADS and MATLAB. 
*FlightTest Engineer / Test Conductor Experience. 
*Althoughtravel is not required for this position, candidate may have the opportunity totravel to St. Augustine occasionally (less than 5% of time) to support on-siteflight test for E-2D programs.


 

         
Northrop Grumman is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. For our complete EEO/AA and Pay Transparency statement, please visit  www.northropgrumman.com/EEO . U.S. Citizenship is required for most positions. 

Job Summary

                             
                     
                         Location 
                             Melbourne, FL 32910 
                     
                 
                             
                     
                         Posted 
                         16 Days ago 
                     
                 
                             
                     
                         Reference code 
                         19014159",Undefined,monster,a15dcd660770ca80d83463e655a58b77
Sr. Data Engineer + DataFlow + (Java Development),entertainment jobs,Quantiphi Inc.,Sunnyvale,California,United states,2019-06-17,"Role  Data Engineer + DataFlow + (Java Development)   Work location Silicon Valley, CA   Employment Mode Full Time Permanent   Experience 3-8 Years   Responsibilities    Extract, transform, and load logic to automate data collection and manage data processespipelines including data quality and monitoring   Contribute to the development of data frameworks on cloud   Write and review technical documents, including requirements and design documents for existing and future data systems, as well as data standards and policies   Architect data pipelines   Collaborate with analysts, supportsystem engineers, and business stakeholders to ensure our data infrastructure meets constantly evolving requirements     Requirement    BABS degree in Computer Science, Mathematics or a related technical field, or equivalent practical experience   Preferred Google Certified Data Engineer   Hands on experience on Dataflow, BigQuery, Cloud SQL, BigTable, Datastore, Dataproc, Cloud Composer is a must  Experience with data processing software (such as Hive) and experience with data processing algorithms (MapReduce) is a plus  Experience in migrating on-premise databases (Teradata and Netezza) to cloud platform(GCP).  Experience in designing, developing, and implementing data pipelines and applications to stream and process datasets on cloud.  Experience in helping vacate a data center to move the applications to GCP  Experience in writing software in one or more languages such as Java, Python  Experience in working with data warehouses, including data warehouse technical architectures, infrastructure components, ETLELT and reportinganalytic tools and environments.   Experience in managing internal or client-facing projects to completion experience troubleshooting clients' technical issues experience working with engineering teams, sales, services, and customers  Experience in technical consulting   Experience with architecting, developing software, or internet scale production-grade Data solutions on Cloud   Experience in working with big data, information retrieval, data mining or machine learning as well as experience in building multi-tier high availability applications with modern web technologies (such as NoSQL, MongoDB, SparkML, Tensorflow)

Job Summary

                             
                     
                         Location 
                             Sunnyvale, CA 94085 
                     
                 
                             
                     
                         Posted 
                         9 Days ago 
                     
                 
                             
                     
                         Reference code 
                         6874_47da2d52d1d761d0e5f84d2bc1f0db30",Undefined,monster,817760b823f5eef02014b79d4df57b53
Data Scientist Research Analyst,Accounting-or-finance,TUFTS University,Medford,Massachusetts,United states,2019-07-03,"Data Scientist Research Analyst - Tisch College - (19001552)

Description

This is a part-time, benefits eligible position working 17.5 hours per week.

The Jonathan M. Tisch College of Civic Life prepares Tufts University students to become active citizens and community leaders. The only university-wide college of its kind, Tisch engages Tufts students in meaningful community building, public service experiences, and transformational learning. It also conducts and supports groundbreaking research on civic and political participation and forges innovative community partnerships.

MGGG (The Metric Geometry & Gerrymandering Group) is a working group that studies applications of geometry and computing to U.S. redistricting. MGGG pursues cutting-edge research on the redistricting problem and builds publicly accessible tools and resources to help citizens and community groups better understand districts and their consequences. Founded in 2016-17, MGGG partners with civil rights organizations to strengthen the quantitative toollkit for protecting voting rights in the U.S.

This MGGG staff position will be fully integrated in Tisch College of Civic Life, which offers a number of opportunities to develop skills in and outside of research. The Geography Research Analyst conducts research and supports a range of projects and activities. Reporting to the MGGG Director, based on the Medford/Somerville Tufts University Campus, the Research Analyst will work as part of the MGGG team on research products and activities. The Research Analyst will also interact with a larger group of colleagues at Tisch College, and will be invited to participate in various college-wide initiatives such as college-wide events and mentorship programs.

Main duties will include:

Building and maintaining open-source tools for redistricting research, including geospatial data processing and auditing packages;

Contributing to the development of Districtr, our open-source web app for drawing districts and identifying communities;

Solving data science problems that come up in our consulting and research projects, with a focus on creating dependable, systematic approaches that can be reused in the future.

Qualifications

Basic Requirements:

1-2 years of experience.

Bachelor’s degree or demonstrated competencies in relevant skills.

Proficiency using a statistical software package such as: SPSS, SAS, or STATA, and Microsoft Office Suite.

Keen attention to details and ability to manage multiple project deliverables and timelines.

Passion for using research to achieve equity in civic learning opportunities through systemic changes.

Demonstrated ability to manage complex projects.

Effective verbal, written and interpersonal skills.

Demonstrated ability to work on several projects simultaneously and meet demanding timelines.

Compose accurate and clearly written reports and documents.

Work independently within basic guidelines and parameters.

Gather and analyze available data and draw logical conclusions.

Establish and maintain effective collaborative working team relationships.

Engage in proactive problem solving and critical thinking/analysis.

Engage with diverse stakeholders of varied educational and professional backgrounds.

Preferred Qualifications:

Expertise with data visualization software and/or website management.

Direct experience with community engagement through community organizing, national service, etc.

Direct experience with young people in diverse communities.

3 years of related experience.

Knowledge of logic models, research design, statistical analysis (multivariate statistics), and qualitative and quantitative research methods.

Experience with graphic software, and in developing and maintaining data management systems.

Special Work Schedule Requirements:

Part-time, 17.5 hours per week.

An employee in this position must complete all appropriate background checks at the time of hire, promotion, or transfer.

Equal Opportunity Employer – minority/females/veterans/disability/sexual orientation/gender identity.

Primary Location: United States-Massachusetts-Medford/Somerville

Job: Research

Organization: Tisch College

Employee Status: Regular

Schedule: Part-time

Job Posting: Jul 2, 2019, 8:26:26 AM",Undefined,indeed,65a05db311588e9215025bae59cc16e1
Big Data Engineer,Scientific,Fractal Analytics,Mumbai,Maharashtra,India,2019-07-02,"RESPONSIBILITIES

Our Big Data capability team needs hands-on developers who can produce beautiful & functional code to solve complex analytics problems. If you are an exceptional developer with an aptitude to learn and implement using new technologies, and who loves to push the boundaries to solve complex business problems innovatively, then we would like to talk with you.

You would be responsible for evaluating, developing, maintaining and testing big data solutions for advanced analytics projects

The role would involve big data pre-processing & reporting workflows including collecting, parsing, managing, analyzing and visualizing large sets of data to turn information into business insights

The role would also involve testing various machine learning models on Big Data, and deploying learned models for ongoing scoring and prediction. An appreciation of the mechanics of complex machine learning algorithms would be a strong advantage.

QUALIFICATIONS & EXPERIENCE

2 to 4 years of demonstrable experience designing technological solutions to complex data problems, developing & testing modular, reusable, efficient and scalable code to implement those solutions.

Ideally, this would include work on the following technologies:

Expert-level proficiency in at-least one of Java, C++ or Python (preferred). Scala knowledge a strong advantage.

Strong understanding and experience in distributed computing frameworks, particularly Apache Hadoop (YARN, MR, HDFS) and associated technologies - one or more of Hive, Sqoop, Avro, Flume, Oozie, Zookeeper, etc..

Hands-on experience with Apache Spark and its components (Streaming, SQL, MLLib) is a strong advantage.

Operating knowledge of cloud computing platforms (AWS/Azure ML)

Experience working within a Linux computing environment, and use of command line tools including knowledge of shell/Python scripting for automating common tasks

Ability to work in a team in an agile setting, familiarity with JIRA and clear understanding of how Git works

In addition, the ideal candidate would have great problem-solving skills, and the ability & confidence to hack their way out of tight corners.

Experience:

Must Have (hands-on) experience:

Scala or Python expertise

Linux environment and shell scripting

Distributed computing frameworks (Hadoop or Spark)

Cloud computing platforms (AWS/Azure ML).

Desirable (would be a plus):

Statistical or machine learning DSL like R

Distributed and low latency (streaming) application architecture

Row store distributed DBMSs such as Cassandra

Familiarity with API design

EDUCATION: B.E/B.Tech in Computer Science or related technical degree",Undefined,indeed,90ded705dcd5e7a8b9c5c0233fb6eca2
DSIT - Technical Analyst - Data Engineer,IT,Shell,#N/A,Karnataka,India,2019-07-01,"Job Description

The position of the Jr Data Engineer is established within the Down Stream Retail IT – MCC Competency Center’s Loyalty & Campaign team. We are looking for a strong candidate who can:

Work together with the Solution- and Data Architect to design the next generation big data platform to support the digital marketing platform.

Design and implement a new big data solution which supports high amounts- and velocity of data, supports future growth, use latest big data technologies/techniques, is cloud supported and in-line with Shell’s strategies.

Design and implement modern data pipelines to extract, clean and process data in batch and real-time from different data sources.

Use the latest development, testing and deployment techniques to quickly deploy new releases to e.g. deploy new data pipelines and add data sources.

Help establish best practices around data governance, data security- and privacy (GDPR).

Work together with the solution- and data architect to the define the target data strategy.

Drives and applies Agile Framework within his/her operating environment. Will take direct reports, when applicable, through Agile Framework and its respective tools.

Dimensions:

Stakeholder management – typically works within cross-functional teams.

Strong collaboration skills to ensure teams are all working towards the same goals.

Highly customer focused and fast paced environment.

Passion to lead others directly and indirectly into the new Data Engineering career development

Cross disciplinary interaction with other Disciplines in Shell outside Retail IT, for instance, Data Science CoE, control and automation, instrumentation others.

Requirements

Skills & Requirements: (5-8 Years of experience)

Bachelor or master degree in information technology, computer science, data management business administration or a related discipline.

Relevant Experience 2+ years’ experience with big data platforms; working with large data sets, large amounts of data in motion and numerous big data technologies.

Experience in operating in Agile framework and usage of its tools i.e. Awareness of Agile Framework and its tools such as Visual Studio Team Services (VSTS)

Experience with Cloud (AWS, Microsoft Azure).

Awareness of Agile Framework and its tools such as Visual Studio Team Services (VSTS)

Data pipelining-based technologies (e.g. KAFKA, StreamSets, Flume Talend, ADFv2).

Core Experiences:

Highly analytical, troubleshooting and problem-solving skills.

Experience with data Architecture and design techniques (local/abstract).

Experience with API techniques/developments.

Experience with data transformation/blending technology (e.g. Alteryx is preferred).

Nice to have:

Preferable experience with data science scenarios and machine learning frameworks (Caffe, Theano, Tensorflow, MXnet, CNTK)

Knowledge in Machine Vision will be advantageous.

Auto software deployment technologies (e.g. Jenkins, Docker, Git)

Hadoop/Spark-based technologies (e.g. Spark, MapReduce, Hive and Pig).

NoSQL-based technologies (e.g. Cassandra, HBASE, MongoDB).

Company Description

Shell began operations in India more than 80 years ago. At Shell India, we invest in our people through our industry-leading development programmes, which see our employees, thrive and gain access to experts on a local and global level. To date, we have invested more than US$ 1 billion already in India’s energy sector alone, in socially and environmentally responsible ways. Shell is the only global major to have a fuel retail license in India.

Shell has established a new IT hub in Bangalore, and plans to scale it up over a five year period. The purpose of the IT Hub is to enable the Business by focusing on business outcomes, delivering fit for business technology solutions which enable business agility and profitable growth.

Disclaimer

Please note: We occasionally amend or withdraw Shell jobs and reserve the right to do so at any time, including prior to the advertised closing date.

Before applying, you are advised to read our data protection policy. This policy describes the processing that may be associated with your personal data and informs you that your personal data may be transferred to Royal Dutch/Shell Group companies around the world.

The Shell Group and its approved recruitment consultants will never ask you for a fee to process or consider your application for a career with Shell. Anyone who demands such a fee is not an authorised Shell representative and you are strongly advised to refuse any such demand.

Shell is an Equal Opportunity Employer.

Work Location

Bangalore RMZ-ECO WORLD

SBO Location

Bangalore

No. of Positions

1",Undefined,indeed,fa4052870ddd9a1c774b14edda605446
Data Engineer,Computer,SSE,#N/A,#N/A,United kingdom,2019-07-05,"We have an exciting opportunity for a Data Engineer to join our growing team based in Reading.

Job Title: Data Engineer

Location: Reading

Salary: SSE08 £39,413 – £52,055 depending on skills and experience

Permanent | Full Time Hours with flexible working patterns available | 37 hours per week

The Role

The main purpose of this role is to produce reports for key stakeholders in Asset Operation and facilitate data extraction, transfer and logging. Creating and maintaining purposefully made web/windows applications, you’ll work with Data Scientists to leverage the advantages offered by data analysis, mining and analytics.

You’ll combine insightful analysis results and algorithm development to make a pivotal difference in driving our Smart Metering business to the next level for customers and key stakeholders.

Skills required for this role

Strong knowledge and proven ability of using SQL

Experience in data warehousing and database

Experience in data analytics platforms such as Azure and Amazon Web Service

Capability of creating apps using Net language e.g. VB, C# or Java.

Experience required for this role

Good knowledge of data modelling, statistical modelling.

Experience with data mining along with using Tableau

For this role you should have a BSc, MSc degree (or equivalent), in engineering, computer science, mathematics, economics or operations research.

Personally, you’ll be highly inquisitive with the ability to facilitate problem solving sessions and study relationships between data. With high attention to detail, you’ll be creative and attempt new problem-solving approaches and potential solutions. Confident in setting realistic personal goals and taking responsibility, you’ll deal with complex requirements from stakeholders. You’ll have highly effective interpersonal, verbal and written communication skills.

Our Company

Our Retail business is a market leader in supply of electricity and gas and in other energy-related services such as telecoms, broadband and boiler cover. We supply energy under our brands: SSE, SSE Scottish Hydro, SSE Southern Electric and SSE SWALEC in the Great Britain market. At SSE, we're committed to giving you excellent customer service and treating you fairly; we want to make life easier for you, find ways of saving you money, and be on hand to help when you need us the most, that’s our customer promise.

Our Benefits

We have an excellent benefits package as part of our offering. Here’s a few highlights;

Generous holiday allowance (you can even buy additional holidays)

Great share plans

Group Pension Plan

One day paid volunteering

Tailored internal development opportunities

Next Steps

Just click the Apply button to submit your application, it doesn’t take long.

Closing date for applications is: 5th July 2019

This vacancy is open to internal and external candidates, if you’re internal please notify your line manager before you submit your application.

For more information about this role, or to discuss any adjustments you require to submit your application please get in touch via sse.resourcing.team@sse.com",Undefined,indeed,71d39174491df83f8288913cb22c0583
Hadoop/Big data Engineer,animal care jobs,Capgemini,Algonquin,Illinois,United states,2019-06-16,"About Capgemini 
With more than 211,300 people in over 40 countries, Capgemini is one of the world's foremost providers of consulting, technology and outsourcing services. The Group reported 2018 global revenues of EUR 13. 2 billion. Together with its clients, Capgemini creates and delivers business, technology and digital solutions that fit their needs, enabling them to achieve innovation and competitiveness. A deeply multicultural organization, Capgemini has developed its own way of working, the Collaborative Business Experience , and draws on Rightshore , its worldwide delivery model.
Rightshore   is a trademark belonging to Capgemini  Job Description
Role: Data Engineer
Location: Chicago, IL
Position: Full time 
Participate in the agile development process 
Participate code review process Work with team members to achieve business results in a fast paced and quickly changing environment 
Pair up with experienced data engineers to develop cutting edge Analytic applications leveraging Big Data technologies Hadoop NoSQL and In memory Data Grids Perform other duties and or projects as assigned 
Qualifications Requirements - Bachelor s degree in a quantitative field such as Engineering Computer Science Statistics Econometrics
Minimum of 2 years of experience 
Hands on experience on writing shell scripts complex sql queries Hadoop commands and Git Ability to write abstracted reusable code components 
Programming experience in at least one of the following languages Scala Java or Python Desired Characteristics Analytical mindset Performance tuning experience 
Experience in developing Hive Sqoop Spark HBase on Hadoop 
Familiar with Ab Intio Hortonworks Zookeeper Oozie and Kafka is a plus Willingness to learn new technologies quickly Superior oral and written communication skills as well as the willingness to collaborate across teams of internal and external technical staff business analysts software support and operations staff Strong business acumen including a broad understanding of Synchrony Financial business processes and practices 
Demonstrated ability to work effectively in a team environment Disclaimer
Role: Data Engineer
Location: Chicago, IL
Position: Full time 
Participate in the agile development process 
Participate code review process Work with team members to achieve business results in a fast paced and quickly changing environment 
Pair up with experienced data engineers to develop cutting edge Analytic applications leveraging Big Data technologies Hadoop NoSQL and In memory Data Grids Perform other duties and or projects as assigned 
Qualifications Requirements - Bachelor s degree in a quantitative field such as Engineering Computer Science Statistics Econometrics
Minimum of 2 years of experience 
Hands on experience on writing shell scripts complex sql queries Hadoop commands and Git Ability to write abstracted reusable code components 
Programming experience in at least one of the following languages Scala Java or Python Desired Characteristics Analytical mindset Performance tuning experience 
Experience in developing Hive Sqoop Spark HBase on Hadoop 
Familiar with Ab Intio Hortonworks Zookeeper Oozie and Kafka is a plus Willingness to learn new technologies quickly Superior oral and written communication skills as well as the willingness to collaborate across teams of internal and external technical staff business analysts software support and operations staff Strong business acumen including a broad understanding of Synchrony Financial business processes and practices 
Demonstrated ability to work effectively in a team environment 

Job Summary

                             
                     
                         Location 
                             Algonquin, IL 60102 
                     
                 
                             
                     
                         Posted 
                         4 Days ago 
                     
                 
                             
                     
                         Reference code 
                         2365_2a4758345ab658f6baddd693adf712d7",Undefined,monster,c4b02bdc7fcf64ae5647f16242d55e62
Data Engineer - SQL / Big Data / Cloud,Architecture,Denodo Technologies,Singapore,#N/A,Singapore,2019-07-06,"Job Description

Your Opportunity

Denodo is always looking for technical, passionate people to join our Services Engineering team. We want a professional who will travel, consult, develop, train and troubleshoot to enhance our clients’ journey around Data Virtualization.

Your mission: to help people realize their full potential through accelerated adoption and productive use of Denodo solutions.

In this role you will successfully employ a combination of high technical expertise and client management skills to conduct on-site and off-site consulting, product implementation and solutions development in either short or long-term engagements being critical point of contact for getting things done among Denodo, partners and client teams.

Duties & Responsibilities

Obtain and maintain strong knowledge of the Denodo Platform, be able to deliver a superb technical pitch, including overview of our key and advanced features and benefits, services offerings, differentiation, and competitive positioning.

Constantly learn new things and maintain an overview of modern technologies.

Be able to address a majority of technical questions concerning customization, integration, enterprise architecture and general feature / functionality of our product.

Capable of building and/or leading the development of custom deployments based and beyond client’s requirements.

Provide timely, prioritized and complete customer-based feedback to Product Management, Sales, Support and/or Development regarding client’s business cases, requirements and issues.

Train and engage clients in the product architecture, configuration, and use of the Denodo Platform.

Promote knowledge and best practices while managing deliverables and client expectations.

Manage client expectations, establish credibility at all levels within the client and build problem-solving partnerships with the client, partners and colleagues.

Provide technical consulting, training and support.

Develop white papers, presentations, training materials or documentation on related topics.

Qualifications

Required Skills

BS or higher degree in Computer Science.

Solid understanding of SQL and good grasp of relational and analytical database management theory and practice.

Knowledge in Java software development, especially in the database field.

Good knowledge of JDBC, XML and Web Services APIs.

Excellent verbal and written communication skills to be able to interact with technical and business counterparts.

Active listener.

Strong analytical and problem solving abilities.

Lots of curiosity. You never stop learning new things.

Creativity. We love to be surprised with innovative solutions.

Willingness to travel around 50%.

Be a team worker with positive attitude.

We Value

Experience working with Java frameworks.

Experience working with GIT or other version control systems.

Experience working with BigData and/or noSQL environments like Hadoop, mongoDB, ...

Experience working with caching approaches and technologies such as JCS.

Experience in Windows & Linux (and UNIX) operating systems in server environments.

Business software implementation and integration projects (e.g. ETL/Data Warehouse architectures, CEP, BPM).

Integration with packaged applications (e.g. relational databases, SAP, Siebel, Oracle Financials, Business Intelligence tools, …).

Industry experience in supporting mission critical software components.

Experience in attending customer meetings and writing technical documentation.

Foreign language skills are a plus.

Additional Information

Employment Practices

We are committed to equal employment opportunity.

We respect, value and welcome diversity in our workforce.

We do not accept resumes from headhunters or suppliers that have not signed a formal fee agreement. Therefore, any resume received from an unapproved supplier will be considered unsolicited, and we will not be obligated to pay a referral fee.",Undefined,indeed,561ff6232751308d18378587aced6023
Data Scientist,Computer-or-internet,Celonis,New york,New york,United states,2019-07-07,"Are you ready for a new challenge?

Celonis is the leader in business transformation software, turning process insights into action with The Celonis Intelligent Business Cloud, built on the process mining technology it pioneered. For Global 2000 companies, transforming to an intelligent enterprise has become a key strategic priority. Celonis disrupted what had previously been a manual, time-consuming and expensive consulting-driven approach to jump-start and operationalize change in transformation initiatives. Companies around the world including Siemens, L’Oreal, Uber, 3M, and BMW rely on Celonis technology to guide action and drive change to business processes, resulting in millions of dollars saved and an improved experience for their customers. Headquartered in Munich, Germany and New York, New York, Celonis has grown 5,000% in 4 years and 300% in the past year. Valuated at over $1Billion, Celonis received $27.6M Series A in June 2016 and $50M Series B funding in June 2018 from investors Accel and 83 North. Since opening its US headquarters in New York in September 2016 it has quickly added blue chip customers like Lockheed Martin, ExxonMobil, Honeywell, and Mars to its client roster. The US is the fastest growing region for Celonis and will soon exceed 50% of its total revenue. In addition to its offices in the UK, Netherlands, and Japan, Celonis is expanding US offices in New York, San Francisco, Raleigh, Ann Arbor, as well as Latin America.

RESPONSIBILITIES...

You will actively drive Celonis’ expansion and work in project teams to kick-start our customers’ process mining journey. You will make digital business processes transparent and harmonize our customers’ gigantic data flows by using our Celonis Process Mining Technology and by applying the most up-to-date extraction and transformation methods. You are involved in implementation projects with process data of varying degrees and complexity and for customers across industries.

After the successful evaluation and preparation of the process data, you connect the respective on-premise/ Cloud systems with our software. You extract and transform customers’ data and design process- and customer-specific analyses.

Over the course of our projects, you expertly handle our customers’ individual needs and actively participate in customer workshops.

REQUIREMENTS...

BA/BS (or MA/MS) in Computer Science/ Mathematics/ Physics or other related field

Relevant work experience in consulting or IT products with need of explanation

(2+ years) in the area of enterprise software sales, pre-sales, consulting or business development

You’ve got excellent analytical skills, you are always well structured and are known for being a quick learner

You have fun evaluating complex data, as well as supporting customers

You are excited about Big Data, Data Mining and Process Mining",Undefined,indeed,d777feeb7c32621538aa6be9905ec565
DATA SCIENTIST,Finance,Made.com,#N/A,#N/A,United kingdom,2019-06-30,"Job Title: Data Scientist

Department/Group: Analytics

Line Manager: Head of Analytics

Location: London - Old Street

Contract Type: Permanent

Travel Required: No

Who we are

At MADE.COM we believe that everyone should have access to great design. So, weve taken a unique approach to making and selling furniture - no middlemen, no agents or importers and no high street stores. Instead we work directly with designers and manufacturers so we can offer high-end furniture at attractive prices.

Its not an easy task it takes a creative and dedicated team to make it happen where everyone has an important part to play. We combine our individual passions and skills to create innovative work thats as exciting and unconventional as the business itself. Its a place where all ideas are listened to, where brainstorming means job titles get left at the door and where a self-starter can really make their mark.

What youll be doing

Work in an agile team. You will be working in a small agile team of analysts in a fast paced demanding environment. The team is passionate about delivering high quality data solutions to drive

changes in the business.

Perform statistical modeling. You will be responsible for advanced statistical modeling in the area of forecasting. You will develop predictive models to forecast future demand and other KPIs which will improve planning capacity of the business. You will develop data driven analytical tools to make the results of your models available to the users. You will be driving considerations around further data discovery and innovative ways to improve the models through new methods and data points.

Communicate insights. You will present your findings to users and senior management to drive the decision making.

Promote best practices. Youll will be responsible for promoting data science best practices,

including high quality code, reproducible research and clear communications.

What youll need

MS or PhD in a quantitative field, or equivalent industry experience.

2+ years hands-on experience implementing data analytic solutions using SAS/SQL/R or Python

(advanced skills in programming preferred).

Fluency with advanced statistical and machine learning techniques: time series forecasting,

product recommendations, classification problems.

Ability to initiate and drive analytic projects from inception to delivery, and productionize and

automate the process with excellent programming skills.

Source control experience.

TO STAND OUT:

Knowledge in cloud and engineering platform solutions such as AWS.

Experience in retail, marketing, ecommerce, or digital advertising.

Continuous integration and test automation experience.

Google Analytics Premium and Google BigQuery.

What we offer

A fast-paced, creative and fun office environment

Great opportunities to make the role your own and get involved with exciting projects

A supportive, diverse company with a brilliant culture

Hot and cold drinks and free breakfast provided in the office (including fruit for the healthy people)

Regular work drinks along with many social and company events

Excellent employee benefits including private healthcare (with discounted gym membership), pension, life insurance, 25 days holiday a year (with an extra day every year served up to a cap of 30 days) and season ticket loan

Temptingly good employee discounts on MADE.com and regular staff sample sales

Up your street? Apply for the opportunity to join our growing team in the heart of Shoreditch!",Undefined,indeed,6430a78fc26672dbec801cf435a3ce67
Product Data Engineer till Xylem,IT,Level Recruitment,#N/A,#N/A,Sweden,2019-07-07,"Product Data Engineer till Xylem

Vill du vara det stödjande navet i framtagningen och utvecklingen av nya såväl som befintliga produkter i ett världsledande företag inom vattenteknik? Vill du bli en fena på produktprestanda och lära dig mer om Xylems produktsortiment av pumpar och omrörare? Kan du i dag lite om mycket, har ett tekniskt intresse och trivs med koordinering och många kontaktytor? Då kan detta vara en möjlighet för dig!

Vi söker nu en Product Data Engineer till R&D-avdelningen på det globala bolaget Xylem.

Om tjänsten

I rollen som Product Data Engineer är du en del av avdelningen Produktdata som består av ett engagerat team om 8 medarbetare. Avdelningens främsta uppgift är att äga de Product Lifecycle Management-applikationer (PLM-applikationer) som används av R&D-avdelningen. Produktdata-avdelningen supporterar även användare och produktutvecklingsprojekt, äger verksamhetskritiska processer, kravställer mot IT samt vidareutvecklar PLM-applikationerna. Gruppen arbetar väldigt nära verksamheten och genomgår just nu en förändring mot ett mer agilt arbetssätt.

Som Product Data Engineer kommer du att vara navet mellan R&D, produktion, marknadsavdelning och säljbolag. Ditt uppdrag är att stödja leverans i produktutvecklings-projekt av pumpar och omrörare genom att samla in data om produktprestanda från organisationens specialavdelningar och koppla tekniska regler för nya produkter samt vårda befintliga produkter. Dina dagar kommer att fyllas av koordinering, problemlösning, datainsamling, analys, support och kvalitetskontroll och du kommer att arbeta både proaktivt och reaktivt för att stötta organisationen med efterfrågad produktdata.

I rollen ingår bland annat att:

Stödja produktutvecklingsprojekt

Bidra till utvecklingen av Xylems produktprestandasystem och processer

Administration och publicering av tekniska ändringar, ritningar och annan teknisk produktdata

Uppdatera produktinformation i tekniska databaser

Stödja säljbolagen vid specialorder

Dokumentera och upprätta lathundar för best practise

Driva mindre projekt

Är det här du?

För att vara framgångsrik i denna roll söker vid dig med universitets- eller högskoleutbildning inom teknik. Det är meriterande om du har erfarenhet av support, konstruktion, produktprestanda, motorer, produktion, produktutveckling, el-lära och/eller strömningslära.En god förmåga att uttrycka dig väl i tal och skrift på både svenska och engelska är en förutsättning för rollen. Koncernspråket är engelska.

Vi värderar personliga egenskaper högt och vi söker dig som är strukturerad, noggrann och analytisk som person. Du trivs bra med att hjälpa och stötta andra och är prestigelös genom att tycka om variationen mellan högt och lågt. I denna roll kan du påverka och göra skillnad, därför är det viktigt att du ser ständiga förbättringar som en del av ditt dagliga arbete och att du har en naturlig framåtanda.

Vill du veta mer?

I denna rekrytering samarbetar Xylem med Level Recruitment. Vänligen sök tjänsten genom att klicka på ”ansök”-knappen här intill. Vid frågor vänligen kontakta rekryteringskonsult Alexandra Tihinen på 08-120 50 421. Urvalet av ansökningar sker löpande.

Välkommen in med din ansökan!

Sökord: produktprestanda, produktdata, ingenjör, administration, PLM, koordinator, analys, elmotor, hydrauldelar, spänning, data engineer, data quality, projektledare, kontaktytor, produktutveckling

Om Xylem

På Xylem arbetar 17 000 personer mot ett gemensamt mål: att skapa innovativa lösningar för världens vattenbehov. Genom att utveckla nya tekniker, förbättrar vi hur vatten används, förvaras och återanvänds nu och i framtiden. Vi transporterar, renar, analyserar och återför vattnet till naturen och hjälper människor att använda vatten effektivt – hemma, på arbetet, inom industrin och i jordbruket. Vi har mer än 100 års erfarenhet inom vattenteknikområdet och erbjuder en portfölj av ledande produktvarumärken och expertkunskaper inom en stor mängd applikationer. Vår kompetens har lett till långvariga relationer med våra kunder i mer än 150 länder. Xylem hade 2018 en omsättning på 5,2 miljarder dollar. Läs gärna mer om Xylem på www.xylem.se.

Kontaktperson

Alexandra Tihinen

08-120 50 421

Tjänstens omfattning

Heltid

Anställningsform

Tillsvidareanställning

Placeringsort

Sundbyberg",Undefined,indeed,5961a8e22b72530304f2a3c375feda0e
Data Scientist,#N/A,SPOTIFY SINGAPORE PTE. LTD.,Singapore,#N/A,Singapore,2019-06-10,"Roles & Responsibilities We seek an outstanding Data Scientist to join our Markets Research team in Singapore.  This individual will be responsible for partnering with local business operations teams to drive strategic decision-making across the globe. You will study user behaviour, market dynamics, and content strategies, providing data and insights that will influence strategic direction. Above all, you will be at the nexus of data science and business at one of the most innovative companies in the world. In addition to possessing strong technical background of his/her own, the ideal candidate will be a natural communicator who is able to explain complex statistical frameworks to non-technical stakeholders all over the world. Accompanying this broad set of responsibilities is exposure to many departments, as well as senior management, at Spotify. What you'll do Productize day-to-day analytics and insights support for Spotify’s Markets Operations team Develop a robust body of knowledge around each of Spotify’s key markets to proactively address business questions and drive strategy Work closely with cross-functional teams of analysts, product owners, marketers, designers, and others across the company who are responsible for driving results in local markets Support Markets leadership with research on key business initiatives and challenges Requirements Who you are Degree in Computer Science/Engineering, Mathematics, Statistics, Economics, or another quantitative field 3-5 years of experience, preferably at at least one company with a matrix organisational structure Excellent communication and stakeholder management skills Extensive experience manipulating and analysing complex data with SQL, Python and/or R. Knowledge of Google BigQuery and Java/Scala is a plus Familiarity with big data processing frameworks like Hadoop or Spark is a plus Ability to converse in two or more languages is a plus Comfort in operating independently in a fast-paced work environment | Degree in Computer Science/Engineering, Mathematics, Statistics, Economics, or another quantitative field 3-5 years of experience, preferably at at least one company with a matrix organisational structure Excellent communication and stakeholder management skills Extensive experience manipulating and analysing complex data with SQL, Python and/or R. Knowledge of Google BigQuery and Java/Scala is a plus Familiarity with big data processing frameworks like Hadoop or Spark is a plus Ability to converse in two or more languages is a plus Comfort in operating independently in a fast-paced work environment",Undefined,Jobscentral,b53ee1dbf6ecbc3825d3626d14129990
Big Data Engineer (Financial Services),"IT-Hardware, IT-Administration, Consulting, Consumer Banking, Corporate Banking, Corporate Communications/Public Relations, Corporate Finance, Credit & Loan, IT-Management, IT-Software/Development",ERNST & YOUNG ADVISORY PTE. LTD.,Singapore,#N/A,Singapore,2019-07-06,"Roles & Responsibilities We are the only professional services organisation who has a separate business dedicated exclusively to the financial services marketplace. Join Financial Services (FSO) and you will work with multi-disciplinary teams from around the world to deliver a global perspective. Aligned to key industry groups including asset management, banking and capital markets, insurance and private equity, we provide integrated advisory, assurance, tax, and transaction services.   The opportunity  As part of our Data and Analytics team of Financial Services Advisory practice you will work with multi-disciplinary teams to support clients in a wide range of big data initiatives aiming to generate and present new, useful and actionable insights. You will have the opportunity to work and take responsibilities in challenging engagements, gaining exposure to clients in various sectors both in Singapore and in the APAC region.    Your key responsibilities Participation in large-scale client engagements. Contribution towards, or even leading, the delivery of innovative and engaging big data solutions. Understanding of business and technical requirements, provision of subject matter expertise, and implementation of big data engineering techniques. Conducting of data discovery activities, performing root cause analysis, and making recommendations for the remediation of data quality issues. Putting into practice good organizational and time management skills, with the ability to prioritize and complete multiple complex projects under tight deadlines. Requirements Skills and attributes for success Leverage technology to continually learn, improve service delivery and maintain our leading edge best practices Strong presentation skills and proficiency in the use of PowerPoint, Word and Excel Good understanding of financial services industry   To qualify for the role you must have Understanding or even practical experience of handling and manipulating semi-structured and unstructured data. Deep understanding of big data technology, concepts, tools, features, functions and benefits of different approaches available. Ability to deploy, manage, and administer Hadoop-based components. Ability to design, build, install, configure and support Hadoop-based applications. Experience with one of Java, C# or C++. Hands-on experience with HiveQL. Familiarity with data ingestion tools such as Kafka, Flume and Sqoop. Knowledge of hadoop related workflow/scheduling tools such as Oozie. Understanding of data modeling (ER models) techniques. Experience with investigating and handling data quality issues. Minimum 3 years hands-on experience in two (2) or more of the above areas. A Bachelor or Masters degree in Computer Science, Engineering, or other related fields.  Ideally, you’ll also have Design and implementation experience of data models in physical form in one (or more) of the leading RDBMS platforms such as SQL Server, Oracle, IBM DB2/Netezza, Teradata, etc. Experience with Business Intelligence or statistical analysis tools and techniques. Strong communication and business relationship skills to effectively explain analysis, both verbally and in writing, to others and translate analysis into a clear business plan. Strong time management and organizational skills to gather and make use of data (both internal and external).  What we look for Highly motivated individuals with excellent problem-solving skills and the ability to prioritize shifting workloads in a rapidly changing industry. An effective communicator, you’ll be a confident team player that collaborates with people from various teams while looking to develop your career in a dynamic organization.   What working at EY offers We offer a competitive compensation package where you’ll be rewarded based on your performance and recognized for the value you bring to our business. We also offer you: Support, coaching and feedback from some of the most engaging colleagues around Opportunities to develop new skills and progress your career The freedom and flexibility to handle your role in a way that’s right for you   About EY As a global leader in assurance, tax, transaction and advisory services, we’re using the finance products, expertise and systems we’ve developed to build a better working world. That starts with a culture that believes in giving you the training, opportunities and creative freedom to make things better. Whenever you join, however long you stay, the exceptional EY experience lasts a lifetime. And with a commitment to hiring and developing the most passionate people, we’ll make our ambition to be the best employer by 2020 a reality.   If you can confidently demonstrate that you meet the criteria above, please contact us as soon as possible. Join us in building a better working world. Apply now.   | Leverage technology to continually learn, improve service delivery and maintain our leading edge best practices Strong presentation skills and proficiency in the use of PowerPoint, Word and Excel Good understanding of financial services industry | Understanding or even practical experience of handling and manipulating semi-structured and unstructured data. Deep understanding of big data technology, concepts, tools, features, functions and benefits of different approaches available. Ability to deploy, manage, and administer Hadoop-based components. Ability to design, build, install, configure and support Hadoop-based applications. Experience with one of Java, C# or C++. Hands-on experience with HiveQL. Familiarity with data ingestion tools such as Kafka, Flume and Sqoop. Knowledge of hadoop related workflow/scheduling tools such as Oozie. Understanding of data modeling (ER models) techniques. Experience with investigating and handling data quality issues. Minimum 3 years hands-on experience in two (2) or more of the above areas. A Bachelor or Masters degree in Computer Science, Engineering, or other related fields.  | Design and implementation experience of data models in physical form in one (or more) of the leading RDBMS platforms such as SQL Server, Oracle, IBM DB2/Netezza, Teradata, etc. Experience with Business Intelligence or statistical analysis tools and techniques. Strong communication and business relationship skills to effectively explain analysis, both verbally and in writing, to others and translate analysis into a clear business plan. Strong time management and organizational skills to gather and make use of data (both internal and external).  | Support, coaching and feedback from some of the most engaging colleagues around Opportunities to develop new skills and progress your career The freedom and flexibility to handle your role in a way that’s right for you",Undefined,Jobscentral,dbea52ab1adc10a9c0db6291456c70af
Data Scientist - Electricity Distribution,Computer,CGI,#N/A,#N/A,United kingdom,2019-06-10,"Job Description  Data Scientist - Electricity Distribution



Position Description

Be part of something exciting. Do you want to take your career to the next level as part of one of the big five IT and business process firms in the world? We are recruiting for an Data Scientist to join our team; responsible for innovation and data modelling across our clients in the Energy and Utilities Sector



Your future duties and responsibilities

 
Maintain domain expertise that bridges the business needs data considerations and associated existing ICT solutions available and those immerging from innovation programmes such as the Network Innovation Allowance and Competition programmes.  


 
The post-holder will maintain an up to date view of sector requirements and be actively engaged in developing these with clients through to project delivery.  


 
Critically add value by applying domain knowledge and experience to ensure IT initiatives closely match business expectations and desired outcomes.  


 
To approach new and existing clients and identify business needs where CGI solutions can improve business performance in a range of metrics.  


 
Deliver an open and pragmatic approach to specifying IT solutions to meet business requirements and be comfortable working with clients at levels up to senior management.  


 
Hands-on involvement to deliver resulting projects.  


Required qualifications to be successful in this role

Knowledge and experience of the UK Electricity Distribution industry sector, gained in an innovation, main business or IT/OT role.



Engineering or Computer Science Degree or equivalent with electricity distribution or DNO ICT experience, and/or smart grid project experience. Qualified electrical engineer ideally network company trained and authorised, or ICT professionals with DNO delivery experience.



Familiarity with Network Operator ICT landscape especially core systems NMS, GIS and EAM as well as network planning applications.



Aware of network innovation programmes feeding the smart grid implementation effort in the UK and the in-house digital transformation required.



For ICT professionals, skills may include technical architecture, solution architect, master data management, data analysis/architecture/modelling/design, requirements capture, ICT strategy, design, service delivery, Project-lifecycle and technology selection.



Knowledge of electrical distribution equipment, network topology and connectivity represented in the core Network operator systems such as NMS, GIS and EAM will be an advantage.



Experience of Data Governance, Master Data Management, IEC 61970/61968/62325 Common Information Model standards and their application, and a working knowledge of the common network modelling and power-flow analysis tools would be very useful.



IT skills sought include Unix, Oracle Spatial, SQL Server, Oracle PL/SQL, Object-Oriented Analysis and Design, SSADM, UML, VB, C, Java, JSON, ESB technologies, Open Source, PostgreSQL/PostGIS, Orient DB, Python, ITIL qualifications




Build your career with us. 



It is an extraordinary time to be in business. As digital transformation continues to accelerate, CGI is at the center of this change—supporting our clients’ digital journeys and offering our professionals exciting career opportunities.



At CGI, our success comes from the talent and commitment of our professionals. As one team, we share the challenges and rewards that come from growing our company, which reinforces our culture of ownership. All of our professionals benefit from the value we collectively create.



Be part of building one of the largest independent technology and business services firms in the world.



Learn more about CGI at www.cgi.com.



No unsolicited agency referrals please.



CGI is an equal opportunity employer.




 

Skills 

 

Reference  690316",Undefined,indeed,7ffb57e927407f7e282244f8afbc6472
Principal Data Scientist,Computer-or-internet,Company Info Follow Get job updates from Money Mart Financial Services Money Mart Financial Services 10 reviews Money Mart Financial Services,Dallas,Texas,United states,2019-07-11,"Job Description

What do you do?

We’re looking for a Principal Data Scientist capable of using deep learning, ML and other techniques to design, evangelize, and implement state-of-the-art solutions. You'll design and run experiments, research new algorithms, and find new ways of optimizing risk, profitability, and customer experience. You get the gist – enjoy the experience of working on high impact, Silicon Valley style projects, while living in Dallas. You also get the learn about how big data is revolutionizing the world of consumer financial services.

What do we need?

You to have an amazing personality and communication style.

That you are super-organized and are a problem solver.

That you take pride in everything that you do, and it shows.

And most importantly that you have unquestionable integrity.

Why work for us?

We invest in our employees, and offer extensive training, and development programs to set you up for future success.

If we sound like a fit, and you’re ready to start an exciting career with an organization that fosters employee growth, apply today!

Job Description

This position will be responsible for:

Use deep learning, machine learning and analytical techniques to create scalable solutions for business problems

Analyze and extract relevant information from large amounts of historical data to help automate and optimize key processes

Work closely with product engineering teams to drive model implementations and new algorithms

Qualifications

Education

BS and Masters degrees in computer science, or related technical, math, or scientific field; PhD degree preferred.

Experience

5+ years of professional experience in a business environment

3+ years of relevant experience in building large scale machine learning or deep learning models and/or systems

Hands on experience building models with deep learning frameworks like MXNet, Tensorflow, Caffe, Torch, Theano or similar.

1+ year of experience specifically with deep learning (e.g., CNN, RNN, LSTM)

Skills

Familiarity with Python and R

Strong working knowledge of deep learning, machine learning and statistics.

Strong communication and data presentation skills

The motivation to achieve results in a fast-paced environment.

Strong attention to detail

Comfortable working in a fast paced, highly collaborative, dynamic work environment

Ability to think creatively and solve problems

Additional Information

Benefits

Medical / Dental/ Vision benefits available after 30 days of employment

Company paid life insurance

Paid holidays

PTO/ 401K / Tuition Reimbursement

On-site wellness center

All your information will be kept confidential according to EEO guidelines.",Undefined,indeed,23ad46a12d26b5bafba90e248138435b
Data Scientist,Computer-or-internet,Company Info Follow Get job updates from KMM Technologies 3 reviews,Reston,Virginia,United states,2019-07-11,"Overview

Role: Data Scientist

Location: Reston, VA

Duration: long term

Your day-to-day:

Project Conception/Refinement - Work alongside our product team to conceive, refine, and plan for new functionality/products that enhance FEPOC’s products/value

Project Management - Shepherd projects throughout their phases, manage resources, plan out delivery, expose and mitigate risks

Promote/Foster Innovation - Identify ways our modeling, processes, interactions can be improved and work with the team to propose and implement solutions

Represent Data Science - Work alongside our product team to conceive and bring to life new functionality/products that impact FEPOC’s performance and value. Represent the data science team throughout FEPOC.

Requirements:

• 5-8 Years data science research or industry experience

Python proficiency - It’s our lingua franca, and we’re big Jupyter fans

MS or PhD in CS or STEM - Ability to transform concepts into practical solutions

Machine Learning experience - Successful implementation of ML solutions

Communication Ability - Experience/comfort in presenting abstract concepts

Project Management Experience - Experience leading large DS/ML projects

Healthcare Experience - Experience with data science/ML techniques as applied to Healthcare, specifically experience on recommendation engines for members and claims anomaly detection

Required abilities and skills:

Advanced proficiency in Python and Spark/Scala for classical statistical analysis and data modeling, machine learning and ETL processes.

Ability to write production-ready code including documentation and unit tests.

Experience with machine learning methods like k-nearest neighbors, random forests, ensemble methods and more.

Proficiency in data science modeling – AI, Machine Learning, Deep Learning, Decision Trees, Random Forest, Neural Networks, Supervised/Unsupervised Learning, Forecasting, Predictive Modeling and Clustering.

Strong background in machine learning using unsupervised and supervised methods.

Deep knowledge of fundamentals of machine learning, data mining and statistical predictive modeling, and extensive experience applying these methods to real world problems

Fluency in SQL and other programming languages. Some development experience in at least one scripting language (PHP, Python, Perl, etc.)

Proven experience of using Python Machine Learning & Data Pre-processing Libraries. (Scikit Learn, Numpy, Pandas)

Ability to initiate and drive projects to completion with minimal guidance

The ability to communicate the results of analyses in a clear and effective manner

Preferred:

Preferred experience with a statistical package such as R, MATLAB, SPSS, SAS, Stata, etc.

Proficiency with healthcare analytics and data structures is preferred.

Desired interdisciplinary skills include big data technologies, ETL, statistics and causal inference, Deep Learning, modeling and simulation.

Intermediate to advanced ability to create data visualizations using Python.

Leading data science projects or teams (as the most technically advanced team member) or working independently on data science projects.

Experience with large data sets and distributed computing (Hive/Hadoop) a plus.

Strong skills in software prototyping and engineering with expertise in applicable programming and analytics languages (Python, R, Spark/Scala) and various open source machine learning and analytics packages to generate deliverable modules and prototype demonstrations of their work.

Capacity to convert to a full time positions without a need for current or future sponsorship

Thanks & Regards

-

Laxman Kumar

Talent Acquisition

KMM Technologies, Inc.

CMMI Level 2 and ISO 9001:2008 Certified

WOSB, SBA 8(A), NMSDC & VA SWaM Certified

Contract Vehicles: GSA Schedule 70 & SeaPort-e Prime

Tel: 240-800-0039 | Fax: (866) 856 3684

E-MAIL: laxman@kmmtechnologies.com

LinkedIn: linkedin.com/in/laxman-m-841970aa

www.kmmtechnologies.com",Undefined,indeed,29d341a0fd9ad7df3a3e949797406909
Data Scientist,Computer,Darwin Rhodes,London,#N/A,United kingdom,2019-07-10,":

Working as part of a cross-functional agile team, collaborating with others to understand requirements, analysing and refining stories, designing solutions, implementing and testing them

Applying Behaviour Driven Development techniques, collaborating closely with users, analysts, developers and other testers

Writing code and writing it well. Be proud to call yourself a programmer. Use test driven development, write clean code and refactor constantly. Make sure we are building the thing right

Ensuring that the software you build is reliable and easy to support in production. Being prepared to take your turn on call providing 3rd line support when it's needed

Helping define the architecture of the components you are working on

Helping your team to build, test and release software with the short lead times and a minimum of waste. Working to develop and maintain a highly automated Continuous Delivery pipeline

Contributing towards a culture of learning and continuous improvement within your team and beyond

Mandatory Skills:

Hands On experience for development & maintenance of data ingestion and transformation processes on the Cloudera based Secure Data Lake platform

Must have experience in Hive partitioning, indexing and performance tuning techniques

Having experience in scheduler tools like Control-M and application monitoring tools like Geneos

Deep knowledge of at least one modern programming language, along with understanding of both object oriented and functional programming. Ideally Java, Scala and Python

Experience of the Hadoop ecosystem and the technologies that comprise it

A good understanding of Apache Spark/Kafka

Practical experience of using test driven development and constant refactoring in continuous integration environment

Knowledge of SQL and relational databases - ideally both Hive/Impala/SparkSQL and a traditional RDMS, such as Oracle

Experience working in an agile team, practicing Scrum, Kanban or XP

Sound knowledge of micro-services, reactive programming

Exposure to cloud based deployment using Docker, Kubernetes

Good to Have Skills:

A background in Behaviour Driven Development, particularly experience of how it can be used to define requirements in a collaborative manner, ensure that the team builds the right thing and create a system of living documentation

An understanding of web technologies, frameworks and tools, for example: HTML, CSS, JavaScript, Angular, Bootstrap, React, D3, Node.js

An understanding of data science techniques, including experience with technologies such as Pandas, Spark Client Library, R, etc. Experience creating effective data visualizations

Knowledge gained in Financial Services environments, for example products, instruments, trade lifecycles, regulation, risk, financial reporting or accounting

eTeam Privacy Policy",Undefined,indeed,da407f4d77d478274bdb51c33ce76f94
Medior Data Scientist,Dienstverlening,Good Company,Utrecht,Utrecht,Netherlands,2019-07-13,"Leer de organisatie kennen

Je werkt altijd bij toonaangevende organisaties aan nieuwe IT projecten die er echt toe doen. Voorbeelden zijn ABN AMRO, SNS, KvK, BAM, Essent.

""Changing the way they work"". Jij werkt mee aan het veranderen en stroomlijnen van de bedrijfsprocessen van onze klanten zodat zij effectiever kunnen werken.

Work hard, play hard!

Over de functie

Enterprise Analytics

Als Data Scientist zal je bij een grote diversiteit aan organisaties aan de slag gaan om complexe business cases op te lossen door gebruik te maken van grote hoeveelheden data en innovatieve technieken. Je zal hierbij verantwoordelijk zijn voor het gehele traject van A tot Z. Enkele voorbeelden van projecten die klaarliggen:

Adviseren van directieleden van grote organisaties (44000+ werknemers) om hun data-driven strategie verder te ontwikkelen.

Van scratch af aan opzetten van een Big Data Analytics strategie voor een logistieke dienstverlener

Analyse van een grote business case voor een overheidsinstantie waarbij meerdere externe bronnen gekoppeld moeten worden

Het geven van workshops/trainingen/kennissessies voor een financiële multinational

Het analyseren van een grote social media campagne van een FMCG marktleider door middel van textmining

Het maken van voorspellingsmodellen m.b.t. predictive maintenance

Door middel van jouw analyses en voorspellingen heb je de kans om gerenommeerde organisaties te helpen bij het maken van belangrijke keuzes en ingrijpende veranderingen.

Jouw kwaliteiten

Minimaal 2 jaar werkervaring als Data Scientist met het analyseren van grote hoeveelheden data en het maken van voorspellingsmodellen

Afgeronde kwantitatieve WO opleiding (Wiskunde, Econometrie, Technische Bedrijfskunde, Artificial Intelligence)

Aantoonbare ervaring in advies en consulting trajecten

Ruime ervaring met programmeren (R, Python, Java)

Ruime ervaring met data analyse tools (R, SAS, STATA, Matlab)

Ruime ervaring met data visualisatie tools (R, SAS VA, Tableau, Qlikview, etc)

Uitstekende mondelinge en schriftelijke beheersing van de Nederlandse en Engelse taal

Ruime ervaring met gedistribueerde processing: Hadoop, Spark, Amazon AWS (EMR, Elasticsearch, Red Shift), MapReduce, NoSQL

De voordelen

De partij werkt samen met gerenommeerde organisaties. Zodoende werk jij samen met de allerbeste Data Scientists.

Enterprise Analytics richt zich alleen op Big Data Analytics, waardoor jij je alleen richt op hetgeen je voor gekomen bent.

Er zijn passende projecten voor zowel junior, medior als senior consultants. Van het uitvoeren van een bestaande Big Data Analytics strategie tot het bedenken en opzetten van een nieuwe strategie. Daarnaast bieden wij jou een hoge mate van vrijheid, zelfstandigheid en flexibiliteit.

De mogelijkheid wordt geboden tot kennisopbouw d.m.v. kennisdeling, congressen en het volgen van opleidingen om jou voorop te laten lopen in je vakgebied.

maakt een structurele groei door met betrekking tot het aantal projecten en het aantal nieuwe consultants. Echter gaat dit niet ten koste van onze persoonlijke aanpak en begeleiding om jouw ambities te realiseren. Senior Consultant, Managing Consultant, Business Unit Manager? Slechts enkele voorbeelden die op jou van toepassing kunnen zijn.

Onze medewerkers zijn onze belangrijkste krachten. Daar willen wij je dan ook graag naar belonen.

Klinkt goed?

Ben jij geïnteresseerd in bovenstaand profiel? Good Company ziet graag jouw sollicitatie tegemoet! Solliciteer via onze website op de vacature van Medior Data Scientist.",Undefined,indeed,3dcb2f58de107f93ea0b6b541a7ea9ba
Big Data Engineer,"IT-Hardware, IT-Administration, IT-Management, IT-Software/Development",THE ADVERTISER,Singapore,#N/A,Singapore,2019-07-08,"Roles & Responsibilities As Big Data Engineer, you will focus on managing the Hadoop cluster, Implementing data ingestion framework & designing data models. Your primary role will be to implement data lake & transform the data for business use.  PRIMARY RESPONSIBILITIES - Deliver big data solution based on premise Hadoop or cloud based systems like AWS. Manage Hadoop cluster, participate in scale out planning & implementation. - Design ingestion layer for structured & unstructured data (text, voice, xml etc) & implement insurance specific data model for business & analytics use. - Deliver ELT solution including data extraction, transformation, cleansing, data integration and data management. Implement batch & near real time data ingestion pipelines based on reference architecture like Lambda. - Ability to augment with new sources of data including internal/external untapped data. Contribute to the establishment and maintenance of cloud computing platform and big data services. - Operationalize analytics models for production usage with big data workflows, proper security & access control. - Ability to provide support for analytics tools & environment like RServer etc & debug performance issues. Requirements 1. EDUCATION / TRAINING - Bachelor degree holder in Engineering or computer application. 2. EXPERIENCE - Min 4 years of experience in Big Data technology. Knowledge of Hadoop architectures with hands on experience in implementing data lake. Experience working & implementing data as a service via REST API for data products. - Should be strong programmer in Python, Scala, Java & with advance knowledge of Linux. 3.  COMPETENCIES - Programming Languages: Java, Scala, Python, R, SQL, Linux commands - Big Data Technology: Apache Hadoop (Cloudera), Spark, Kafka Hbase, No SQL DB - Data Integration tools: Talend, SSIS etc. - Business acumen: Insurance or banking domain knowledge preferred. - Technology evangelist.      ",Undefined,Jobscentral,658f86b611e87821b81088aab48705ff
Data Engineer (6 Month CONTRACT) - Global Technology Company,it jobs,MRJ Recruitment,Manchester,Manchester,United kingdom,2019-07-12,"Data Engineer (6 Month CONTRACT) - Global Technology Company (Manchester) 
 
Day rate: Up to £400 Per Day
 
Are you looking to put your stamp on an international digital brand?
 
A digital brand based in the heart of Manchester City Centre is searching for an experienced Data Engineer (Traffic Automation/ ETL Consultant) for 6 month contract,to help delivery on a huge and highly rewarding project The candidate will be; Skilled in  building and helping maintain Power BI reports using complex datasets and document-oriented databases.
 
ROLE: Data Engineer (Traffic Automation/ ETL)
 
The ideal candidate should have strong ETL skills, preferably Alteryx, they should have experience in collecting data from a variety of sources including APIs, Web maps and other websites. They will assist with the collection, consolidation and storage of traffic data from data partners  & other sources.
 
ESSENTIAL SKILLS: 

Experience in designing ETL processes including knowledge of data warehousing strategies and theories

Develop new or maintain and improve existing ETL processes ideally using Alteryx, R or Python, including but not limited to web scraping tabular data and web maps, automating file downloads, making use of API such as for geocoding addresses

Scripting GIS processes in QGIS (using Python) to (semi-)automate georeferencing, point plotting and data matching

Experience in using REST API’s

The ability to articulate and document architectural solutions and processes

Familiarity with VPN tools to enable access to international websites

Willingness to attend technical and business meetings and act as subject matter expert

Establish and maintain collaborative relationships with stakeholders

Experience extracting data from .pdf files

Strong knowledge of OCR tools and processes

Traffic network knowledge and experience highly desirable

*Experience or knowledge of traffic, demographic or other geospatial data is desirable.",Full Time,reed,daaec3b7003d78986a3dac2619fecb4f
Data Engineer,it,experian,London,#N/A,United kingdom,2019-06-22,"Description  Senior Data Engineer * Posting date: 20.06.2019 * Closing date: 20.07.2019 * Salary: Competitive   Do you want to join a team that is transforming the way data services are delivered at one of the world’s most trusted information services organisations?   We are looking for a Senior Data Engineer to join our growing Data Engineering team within Experian’s e-commerce business, Experian Consumer Services. You’ll contribute to the maintenance of our data platform development of new data solutions helping to access, extract and manipulate data for MI/BI, descriptive and predictive analytics applications. You’ll be using modern, scalable technologies to support the expansion of machine learning and be part of transforming the way that we understand and talk to our customers.   Our team has a passion for learning, problem solving and building innovative and scalable data solutions. If this sounds like a good fit for you then this could be a great opportunity.   Key responsibilities of the role: * Design and deployment of large scale data pipelines and applications * Build production ready data services using a range of technologies including Spark, Kafka, Hive and Impala production ready data services using a range of technologies including Spark, Kafka, Hive and Impala * Contribute to the evolution of the platform by evaluating new technologies and building prototypes covering topics such as machine learning, streaming or API-driven services  * Work as part of an agile team to deliver business-focused requirements on the data platform & leading Data Engineer team. * Advise development teams on best practices for the use of big data technologies and coding practices * Develop and share knowledge on new technologies across our analytics and data science community   You’ll have experience with a majority of the following: * A minimum of 2 years of designing and building consumer-based data solutions at scale for a similar size organisation using Spark, Kafka, Impala, Oozie, Hive etc. * Strong understanding of and experience utilising big data modelling methodologies and best practices * Strong problem-solving skills and experience in debugging and performance tuning big data applications * Skilled programmer with extensive experience in Scala, Java or Python * Experience with Linux and scripting languages, e.g. bash, is required * Experience working in and leading teams using agile delivery methods * Experience with visualisation platforms such as MicroStrategy and Tableau * Experience building cloud-based solutions (AWS requirement) * Demonstrable communication, influencing and relationship skills in a virtual, matrix environment * Team management/supervisory or leadership experience required   Essential technology stack * Kafka * Hadoop * Scala (preferable), Java/Python (advantageous) * Spark",Undefined,monster,13cb69c551351cce3da8348febd32f36
Data Engineer with IPAF,engineering,DCS Recruitment,Nottingham,Nottingham,United kingdom,2019-07-08,DCS Recruitment currently seek a data engineer with IPAF in Nottingham on behalf of a national clientStart Friday 12th July 2019CSCS/ECS card and IPAF requiredReferences needed prior to startCall Scott on 0161 212 2308 (option 2) or submit your cv to apply,Full Time,monster,ce9829a98db49202ea18c8a0494726b8
Senior Data Engineer,Engineering-or-architecture,"Company Info Follow Get job updates from InTec, LLC 2 reviews",Springfield,Virginia,United states,2019-07-13,"Overview

Position ID: M-24-B02

Position/Project Name: Office of Strategic Operations Enterprise Integration

The ideal candidate for this position should have strong data engineering background and the ability to interpret metrics and translate these metrics into requirements. Additionally, a strong understanding of NGA Program Build process is a plus. The ability to strategically plan and execute the director’s initiative, mission, and vision for the out years is a must.

Responsibilities

Candidate will plan and perform full SE&I life cycle technical design, CONOPS development, implementation planning, integration, cost, schedule, technical performance, opportunity/risk, and supportability/mission effectiveness analyses spanning all levels of NSG/ASG enterprise.

Ensure logical and systematic conversion of mission needs, joint topical or product requirements into total systems solutions through enterprise transition to operations, acknowledging cost, schedule, and technical constraints.

Manage GEOINT mission-driven capability needs across NSG/ASG, driving requirements closure, performing functional and timeline analysis, detailed trade studies, AoAs, mission needs allocation & interfaces definition translating customer requirements into capability and service specs.

Plan and coordinate NSG/ASG mods, with emphasis on NGA systems, segments, platforms, capabilities, services, and functions to support GEOINT data types, formats, metadata, and capacity.

Apply appropriate project management model selected for capability implementation efforts and perform end-to-end project analysis, to ensure capabilities being implemented comply with NSG/ASG enterprise technical architecture and support NSG/ASG enterprise control gates.

Manage, develop, coordinate, document, integration of GEOINT functions into existing NGA segments.

Qualifications

Required Qualifications:

B.S. in Engineering, CS, Info Systems, Math, or related scientific or technical discipline

16+ years’ experience in directly related field, with 10+ years GEOINT/geospatial experience

Data engineer and requirement development; understanding of metrics and interpretation of metrics

5+ yrs. recent ISR TCPED (Tasking, Collection, Processing, Exploitation, and Dissemination) SE&I experience

Experience using logic and reasoning to identify the strengths and weaknesses of alternative technical solutions, conclusions or approaches to problems (studies & analyses, white papers)

Demonstrated ability/experience identifying/solving problems reviewing related information to develop/evaluate options and implement solutions with minimal supervision / direction

Strong interpersonal, problem solving, organizational, multi-tasking, load-balancing skills

Excellent written, verbal, presentation skills; Able to lead technical forums/initiatives/studies

Technical project engineering project leadership skills/experience; systems analysis experience

Desired Qualifications:

M.S. in Engineering, CS, Info Systems, Math, or related scientific or technical discipline

Relevant SE&I certification (INCOSE xSEP), IT (ITIL), Agile [ScrumMaster]), etc.

Knowledge of NGA Portfolio Strategic Initiatives (ABI, SOM, OBP, etc.)

Knowledge/experience with all source all domain (space, air, sea, land)

Experience working with mission partners complying with export control/ITAR requirements

InTec, LLC is a Service Disabled Veteran Owned Small Business (SDVOSB) located in Northern Virginia. Our mission is to provide high quality, cost effective solutions that will provide long term value to our customers and the Nation. InTec Management believes our employees’ welfare is paramount to good business and so provides a compensation and benefits package which reflects our corporate policy and befits our seasoned professionals.

InTec is an Equal Opportunity Employer",Undefined,indeed,948e4faf193b5c0b57ae50ea15df21e9
Data Engineer,arts design and media,Robert Half Technology,Los angeles,California,United states,2019-07-12,"Ref ID: 00320-9502060501Classification: Account Executive/Staffing ManagerCompensation: $165,000.00 to $165,000.00 per yearData Engineer Salary: $165,000 (depends on experience) Title: Sr. Big Data Engineer Location: Play Del Rey, CA Employment Type: Full Time ndash; Direct Hire Benefits: M/D/V, 401K, competitive compensation structure with stock Hours: 8am-4pm, 9am-5pm, or 10am-6pm Job Requirements **For immediate and confidential consideration please email your resume to Omar Garcia-Gomez nbsp;at omar.garcia-gomez@rht.com** Ideal candidate must be enthused about all spectrum of big data development, including data transport, data processing, data warehouse/ETL integration, quick learning and self-starting. This is a demanding role that will require hands-on experience with big data processing development to be deployed on Linux. You will be responsible for the day to day operation and new developments. We are seeking a candidate with good skills in software development life cycle, build data services with Java (or Scala), script languages, like, Python etc. This position includes 24x7 production support. Candidates do not need to come with Big Data Engineering experience, if you are a strong Java or Scala developer and want to get into Big Data please reach out. Top Requirements: Bachelor rsquo;s in Computer Science, Mathematics, or Engineering Java 7 Scala Python ETL nbsp;Great if you have: Experience with some of the following AWS tools: EMR, Kinesis, Firehose, Redshift, RDS, S3 API, Lambda, SQS Experience with Presto, Hive, Impala or similar SQL based engine for Big Data Experience with Redis, Cassandra, MongoDB or similar NoSQL databases. Scala, Python Experience with any of the following message / file formats: Parquet, Avro, Protocol Buffer **For immediate and confidential consideration please email your resume to Omar Garcia-Gomez nbsp;at omar.garcia-gomez@rht.com**Technology doesn't change the world. People do.As a technology staffing firm, we can't think of a more fitting mantra. We're extreme believers in technology and the incredible things it can do. But we know that behind every smart piece of software, every powerful processor, and every brilliant line of code is an even more brilliant person. Leader among IT staffing agenciesThe intersection of technology and people — it's where we live. Backed by more than 65 years of experience, Robert Half Technology is a leader among IT staffing agencies. Whether you're looking to hire experienced technology talent or find the best technology jobs, we are your IT expert to call. We understand not only the art of matching people, but also the science of technology. We use a proprietary matching tool that helps our staffing professionals connect just the right person to just the right job. And our network of industry connections and strategic partners remains unmatched.Apply for this job now or contact our branch office at 888-490-4429 to learn more about this position.All applicants applying for U.S. job openings must be authorized to work in the United States. All applicants applying for Canadian job openings must be authorized to work in Canada.© 2019 Robert Half Technology. An Equal Opportunity Employer M/F/Disability/Veterans.By clicking 'Apply Now' you are agreeing to Robert Half Terms of Use.",Full Time,careerbuilder,e35b608f8052e7e3053361cc59018870
Data Engineer,Hotel,Die Mobiliar,#N/A,#N/A,Switzerland,2019-07-10,"Sie wollen auf grüner Wiese bauen und so die Systemlandschaft der Mobiliar nachhaltig prägen? Dann gestalten Sie mit uns die Zukunft – per sofort oder nach Vereinbarung bis 31.12.2019 mit Aussicht auf Verlängerung als Data Engineer Metadaten am Direktionsstandort in Bern mit einem Arbeitspensum von 60-80%.

Ihre Aufgaben

Sie helfen uns das Datenmanagement auszubauen und entwickeln Datenzugriffsapplikationen für das Meta-Datenmanagement.

Bei der Entwicklung und Visualisierung von Datenkatalogen helfen Sie mit.

Mit den Spezialisten für Datenqualität, Data Curation, Informationssicherheit und Datenlogistik arbeiten Sie eng zusammen.

Sowohl auf Stufe der Software-Entwicklung als auch mit dem Management kommunizieren Sie zielgruppengerecht.

Ihr Profil

Eine höhere Aus- oder Weiterbildung in Informatik (oder vergleichbar) haben Sie abgeschlossen.

Sie haben Kenntnisse im Datenmanagement.

Erfahrungen in der Software-Entwicklung mit besonderem Fokus auf Daten haben Sie bereits gesammelt.

Die deutsche Sprache beherrschen Sie in Wort und Schrift.

Ihr analytisches Denken und gute Kommunikations- und Präsentationsfähigkeiten zeichnen Sie aus und Sie behalten auch in einem komplexen Umfeld den Durchblick.

Haben wir Ihre Neugier geweckt? Sprechen Sie diese Herausforderungen an? Dann freuen wir uns, Sie kennen zu lernen.

Bei Fragen stehen Ihnen Frau Andrea Küffer, Recruiting & Sourcing, Telefon 031 389 63 43 oder Bruno Russiniello, Systemplattform und Daten-Architektur, Telefon 031 389 71 67 gerne zur Verfügung.",Undefined,indeed,a3f240cfa554e4f6cd1cba980bbb1e1e
Data Engineer - Vancouver,IT,STEMCELL Technologies Inc.,Vancouver,British columbia,Canada,2019-07-15,"Who We Are Job Description Summary

STEMCELL CEO and founder Dr. Allen Eaves started with a passion for science and a staff of eight. Today, STEMCELL is Canada's largest biotechnology employer and has more than 1000 employees in 11 countries around the world. Explore our history and our culture.

The Data Engineer is an expert in sourcing, cleansing, modelling, and content delivery to meet business needs. The role is a collaborative one with a focus on getting business users their data and allowing them flexibility to do their analysis as needed. As the organization grows, so will the role. This requires someone who is excellent problem solver, able to organize their work, be transparent, and a good communicator.

Job Description Duties and Responsibilities

Join us in our mission to advance the pursuit of scientific knowledge by supplying high-quality, innovative reagents, tools and services that enable life science research.

Qualifications STEMCELL Technologies Inc. is a privately-owned biotechnology company based in Vancouver that helps power leading-edge life science research around the world. Scientists performing stem cell, immunology, cancer, regenerative medicine and cellular therapy research are among those who rely on our cell culture media, cell separation products, instruments, ancillary reagents and contract assay services. We create novel, useful, standardized products of unfailing quality and deliver them to more than 70 countries via our many regional offices plus distribution centres in Vancouver, Seattle, Grenoble and Singapore. Driven by our love of science and our passion for quality, we see ourselves simply as ""Scientists Helping Scientists"" - standing by our customers to provide outstanding products, technical support and training. We have over 1000 science-oriented employees globally, including 250 PhDs/MScs, with most others holding a BSc or engineering degree. STEMCELL is proud to be the largest Biotechnology employer in This is an opportunity to work with highly motivated colleagues in a science-oriented, creative and dynamic environment. We offer a competitive salary, excellent benefits and significant career development

To apply please select the apply button. You will then be directed to a login screen asking you to set up an account. You must set up an account in order to apply.

Password must be eight characters long, contain at least one special character, one capital letter, and a number.",Undefined,indeed,b0412e4022bc83c388fb2af2f5d0d18e
Senior Data Scientist - Model Validation,Administrative,Funding Circle UK,#N/A,#N/A,United kingdom,2019-06-15,"Senior Data Scientist – Model Validation  


London 


Competitive + benefits + stock 


Funding Circle was created with one mission: to revolutionise the broken financial system and change small business finance! 


We've created the leading online marketplace for small business loans that directly connect credit worthy businesses with investors wanting attractive returns. 


In just nine years, 90,000 Funding Circle investors have lent £7 billion to 68,000 businesses across the world. In 2018 alone lending through our platform created and sustained 115,000 jobs worldwide and contributed £4 billion to the global economy.




The Role 

Funding Circle’s Global Model Risk team is looking to add an enthusiastic, smart, &amp; results-driven data scientist to validate the integrity and comprehensiveness of risk models independently.



Our data scientist will be working within Funding Circle’s Model Risk team, supporting the head of Enterprise Risk, and will be required to validate and monitor models across geographies.



They will also collaborate with Country Risk team and the Business teams to provide analytical input for the model development, credit strategy building, fraud prevention and anti-money laundering strategy building; and ensure that any risks are highlighted effectively on timely manner. 



Birds-eye view of the role: 

 
 


Perform model validation and relevant quantitative analyses to test the performance of the models for credit risk, stress testing, cash flow, financial crime, and other risk models 


Review models with respect to accounting requirements, investor requirements and internal standards 


Communicate validation findings and statistical analytics results with stakeholders effectively 


Ensure complete and accurate documentation of model validations 


Conduct analysis to support the validation management during ad-hoc projects or special investigations 


Work collaboratively with Model Development teams, Country Risk teams, and Business teams across the company to achieve best practice 
 



Qualifications &amp; Skills: 

 
 


Strong quantitative skills with an academic background in Econometrics, Statistics, Mathematics or similar fields 


Proven industry experience in developing or validating end to end statistical models 


Proficiency in analytical tools like Python or R, and associated statistical model libraries 


Proven problem-solving skills using logical reasoning and analytical methods 


Excellent ability to translate complex problems into clear and simple stories 


An open minded, collaborative and personable individual , identification with our Mission, “To build a better financial world” and alignment with our Core Values: Think Smart, Make It Happen, Be Open, Stand Together, Live The Adventure 
 



Why Join Us?  


Happy employees are productive employees, that’s why we offer a hearty benefits package including: 
 


Our employees make our mission a reality, and we want you to share in the company’s success by offering generous shares. 


Cool kit - Mac or PC 


Private healthcare, pension and healthcare cash back schemes 


Discounted onsite gym membership 


Learning and development through FC Academy 


Personal development funding 


Flexible working 


Free breakfast, barista coffee and discounted hot lunch at our Funderbar! 


We are a regular host of Meet-Ups and events. 


Company-wide socials 
 


At Funding Circle, we celebrate and support the differences that make you, you. We’re proud to be an equal opportunity workplace and affirmative action employer. We truly believe that diversity makes us better.",Undefined,indeed,d94a47ad7b9f6d520aaabd6a68a07129
Data Scientist,Computer,Valerann,#N/A,#N/A,United kingdom,2019-06-16,"Nobody can predict how we will use vehicles in 10 years. Are all vehicles going to be self-driving? Is traffic going to be controlled from a central system or distributed? Are we going to own cars at all? Whatever the future of autonomous vehicles will be, one thing is certain we will need good, safe and intelligent roads. 

If you want to be part of a dynamic and award-winning start-up and help shape the future 

of mobility - join Valerann! We are developing a unique and ambitious traffic management system which is based on a large scale LPWAN sensor array. We ingest streams of data in our cloud environment; we run machine learning algorithms to identify various traffic issues and feed them back in real time to vehicles and road operators. We have made huge progress, but we need your help to move to the next level. 

Our London based team is looking for a talented, experienced and hard working data scientist. Your primary focus will be analysing our data and developing machine learning algorithms to detect and predict various traffic issues and road conditions. 

Proven experience that we are looking for: 
 

Experience in data science: processing of real-time geo-spatial time-series data, using machine learning algorithms - clustering, regression, classification, deep learning. 

Experience in research and development in Python using libraries such as: numpy, pandas, scikit-Learn, tensorflow. 

Highly proficient in SQL using databases such as PostgreSQL, MySQL, Athena, Redshift 

Experience in big data processing using Kafka, Spark, Hive (or similar technology) 

Developing user facing visualisation of our data and insights 

Using high quality processes and tools (Github, Jira, Anaconda, D3JS, Grafana) 
 

You should be 
 

A person who likes to work in a startup environment: dealing with uncertainties, working in a small team, taking initiatives, and finally, committed to our mission. 

Someone who is passionate about transportation, excited about our vision, and would like to improve the safety and efficiency of our roads systems. 

Someone who is not afraid of challenges and enjoys engineering complex systems 

Someone who can identify MVP and develop the right product. 
 

Bonus: 
 

PhD degree in Computer Science or a related technical discipline, or equivalent practical experience. 

Experience in signal processing: Filters, Spectral analysis, Matlab. 

Developing backend and frontend code in Javascript using frameworks such as React and NodeJS. 

AWS cloud/Linux environment: IoT, Lambda, Docker and tools such as Terraform 

Implementing security and data protection best practices 

Experience in IoT, LoraWAN, Wireless networks 
 

Location: London/Camden 

*The company is an equal opportunity employer 

Job Type: Permanent",Undefined,indeed,930910782e5cb8c47a5b910cbfd4db23
Lead Data Scientist - Relocation to Saudi Arabia - Saudi Nationals,Scientific,Center for Combating Extremist Ideology,#N/A,#N/A,United kingdom,2019-06-16,"THIS ROLE IS BASED IN RIYADH, KSA. SAUDI NATIONALS.  


JOB PURPOSE  

We are looking for a Lead Data Scientist to work with the Etidal innovation Lab within the Global Center for Combating Extremist Ideology. You will manage the design and development of machine-learning models. Work collaboratively with other functions to group the efforts of the teams towards the achievement of Etidal’s campaigns, projects, and programs. 


RESPONSIBILITIES  
 


Strategic  

Contribute to the development of the directorate’s strategic plans. 

Continuously monitor the performance of team members to ensure performance deviations are identified in a timely manner, and actions are implemented to meet performance targets. 


Operational  

Collaborate with data analytics and multimedia forensics leads to understand their requirements. 

Collaborate with data science, software development and CE digital solutions leads to ensure the proper translation of ideas and prototypes into full fledge solutions. 

Develop the data science plans, ensure its alignment with the directorate’s strategy, and manage its implementation. 

Supervise the data science team throughout the day-to-day operations. 

Supervise the analysis and evaluation of applicable emerging data science technologies, and provide technical expertise in adopting technologies related to data science. 

Manage the conceptualization, design and development of machine learning and data mining models. 

Ensure the completion of activities on time, within budget and with quality. 

Where applicable, work hand in hand with all relevant stakeholders to understand execute counter extremism and tolerance interventions scope and objectives and execute accordingly. 

Keep up to date with latest trends and technologies in the data science field, and provide technical recommendation to improve work activities. 


Policies, Procedures and Systems  

Provide input to support the development of directorate systems, policies, processes, and procedures. 

Ensure team members’ compliance and adherence with all policies, processes, standard operating procedures so that work is carried out in a controlled and consistent manner. 

Ensure team members’ compliance with law (e.g. copyright and data protection). 


Reporting  

Report to the Director/Engagement Manager on the progress of activities against the operational plans, opportunities, challenges and issues faced, mitigations taken, etc. as required, to make an informed decision. 

Propose recommendations/alternatives basis analysis to senior-level management and provide direction on areas needing additional research or improvement. 


People Supervision  

Work hand in hand with the direct reports to develop their personal development plans. 

Conduct and review performance appraisals for direct reports to identify areas of development and areas of strength. 

Identify the workforce, recruitment, training and developing needs to ensure the availability and readiness of competent, qualified and highly motivated staff. 

Contribute to fostering an inclusive workplace where diversity and individual differences are valued and leveraged toachieve the vision and mission of Etidal. 

Help in building a learning organization that will continue to grow, flourish and enhance the skills and abilities of employees. 

Create an environment that facilitates healthy relationships among all team members. 
 


QUALIFICATIONS  
 

Bachelor’s degree in Statistics, Mathematics, Computer Engineering, Computer Science or any other relevant field. Master’s degree in any relevant field is a plus 

Minimum of 7 years of experience in a similar role, 2 years of which are in a managerial role. 
 


EXPERIENCE &amp; KNOWLEDGE  
 

Master Arabic Natural Language Processing, Arabic Language Text Mining and Opinion mining concepts. Knowledge of Voice and Image Recognition is a strong plus. 

Master statistical data analysis and data mining techniques and their practical applications and interest of opinion mining techniques. 

Experience in programing languages such as Python (preferred) or packages such as SAS, Matlab, SPSS, R is a must. 

Knowledge of database programing (SQL) &amp; NoSQL. 

Knowledge of Deep Learning is a must. 
 


SKILLS &amp; ABILITIES  
 

Ability to adapt to new ideas and learn new techniques and their practical application. 

Ability to interact successfully with others to learn and teach new skills. 

Ability to organise and prioritise own work with minimal supervision. 

Ability to write technical reports and master the process of developing a whole model from data handling to production. 

Excellent communication skills 

Self-motivated individual interested in developing new ideas and concepts. 
 

Job Types: Full-time, Temporary, Contract 

Experience: 
 

Management: 2 years (Preferred) 

Data Science: 7 years (Required) 
 

Language: 
 
Arabic (Required)  

Relocation: 
 
Saudi Arabia (Required)",Undefined,indeed,a40bf26a333028d6d11029f24a09347a
Data Scientist,Computer,Valerann,#N/A,#N/A,United kingdom,2019-06-16,"Nobody can predict how we will use vehicles in 10 years. Are all vehicles going to be self-driving? Is traffic going to be controlled from a central system or distributed? Are we going to own cars at all? Whatever the future of autonomous vehicles will be, one thing is certain we will need good, safe and intelligent roads. 

If you want to be part of a dynamic and award-winning start-up and help shape the future 

of mobility - join Valerann! We are developing a unique and ambitious traffic management system which is based on a large scale LPWAN sensor array. We ingest streams of data in our cloud environment; we run machine learning algorithms to identify various traffic issues and feed them back in real time to vehicles and road operators. We have made huge progress, but we need your help to move to the next level. 

Our London based team is looking for a talented, experienced and hard working data scientist. Your primary focus will be analysing our data and developing machine learning algorithms to detect and predict various traffic issues and road conditions. 

Proven experience that we are looking for: 
 

Experience in data science: processing of real-time geo-spatial time-series data, using machine learning algorithms - clustering, regression, classification, deep learning. 

Experience in research and development in Python using libraries such as: numpy, pandas, scikit-Learn, tensorflow. 

Highly proficient in SQL using databases such as PostgreSQL, MySQL, Athena, Redshift 

Experience in big data processing using Kafka, Spark, Hive (or similar technology) 

Developing user facing visualisation of our data and insights 

Using high quality processes and tools (Github, Jira, Anaconda, D3JS, Grafana) 
 

You should be 
 

A person who likes to work in a startup environment: dealing with uncertainties, working in a small team, taking initiatives, and finally, committed to our mission. 

Someone who is passionate about transportation, excited about our vision, and would like to improve the safety and efficiency of our roads systems. 

Someone who is not afraid of challenges and enjoys engineering complex systems 

Someone who can identify MVP and develop the right product. 
 

Bonus: 
 

PhD degree in Computer Science or a related technical discipline, or equivalent practical experience. 

Experience in signal processing: Filters, Spectral analysis, Matlab. 

Developing backend and frontend code in Javascript using frameworks such as React and NodeJS. 

AWS cloud/Linux environment: IoT, Lambda, Docker and tools such as Terraform 

Implementing security and data protection best practices 

Experience in IoT, LoraWAN, Wireless networks 
 

Location: London/Camden 

*The company is an equal opportunity employer 

Job Type: Permanent",Undefined,indeed,e651b7b2706c7aaa3d2d8a9c66d29d46
Data Scientist,Manufacturing,MBN Recruitment Solutions,Glasgow,Glasgow city,United kingdom,2019-07-04,"Data Scientist – Glasgow
  


£40,000-£45,000 per annum  


Data Science at its core, has always been able to deliver what some would consider the impossible and this organisation can say hand on heart they are doing just that. 


My client is a dynamic start up based in the heart of Glasgow, looking for a Data Scientist to help them on their endeavour to bring their ‘digitisation’ of the scientific method out of smaller research facilities and to the globe. 


By ingesting and processing large volumes of data, they have been able to deliver a fully functioning solution that for the first time in centuries, allows scientists to do more with their experiments. 


Through this unique hardware and software combination, this young and vibrant technology company need people a Data Scientist the same desire to implement change. 



You will need:  
 

Python programming experience 

Some exposure to an object orientated programming language (Java, C++ or equivalent) 

A good broad understanding of machine learning techniques 

Solid academic credentials or relevant experience (or both) 

A good communicator, who can articulate solutions to various audiences 
 

In return, they will offer you a competitive salary, great holidays and the chance to work in complete harmony with their Lead Data Scientist, giving you the autonomy to deliver on projects without the red tape. This is a chance to get on board with a company that is really doing something different, right at the start of their amazing journey. 


Interested? Then I want to hear from you. Apply via the advertisement for more information or drop me a line in the strictest of confidence.",Undefined,indeed,fbbdfc61ce1e5e35979b655bd7f573da
Sr. Data Scientist,Customer-Service,Oracle,United,Pennsylvania,United states,2019-07-13,"Sr. Data Scientist-19000I1A

Preferred Qualifications

Every day at Oracle we are changing the way the world does business by challenging the status quo through the delivery of innovative cloud, infrastructure and data solutions. The things we do at Oracle have never been done before and it has a tremendous impact on millions of people across the globe. Oracle continues to push the boundaries of technology and passionately believes that modern cloud computing allows businesses to innovate faster by helping them realize and capitalize on new opportunities. The largest names in technology and global business rely heavily on Oracle products to thrive in competitive markets.

The EPM SaaS team at Oracle is committed on providing the best in breed SAAS solutions to enable customer to do their Budgeting/Planning, Consolidation and Reporting activities. This particular team focusses on Reporting and Analytics domain to help customers handle their Management, Statutory and Narrative Reporting needs. We primarily source data from our Planning and Consolidation Apps which are multi-dimensional in nature. We also support full office integration for other proprietary sources of data.

We are currently focusing on exposing the intelligent auto-narrative generation and anomaly/variance detection mechanisms to take Reporting Analytics to the next level and this is where we are looking for someone with right skills and attitude to come join our team of amazing engineers.

This position requires a Master’s degree (or PHD) and 6+ years of experience in AI/ML. In this role, you will have the opportunity of working in a team of top-notch engineers to deliver world class software. You should come prepared to learn a lot and help define and drive initiatives in a strong team that is helping Oracle become the #1 cloud provider in the world.

Responsibilities

Spearhead the AI/ML initiatives in our team

Collaborate to create well-thought-out software designs

Write good, testable and maintainable code in Java that meets the requirements

Collaborate with consumers and other team members to collect, understand and solve problems

Qualifications

Highly experienced AI/ML expert

Prior experience in NLP is preferable

Understanding of Java and related technologies

Experience writing well-maintainable RESTful web services

Real experience with testing, code review

Have spent time as part of an agile development team

6+ years of industry experience

MS/PHD in computer science or related field.

Detailed Description and Job Requirements

Design, develop, troubleshoot and debug software programs for databases, applications, tools, networks etc.

As a member of the software engineering division, you will take an active role in the definition and evolution of standard practices and procedures. You will be responsible for defining and developing software for tasks associated with the developing, designing and debugging of software applications or operating systems.

Work is non-routine and very complex, involving the application of advanced technical/business skills in area of specialization. Leading contributor individually and as a team member, providing direction and mentoring to others. BS or MS degree or equivalent experience relevant to functional area. 7 years of software engineering or related experience.

Oracle is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability and protected veterans status or any other characteristic protected by law.",Undefined,indeed,a7737cb2ddb617e2db3157bcd6617bcf
Data Scientist - Survey Methodology and Computational Social Science,life physical and social science,Facebook,Seattle,Washington,United states,2019-07-04,"Facebook's mission is to give people the power to build community and bring the world closer together. Through our family of apps and services, we're building a different kind of company that connects billions of people around the world, gives them ways to share what matters most to them, and helps bring people closer together. Whether we're creating new products or helping a small business expand its reach, people at Facebook are builders at heart. Our global teams are constantly iterating, solving problems, and working together to empower people around the world to build community and connect in meaningful ways. Together, we can help people build stronger communities - we're just getting started.Marketing Science R&D is an interdisciplinary team of data scientists focused on research that improves measurement and ads delivery on our platform. The team's expertise spans domains, including causal inference, survey methodology, machine learning, cryptology, location and identity prediction algorithms. We develop methodologies, design and prototype solutions, and partner with our engineering and product colleagues to scale these solutions such that millions of advertisers can benefit.We're looking for researchers and data scientists with expertise in survey methods and computational social science that can develop new methodologies and frameworks to build robust inferences from survey data we can receive from billions of people across our platforms. Team members will pursue deep technical knowledge of our ads, measurement and survey infra systems at Facebook, and develop robust and creative frameworks to leverage anonymized response data to power new and enhance existing measurement and ads delivery systems.Required SkillsResearch opportunities to develop and implement new methods or algorithms for survey collection and inference to improve ads delivery and measurement for advertisersAssess the validity and rigor of new data sources and approaches, establishing scalable validation frameworks for ongoing evaluationWork both independently and build cross-functional relationships with Engineering, Product and Analytics to shape long-term product roadmaps with a balance of technical rigor and strategic considerationsLearn new tools, systems and languages quickly as required by the particular project you are working onApply communication skills to engage diverse audiences on technical topics and nuanced insights Job Requirements Minimum qualificationPhD in Economics, Political Science, Sociology, Communication, Psychology, or related field, or a Master’s within one of these fields combined with 3+ years of hands-on research experience in the social or biomedical sciences, internet or advertising industry architecting and implementing survey methods-focused solutionsExperience with survey methodology, survey experiment design, and analysis of survey experimentsKnowledge in survey methodology-related patents, conference presentations, academic papers or other indicators of research experience in industry-grade survey methodologyExperience addressing challenges that emerge from missing or unrepresentative dataKnowledge with Python and/or RDevelopment experience for Bayesian modeling leveraging Stan or JAGSPreferred qualificationExperience with online advertising, targeting, optimization and measurement systemsKnowledge of machine learning and advanced statistical modelingExperience with Presto, Hive or Spark SQLExperience leveraging large-scale demographic, behavioral or social network data to derive valuable inferencesFacebook is proud to be an Equal Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Facebook is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.",Full Time,careerbuilder,d077a8521bc4e95b6f5e88a8a910a9ac
Senior data engineer,IT,Rakuten,India,Madhya pradesh,India,2019-07-20,"Role

Senior Software Engineer (Regular Employee)

Position Summary

Are you interested in building the next generation of Internet services that touch hundreds of millions of users across the globe every day?

Rakuten is one of the leading e-commerce companies in the world. Our mission is to empower people and society through the Internet, and we aim to become Global Innovation Company.

The Technology Division at Rakuten is the IT powerhouse for the Group’s business. In the Technology Division, you will join a diverse global team and play a central role in our technology innovations.

Aligning with the Division's innovation nature, the Ecosystem Service Department (ESD) is thinking big: we build scalable platforms that powers the Rakuten Group worldwide.

Our team contributes to management in ESD, the Group businesses, and the Headquarters by providing them actionable insights from service data. We manage an analytics platform that provides well-formed data to managers and executives to drive decision making. If you are interested in providing business-oriented people with data-driven shikumis (systems), please come talk to us!

Responsibilities

Contribute to the team and group strategy by tactically driving activities to continuously improve the batch-processing / streaming data pipelines and surrounding systems supporting them to keep the data pipelines healthy based on a defined service level

Make technical design decisions on the systems by investigating and analyzing facts

Make agreements about your decisions among the stakeholders by negotiating with them

Design, develop, deliver, and manage the systems and the processes by analyzing them to drive improvements in order to maintain the expected levels of service

Discover new technologies, analyze them, perform feasibility studies, design and develop the solution and deliver it

Coach team members to drive the system development and improvement activity

Qualifications

Basic Qualifications

B.S. in Computer Science or in related fields, or equivalent education and experience

5+ years in total of experience in designing, developing, building and ongoing support of FIVE OR MORE of following types of systems:

Batch-processing data pipelines (or so-called ""ETL"") composed of Airflow, Digdag, Argo Workflow, Informatica, etc.

Streaming data pipelines composed of subsystems such as Apache NiFi, Apache Kafka, so-called ""ELK stack,"" Splunk, etc.

Applications leveraging so-called ""Big Data"" systems such as Hadoop, Hive, Spark, etc.

Data visualizer and analyzer systems like Domo, Tableau, Power BI, Microstrategy, Superset etc.

Web application backend systems composed of load balancers, Apache web server / Nginx, MySQL / PostgreSQL, Tomcat / Ruby on Rails, etc.

Applications integrating container hypervisors or container orchestrators such as Docker, LXC, Kubernetes, Apache Mesos, etc.

Systems that have high service level objectives/agreements (SLOs / SLAs.)

Deployment pipeline composed of systems such as Jenkins, Concourse, etc.

5+ years of experience in developing in TWO OR MORE of following programming languages and building ecosystems (if applicable)

Java and its building ecosystems such as Ant, Maven or Gradle

Scala and its building ecosystems such as SBT

Python and its building ecosystems such as Pipenv

Shell Scripts

5+ years of development or operational experience in Linux systems

Preferred Qualifications

M.S. in Computer Science or in related fields, or equivalent education and experience

Experience working with data or statistical analytics

Experience in leading the team activity of two or three team members

Language Level

English: Business Level (TOEIC score over 800 or equivalent)

Japanese: Optional",Undefined,indeed,89cea6e54e05ce0ff410920e98fd5f1f
Business Intelligence Developer / Data Engineer f/m/x,Consulting,MILES Mobility,Berlin,Berlin,Germany,2019-07-20,"MILES is your urban life companion, showing you hidden treasures and the coolest spots - everything that makes the city worth living.

MILES is carsharing for everyone who wants more in life than living it by the minute. Driving with no time pressure, no limits and no specific vehicle types or car brands. Our passion for the new and unexplored drives us in our vision to make urban life better.

#milesnotminutes

These will be your tasks

Our Business Intelligence is driven by the vision to transform MILES to a data driven company in all areas. The goal is an intuitive, correct and complete supply of data for any stakeholder, intern or extern. As a BI-developer in our young team you constantly challenge the status quo together with our analysts with the goal to develop a vision for a holistic and scalable BI-solution. You are a fully involved in deciding and implementing any adjustments in our data infrastructure.

Your key- and most urgent objective will be to create a data warehouse which is reliable and accepted as the “single point of truth” for our company.

Furthermore you support our analysts by creating and enhancing our BI-software. The goal is to provide the most important reports automated as well as self service BI-solutions which are usable and intuitive to everybody.

If you are looking for responsibility and the possibility to shape a BI-solution from day 1, this is the ideal position for you.

You're offering these qualifications

A degree (Bachelor, Master) in Mathematics, Computer Science or similar

1-3 years working experience in relevant fields

You have already gained profound professional experience in building data structures and databases

Ideally, you have very good knowledge of ETL processes

You are fluent in English, German is a plus

Nice to have:

Knowledge in Big Data technologies (e.g. Spark, Hadoop)

Knowledge in Data Science (i.e. Python/Pandas or R)

Knowledge in web tracking

Experience as a backend developer

Experience with BI-tools (e.g. Tableau)

We're offering these benefits

A great working environment in one of Berlins most beautiful offices

The opportunity to grow with no boarders

Great perks, like holiday and software package

Team events and sport on a weekly base",Undefined,indeed,bf5e4539a1de4c1f4ad67079bde33f9a
Junior Data Scientist - Center for Quantitative Drug and Disease Modeling,Engineering-or-architecture,USC,Los angeles,California,United states,2019-07-20,"The USC School of Pharmacy Center for Quantitative Drug and Disease Modeling is seeking applications for a Junior Data Scientist. The Junior Data Scientist is responsible for supporting the management and processing of data used for scientific research purposes for the USC’s School of Pharmacy, while supporting the implementation of clinical/preclinical CDISC-compliant data standards. This position will work extensively with the data analysis team and support efforts that generate clinical and preclinical data in their projects. The Junior Data Scientist will assist with the design and implementation of databases, and utilize vendor and internally-developed tools to review data quality, remap data per existing data standards and support the development of data sub-sets required by research plans.

Essential Job Duties and Responsibilities:

Develop database design and architecture documentation for the Center

Provide insight into the changing database storage and utilization requirements for the Center and offer suggestions for solutions

Analyze database implementation methods to make sure they are in line with the Center policies and any external regulations that may apply

Help maintain the integrity and security of the databases

Create data monitoring models for each project and work with our analysis team to create models ahead of new releases

Work with other data scientists and data analysts to implement descriptive, forecasting and predictive algorithms and models using the latest technologies

Support and collaborate with internal and external collaborations to ensure data delivery architecture is consistent throughout ongoing projects

Continuously improve or re-design data architecture to support the next generation of products and initiatives

Perform complex ad hoc analysis using R, Python and/or SQL as required, working with large datasets including loading them to a database and analyzing them

Experience in clinical/preclinical data management, specifically protocol assessment, case report form (CRF), including annotated CRF, clinical data management system (CDMS), study start up, edit check creation, data validation, database lock, reviewing source data

Work effectively with team members via in-person, teleconference and web meetings

Other duties and responsibilities may be assigned

Minimum Requirements:

Master’s degree in Life Sciences, Data/Computer Science, Management Information Systems or Medical Technology, Business Analytics or related fields

Or Bachelor’s degree with 3+ years’ hands-on experience in the related position

Strong programming skills in R, Python or SAS

Fluency with SQL and Relational Databases

Experience in structured & unstructured data expertise

Knowledge or experience in Cloud based solution or Cloud environment development, e.g. Amazon Web Services (AWS) Cloud and Google Cloud Platform (GCP)

Experience as Data Architect building tables, columns and data warehouse elements

Excellent verbal and written communications

Preferred Experiences:

Master’s degree in Life Sciences, Data/Computer Science, Management Information Systems or Medical Technology, Business Analytics or related fields

Experience with R, Python or SAS coding.

1+ years' experience in industry (pharmaceutical, CRO, biotechnology, healthcare) preferred

Experience in use and manipulation of clinical data sets preferred

Experience designing data pipelines or ETL processes to move data from various internal and external sources into the platform

Experience in development of the Data Management Plan (DMP)

Knowledge or expertise in CDISC standards preferred

Knowledge or expertise in machine learning model for predictive analysis preferred

Knowledge/Skills/Abilities:

Excellent interpersonal skills and problem solving/decision making skills

Excellent organizational skills

Demonstrated negotiation skills

Strong data management skills in R, Python or SAS

Strong programming skills in SQL

Good understanding of data infrastructure and distributed computing principles

Works well independently and in a team-oriented, collaborative environment

Knowledge of clinical/preclinical research industry and familiarity with the clinical drug development process

Ability to effectively manage time, prepare for meetings, and prioritize project work

Travel on occasion for out of town meetings (max 3%)

Math Ability: Commensurate with Bachelor's degree with emphasis on review and analysis of data.

Reasoning Ability:

Exercise sound technical judgment when making decisions and adhere to external and internal policies and regulations

Ability to proactively address issues or challenges without being specifically directed

Use sound judgment when working with critical or confidential information

Minimum Education: Master's degree or combined experience/education as substitute for minimum education

Minimum Experience: 1 year or combined education/experience as substitute for minimum experience

Preferred Education: Master's degree

Preferred Experience: 2 years

Minimum Field of Expertise: Experience in Data Architect, Database Management, Statistics or related field. Experience with R, Python or SAS

Minimum Education: Master's degree Combined experience/education as substitute for minimum education Minimum Experience: 1 year Combined education/experience as substitute for minimum experience Preferred Education: Master's degree Preferred Experience: 2 years Minimum Field of Expertise: Experience in Biostatistics, Statistics or related field. Experience with SAS, R or STATA.",Undefined,indeed,e3778fe2fe7495204f4627d79d99cd50
Data Scientist,Engineering,TalentSpa,Liverpool,Liverpool,United kingdom,2019-07-04,"Salary: £60000 per annum

Reference: LA/DataSc

Data Scientist

Liverpool City Centre, L3 9AG

£60,000 per annum

Pemanent, Full Time

Data Scientist

An award-winning performance and technology business have a fantastic opportunity for a passionate Data Scientist to join their team in Liverpool.

One of the UK and Europe’s fastest growing tech companies, they have been featured in Tech Track 100 (The Sunday Times) and FT1000 (Financial Times) and are the fifth-fastest growing tech company in the north of the UK (Tech Nation).

In the business since 2002, they use their own digital assets, emerging technologies and a unique network of premium UK publishers to find and engage hard-to-reach in-market consumers as they research their next purchase online.

The company specialises in the automotive and property industries, with an extensive client list including BMW, VW Group, Mercedes-Benz, Ford, Hyundai, Yopa and eMoov.

The Data Scientis Role

A fantastic opportunity for an ambitious individual to join The Lead Agency in the role of Data Scientist. Reporting to the Head of Data Insight, the role will be wholly focused on the support and delivery of key Big Data projects across the business. The role holder will work in tandem with technology, R&D and development teams within the business to create statistical learning models that drive key business systems and processes.

As an expert in the application of statistical analysis and data modelling techniques, you will work with internal technology and infrastructure owners to develop data capture, cleansing, enrichment and verification processes to maximise the value of data inflows to the business. You will transform large, unstructured data flows into structured, queryable datasets, and subsequently develop statistical models to systematically interrogate datasets to produce actionable insights. You will leverage your knowledge of and experience with machine learning applications to make applications automatable and self-sufficient.

Data Scientist Responsibilities:

Systemise the collection of unstructured data and systematically transform into queryable dataset via wrangling, cleansing and verification techniques.

Enrich datasets with third-party data where possible and/or necessary.

Optimise data storage and processing architecture, ensuring it is fit-for-purpose for requirements.

Research and develop statistical learning models for data analysis.

Own data projects, leading the development of TLA’s data science and machine learning projects.

Collaborate with product management and technology/development teams to understand company needs and devise possible solutions.

Communicate results and ideas to key decision makers.

Data Scientist Requirements:

A strong degree in a mathematical, statistical or computer science related field (postgraduate preferred)

5 years’ practical experience with data mining and statistical analysis for Big Data, with a track record of delivering actionable, value-adding outputs

Proficiency in statistical analysis, quantitative analytics, forecasting / predictive analytics, multivariate testing, and optimisation algorithms.

Advanced skills in SQL, Python and r, with proficiency with other programming languages (SAS, Java etc.) being beneficial

Strong experience of leading transformational data projects

A strong working knowledge of machine learning theory and application, with demonstrable experience of application in previous roles

Experience working with Big Data frameworks (such as Hadoop, Spark, Cosmos DB or others)

Strong communication and leadership skills

Technically-minded, with an active interest in working with cutting-edge technology

Unafraid to challenge the status quo

Great team worker, able to influence and promote change

Passionate about the detail

Data Scientist Benefits:

Fantastic office culture

Based in a bright, open plan office on the 13th floor of the Unity Building, offering spectacular panoramic views of Liverpool

Flexible working hours (35 Hour Week)

Free personal training and squash games

Subsidised gym membership

Private Healthcare / Pension

Regular nights out and charity events throughout the calendar

Free office bar every Friday!

If you think that you are suitable for this Data Scientist role, please apply now!",Undefined,indeed,d2324ef8858a72e921021f5c38defd3e
(Senior) Data Scientist (m/w/d),Naturwissenschaft,Tchibo GmbH,Hamburg,Hamburg,Germany,2019-06-23,"Aufgaben

Der Bereich BI verantwortet den Tchibo Daten-Wertschöpfungszyklus von der Sammlung über die Speicherung und Auswertung bis zur Nutzbarmachung der insbesondere durch Data Science gewonnenen Erkenntnisse. Dafür greifen wir auf einen großen Bestand von existierenden Daten zurück und evaluieren ständig weitere strukturierte/unstrukturierte Quellen sowie notwendige Technologien, bemessen das Potential und integrieren diese im positiven Fall in unsere Wertschöpfung. Aufbauend auf einem sich parallel in Entwicklung befindlichen hochmodernen BI / Big Data Ökosystems können Sie diese Entwicklung entscheidend mitprägen. Unser Ziel ist es, Konsumenten 360° Omni-Channel zu verstehen, neue Business-Potentiale zu identifizieren und Tchibo mit datengetriebenen Services direkt oder indirekt in Richtung „Data Driven Company“ zu entwickeln. Über agile Vorgehensmodelle entwickeln wir dazu Proof-of-Concepts, identifizieren Quickwins und bauen diese sukzessive zu hochverfügbaren datengetriebenen Services aus.

Anforderungen

Sie brennen für das Thema Data Science. Sie besitzen das Talent, kreative Lösungsstrategien zu entwickeln und so Fragestellungen zielgerichtet zu beantworten.

Abgeschlossenes Studium der Mathematik, Informatik oder vergleichbare Qualifikation mit statistischem Schwerpunkt

Fundierte Erfahrung im Bereich Softwareentwicklung, insbesondere im agilen Umfeld (Jira, GitLab, Jenkins, Confluence etc.)

Mindestens drei Jahre Erfahrung in der Entwicklung von Data Science Modellen (Validieren, Aufsetzten von Testprozessen, etc.) auf verteilten Systemen (R, Python, Scala oder vergleichbare Umgebungen) in business-relevanten Fragestellungen, bestenfalls im Retail und/oder Online B2C

Erfahrung in Design und Implementierung von Machine Learning Modellen und Modell-Pipelines mit Fokus auf Supervised Learning z.B. für zeitreihenbasierte Prognosen oder Text-Klassifikation sowie Erfahrung mit dem Hadoop Ökosystem, insbesondere Apache Spark

Überdurchschnittliche analytische Fähigkeiten gepaart mit Kommunikations- und Umsetzungsstärke

Wir freuen uns auf Ihre Online-Bewerbung jetzt viel leichter ohne Anschreiben!

Ihr Ansprechpartner ist Markus Wittlake.

Für Fragen kontaktieren Sie gern unseren Recruiting Support +49 40 6387 3353.",Undefined,indeed,cb93d2104a849876e2f2d7c3341795bd
Data Scientist..,Scientific,Akamai,Bangalore,Karnataka,India,2019-06-23,"Bengaluru, Karnataka

If you have a deep passion for data and security, love handling massive data sets, and get excited from solving hard problems, Akamai is the place for you. We are seeking a highly motivated Threat Operations Analyst who will work with Engineering and Product Management teams to quickly resolve highly technical, complex issues, and advocate for real-world customer use cases, features, and functionality. You will apply your practical analytical skills and your experience with statistical analysis to derive actionable insights from large volumes of data.

Join a fast-paced team in Akamai’s Security Unit charged with protecting the largest brands against the unpredictable landscape of evolving botnets and malware. Bad actors might build massive botnets or new automated attack systems; you’ll help dismantle and cripple them in real, internet time.

About the Team

The web security team is focused on leveraging Akamai's core strengths of its highly distributed cloud-based platform that already serves up to 30% of the traffic on the web and the massive amount of HTTP data it has access to as a result to define industry leading web security products that provide rapid visibility and control for protection against constantly changing attack profiles.

Responsibilities

 Investigate the most sophisticated bots from across the Akamai’s customer base

 Tuning detection algorithms for best fit for a particular customer traffic pattern.

 On-going monitoring and measurement of the effectiveness of bot detection algorithms

 Build tools for automated analysis

 Keep abreast of current malware, botnets, or other automated agent trends and provide insights for further product enhancements

Required Education and Experience:

 BS or MS in Computer Science, Applied Math, Statistics, Data Science or relevant subject

 3 years experience in Data analysis

 3 years experience in Python programming

 3 years experience in SQL.

 3 years experience working on Unix platform

 2 years experience with various open source data analytic packages such as Pandas, numPy, Matplotlib, etc

Desired Qualifications:

 Strong verbal and written communications skills; experience presenting complex technical information, succinctly, to technical and business audiences.

 Data visualization skills to translate complex models and analysis results into layman terms.

 Experience, familiarity and ease with handling large, messy data sets. Prior experience with AWS Athena is a plus, but not required.

 Experience in Javascript debugging.

 Understanding of Proxies, DNS, HTTP protocol, Browser Rendering engines.

 Familiarity with AWS and Big Data Technologies like EMR or Spark is a plus, but not required.

 Bot detection experience is a plus

 Interest in Machine Learning, specifically anomaly detection and data mining

 Interest in Web Application security",Undefined,indeed,4ccc32c233fda06df750fa3d2c91e736
Data Engineer,IT,Die Mobiliar,Bern,Bern,Switzerland,2019-07-10,"Sie wollen auf grüner Wiese bauen und so die Systemlandschaft der Mobiliar nachhaltig prägen? Dann gestalten Sie mit uns die Zukunft – per sofort oder nach Vereinbarung bis 31.12.2019 mit Aussicht auf Verlängerung als Data Engineer Metadaten am Direktionsstandort in Bern mit einem Arbeitspensum von 60-80%.

Ihre Aufgaben

Sie helfen uns das Datenmanagement auszubauen und entwickeln Datenzugriffsapplikationen für das Meta-Datenmanagement.

Bei der Entwicklung und Visualisierung von Datenkatalogen helfen Sie mit.

Mit den Spezialisten für Datenqualität, Data Curation, Informationssicherheit und Datenlogistik arbeiten Sie eng zusammen.

Sowohl auf Stufe der Software-Entwicklung als auch mit dem Management kommunizieren Sie zielgruppengerecht.

Ihr Profil

Eine höhere Aus- oder Weiterbildung in Informatik (oder vergleichbar) haben Sie abgeschlossen.

Sie haben Kenntnisse im Datenmanagement.

Erfahrungen in der Software-Entwicklung mit besonderem Fokus auf Daten haben Sie bereits gesammelt.

Die deutsche Sprache beherrschen Sie in Wort und Schrift.

Ihr analytisches Denken und gute Kommunikations- und Präsentationsfähigkeiten zeichnen Sie aus und Sie behalten auch in einem komplexen Umfeld den Durchblick.

Haben wir Ihre Neugier geweckt? Sprechen Sie diese Herausforderungen an? Dann freuen wir uns, Sie kennen zu lernen.

Bei Fragen stehen Ihnen Frau Andrea Küffer, Recruiting & Sourcing, Telefon 031 389 63 43 oder Bruno Russiniello, Systemplattform und Daten-Architektur, Telefon 031 389 71 67 gerne zur Verfügung.",Undefined,indeed,674bbe9121e1c767758ca8ab28da3f81
Data Scientist (w/m/d) mit Schwerpunkt Text Mining,Computer and Information Research Scientists,Deutsche Bahn,Frankfurt,Hesse,Germany,2019-07-28,"Was Dich erwartet
 Wenn es darum geht, zukünftig Millionen Fahrgäste und tausende Züge auch digital auf den Weg zu bringen, braucht es die besten IT-Experten. 8.000 haben wir schon, aber längst nicht genug. Als Projektleiter, Berater, Entwickler oder IT-Architekt ist jetzt die spannendste Zeit einzusteigen und in einem starken Team wegweisende Lösungen und Großprojekte in den Bereichen Mobilität, Infrastruktur und Logistik umzusetzen.
Deine Aufgaben
Zum nächstmöglichen Zeitpunkt suchen wir Dich für die DB Fernverkehr AG am Standort Frankfurt am Main.
 Deine Aufgaben:
Als Data Scientist (w/m/d) mit Schwerpunkt Text Mining arbeitest Du in einem Team an der Weiterentwicklung des Kundenfeedbacksystems.
Dabei stellst Du dessen Qualität sicher und präsentierst die Erkenntnisse daraus vor Fachbateilungen und Entscheidungsträgern.
Du setzt Analyseergebnisse mit Daten aus bestehenden Datenbanken und Monitoringsystemen für Reisendenströme und -umsätze der DB Fernverkehr AG in Zusammenhang.
Weiterhin entwickelst du die Visualisierungen für Textzusammenhänge un deren Kernaussagen.
Du bist verantwortlich für die Weiterentwicklung und Verbesserung von bestehenden Java-basierten Clustering- und Klassifikationsmodellen.　
Du optimierst bestehende Algorithmen zur Anwendung in einer parallelisierten Umgebung (z.B. Apache Spark).
Darüber hinaus entwickelst Du Visualisierungen für Textzusammenhänge und deren Kernaussagen.
Du experimentierst mit neuartigen Lernverfahren, wie z.B. Deep Learning im Kontext von Chat Bots.
Qualifikationen
 Dein Profil:
Du hast einen (Fach-)Hochschulabschluss oder eine Promotion in einem mathematischen, natur- oder ingenieurwissenschaftlichen Studiengang, mit Schwerpunkt Machine Learning und insbesondere Text Mining.
Darüber hinaus hast Du bereits sehr gute Erfahrungen in der Programmierung in Java und SQL sowie erste Erfahrungen mit Apache Spark und dem Hadoop Ökosystem.
Idealerweise hast Du mehrjährige Berufserfahrung in einem ähnlichen Gebiet.
Du hast Spaß an der Arbeit mit großen Datenmengen und zeigst Kreativität bei der Datenbeschaffung, Analyse und der Visualisierung deiner Ergebnisse.
Weiterhin behältst du den Überblick über die notwendigen Details aber auch über die Einordnung der Analysen und Handlungsempfehlungen in den größeren Geschäftskontext.
Dein hoher Anspruch an die Qualität der eigenen Arbeit und eine verantwortungsbewusste Arbeitsweise sind für Dich genauso selbstverständlich wie deine Kommunikationsstärke.
Neugier für versteckte Korrelation und Zusammenhänge sowie ein Eigeninitiative verbunden mit einem Dienstleistungsgedanken gegenüber Anwendern runden Dein Profil ab.",Full Time,jobs_de,356faf0e11af8f4c7002082519d5654d
Data Scientist - EMEA,Architecture,Harnham,London,#N/A,United kingdom,2019-07-27,"Data Scientist - EMEA  



London  



£50,000-£70,000  


As a Data Scientist, you will take charge of all advanced data science, AI and machine learning modelling. This is an opportunity to join a pure R&amp;D technology company pioneering data solutions to the most challenging and interesting business problems. 



THE COMPANY:  


A cutting-edge tech start-up focusing on hyperpersonalisation software product for financial services. One year ago, this company was 20 people, they have now expanded to over 100 people and counting. 



THE ROLE:
  

You will be exploring and experimenting with machine learning techniques and playing around with large rich data sets of customer behaviour and location data using Python, NoSQL and AWS. 
 


Experimenting with advanced statistical and machine learning techniques in Python 


Using Python and NoSQL to design proof of concepts for state-of-the-art techniques 


Building customer reports, using Python, to produce valuable insights for their massive clients 


Taking ownership and being the technical lead for projects - delivering highly technical concepts to non-technical clients (stakeholders and managers) 
 



YOUR SKILLS AND EXPERIENCE:  
 


Extensive knowledge and use of Python for machine learning, NoSQL is essential; AWS experience is desirable 


You will have built machine learning models and had them productionised in industry 


Proven commercial experience exploring and applying machine learning techniques to big data using Python 


The successful data scientist will have commercial experience using machine learning techniques on location data, using GIS 


The ideal candidate will have experience in communicating heavily technical concepts in an effective way and have experience delivering these to non-technical stakeholders 
 



THE BENEFITS:  
 


£50,000-£70,000 


Meet ups/conferences 
 



HOW TO APPLY:  


Please register your interest by sending your CV to Kian Dixon via the Apply link on this page. For more information about similar roles, please get in touch!",Undefined,indeed,4cc26895f94876e9554da57cf6c6e549
Customer Insight Data Scientist,Scientific,Harnham,London,#N/A,United kingdom,2019-07-27,"Customer Insight Data Scientist

London

£60,000-70,000 + benefits + bonus

Join a brand-new Greenfield team with the vision to drive innovation solely! As a Customer Insight Data Scientist, you will pioneer creativity, R&D and building cutting-edge machine learning products off the back of this. You will be working in a start-up environment, within a larger company, promoting collaboration of state-of-the-art approaches to data science.

THE COMPANY:

This global retail company are investing heavily into finding a Customer Insight Data Scientist to join a company using advanced data science techniques. With a clear vision and business plan, this company are focuses on understanding their customers better than anywhere else - making a slicker and more efficient customer experience. You will also receive endless training and learning opportunities, including conference budgets, collaboration sessions and online courses are encouraged.

THE ROLE:

As a Customer Insight Data Scientist, you will get the opportunity to play around with huge data sets - made up of instore and online data - to produce bespoke machine learning models.

Day to day you would be analysing large amounts of customer data in Python or R, using machine learning techniques to produce valuable insights for the business around their consumers.

Providing internal consultancy for the customer science team across all business areas and liaising with teams across the country.

Exciting side projects include working with new data sets and natural language processing (NLP) techniques.

YOUR SKILLS AND EXPERIENCE:

The successful Customer Insight Data Scientist will have extensive knowledge and commercial use of SQL and Python/R

Experience performing machine learning techniques in industry, using Python, and NLP for personalisation

Knowledge and/or use of AWS

The ideal candidate will have commercial experience in customer and/or marketing analytics and delivering technical insight to non-technical stakeholders

THE BENEFITS:

£60,000-£70,000

Generous bonus

Hackathons

Opportunities to have side projects implemented

HOW TO APPLY:

Please register your interest by sending your CV to Kian Dixon via the Apply link on this page. For more information about similar roles, please get in touch!",Undefined,indeed,f0efcbe4cf380c8b583a9d80876b0c7c
Senior Data Scientist,Computer,Bank of Ireland,#N/A,#N/A,Ireland,2019-06-29,"Description of business unit

The Data Solutions & Analytics portfolio was set up in September 2018 to enable Group Internal Audit to drive further independent insight and opinion through the provision of data driven products and capabilities. The Data Solutions & Analytics portfolio is a new function within Group Internal Audit with the responsibility for:

Design and execution of the division's data and analytics strategy

Design, development and deployment of Group wide advanced analytics risk management and assurance solutions.

Provision of data and model risk assurance for the Group, including transformation assurance on key strategic programmes.

Buildout and development of GIA's strategic analytics architecture; and

Driving the capability and training strategy to embed data and analytics skills across GIA.

The role holder will deliver end to end projects within the data and analytics strategy, utilising Agile principles and contribute towards driving Group Internal Audits utilisation of advanced analytics techniques (such as machine learning and natural language processing) to drive risk management activities across the Group.

Purpose of the Role

This is a cross functional individual contributor role to lead the technical solution delivery for analytics projects, realising value of the Groups data. You will design, develop and deliver solutions to teams across Group Internal Audit utilising data from across the Group, and using the latest technologies in data exploration, modelling and visualisation. You will have an opportunity to partner with the business on a wide range of projects, collaborating on appropriate ways of working and proposing new methodologies. You will contribute more broadly to the achievement of Group Internal Audit strategic plans and priorities.

Key Accountabilities

Lead the design and development of multi-component analytical solutions and advanced modelling capabilities, from initial engagement workshops through to solution deployment

Lead sophisticated and complex research projects and analysis (e.g. natural language processing, graph analytics, clustering etc.) for senior management to drive business insights and proactive risk management across the Group

Lead innovation projects across the portfolio, utilising data science techniques and methodologies to inform decisions to drive enhanced risk management and insight across the Group

Drive experimental rigor within the function by leading high value, high visibility projects and pilots.

Design and development of strategic management information solutions to present data driven insights to senior management

Contribute towards Group Internal Audits data & analytics strategy and the Data Solutions & Analytics portfolio through the identification of new value add data exploitation and continuous improvement opportunities

Promote awareness of data analytics, emerging industry trends (incl. regulation) and a digital future across Group Internal Audit

Collaborate cross-functionally (with other teams within Group Internal Audit, and across the wider Group) to refine recommendations and develop next best action plans for risk management.

Contribute to a creative culture centred on an agile environment, value prioritisation and design thinking

What is the opportunity?

The successful applicant will have the opportunity to help drive the execution of GIA's multi-year data and analytics strategy, with a view to embedding data driven risk management solutions across the function.

Essential Qualifications

Third Level qualification, in computational science, computer science, mathematics, statistics or another discipline including a significant quantitative element

Essential Skills & Experience

5+ years' experience in the end to end development of business relevant data science solutions

Proficient in applying supervised and unsupervised machine learning methods such as logistic regression, decision trees, neural networks, graph analytics, clustering etc. to real world business problems

Proficient in leveraging applied statistics and mathematics to test complex hypotheses across a wide variety of functional domains

Experience in developing and validating machine learning models through SAS Enterprise Miner, Python, R, pySpark etc.

Proficient in the development of data science solutions in one or more of the following functional domains: risk, anti-money laundering, IT, finance or marketing/customer analytics.

Proven experience in leveraging SQL to acquire, transform and extract insights from large scale complex datasets

High level of discretion, capable of dealing with highly confidential and sensitive information

Excellent time management and organisational skills with the ability to work on own initiative

Strong attention to detail and high levels of accuracy and a strong team ethic and flexible approach in order to meet challenging objectives and deadlines

Key Competencies

Amplify Capability: People Manager

Accountable: Self

Champion Transformation: People Manager

Manager Risk: People Manager

Agile: People Manager

Desirable Qualifications, Skills & Experience

Experience in applying analytical techniques to semi-structured and un-structured datasets

Knowledge of the Cloudera Hadoop platform, and associated analytical tools (i.e. pySpark)

Bank of Ireland Group is an equal opportunities employer and is committed to fostering an inclusive workplace which values and benefits from the diversity of our workforce.

Where Agency assistance is required Bank of Ireland Recruitment Team will engage directly with suppliers. Unsolicited CVs / profiles will not be accepted for this role.",Undefined,indeed,6a293361941d3568fb4080dbdeb968f4
Senior Data Engineer,Computer,Johnson & Johnson Family of Companies,#N/A,#N/A,Ireland,2019-06-29,"The Johnson and Johnson, EMEA Software Development Centre, are currently seeking an Data Engineer to join our team. We develop, design and deliver high quality business applications, software solutions and services to meet J&J business technology requirements.

The offices are newly designed, specifically to accommodate Scrum development and are based on the University of Limerick Campus. It is an open and highly collaborative environment based on LEAN principles with a strong emphasis on continuous integration, automated testing and continuous delivery. Scrum teams are encouraged to be self-organising and autonomous.

Responsibilities:

Playing a lead role in software design, architecture, requirements analysis, investigation of leading edge technologies, and software development.

Collaborating with the core development team and the product owner to define and estimate business requirements and then translate these into specific software tasks.

Collaborate as a member of an agile team to get products developed and completed with best in class software development.

Design, build, and maintain high performance, reusable, and reliable ETL packages.

Ensure the best possible performance, quality, and responsiveness of applications developed.

Qualifications

Requirements:

5+ years’ experience of development of ETL packages.

Strong technical knowledge of Enterprise Data Warehouse, database design and Information Management.

Experience with Informatica Power Center in designing and developing complex ETL packages.

Experience with writing and debugging complex SQL queries

Experience in designing and developing data models

Experience in real/near time data load using Informatica CDC (Change Data Capture)

Knowledge and experience with Gemfire, IMDG, Big Data, Hadoop, Kafka and Spark.

Experience with Java and Spring – Spring Cloud, Spring XD and Spring Batch.

Strengths:

Possess a basic understanding of agile development methodologies, specifically Scrum and Kanban.

Excellent written and verbal English skills.

Preferred qualifications:

BSc. or Master's degree in Computer Science or related technical field.

Solid understanding of information management, data modeling, system integration, development methodologies (including unit testing) and web technologies.

Excellent interpersonal and communication skills and an ability to work effectively with teams.

Strong analytical skills and a demonstrable bias toward action.

Johnson & Johnson is an Affirmative Action and Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, colour, religion, sex, sexual orientation, gender identity, age, national origin, or protected veteran status and will not be discriminated against on the basis of disability.

INDHP

Primary Location

Ireland-Limerick-Limerick-

Organization

Janssen Pharmaceutical Ltd. (8170)

Job Function

Engineering (IT)

Requisition ID

1905717911W",Undefined,indeed,d49282046792b1b89a8f91315c91ac37
Senior Data Engineer,Computer,Johnson & Johnson Family of Companies,#N/A,#N/A,Ireland,2019-06-29,"The Johnson and Johnson, EMEA Software Development Centre, are currently seeking an Data Engineer to join our team. We develop, design and deliver high quality business applications, software solutions and services to meet J&J business technology requirements.

The offices are newly designed, specifically to accommodate Scrum development and are based on the University of Limerick Campus. It is an open and highly collaborative environment based on LEAN principles with a strong emphasis on continuous integration, automated testing and continuous delivery. Scrum teams are encouraged to be self-organising and autonomous.

Responsibilities:

Playing a lead role in software design, architecture, requirements analysis, investigation of leading edge technologies, and software development.

Collaborating with the core development team and the product owner to define and estimate business requirements and then translate these into specific software tasks.

Collaborate as a member of an agile team to get products developed and completed with best in class software development.

Design, build, and maintain high performance, reusable, and reliable ETL packages.

Ensure the best possible performance, quality, and responsiveness of applications developed.

Qualifications

Requirements:

5+ years’ experience of development of ETL packages.

Strong technical knowledge of Enterprise Data Warehouse, database design and Information Management.

Experience with Informatica Power Center in designing and developing complex ETL packages.

Experience with writing and debugging complex SQL queries

Experience in designing and developing data models

Experience in real/near time data load using Informatica CDC (Change Data Capture)

Knowledge and experience with Gemfire, IMDG, Big Data, Hadoop, Kafka and Spark.

Experience with Java and Spring – Spring Cloud, Spring XD and Spring Batch.

Strengths:

Possess a basic understanding of agile development methodologies, specifically Scrum and Kanban.

Excellent written and verbal English skills.

Preferred qualifications:

BSc. or Master's degree in Computer Science or related technical field.

Solid understanding of information management, data modeling, system integration, development methodologies (including unit testing) and web technologies.

Excellent interpersonal and communication skills and an ability to work effectively with teams.

Strong analytical skills and a demonstrable bias toward action.

Johnson & Johnson is an Affirmative Action and Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, colour, religion, sex, sexual orientation, gender identity, age, national origin, or protected veteran status and will not be discriminated against on the basis of disability.

INDHP

Primary Location

Ireland-Limerick-Limerick-

Organization

Janssen Pharmaceutical Ltd. (8170)

Job Function

Engineering (IT)

Requisition ID

1905717911W",Undefined,indeed,929db1feabcb9c92c3894ddb26625e76
Senior Data Engineer,Customer-Service,Johnson & Johnson Family of Companies,#N/A,#N/A,Ireland,2019-06-29,"The Johnson and Johnson, EMEA Software Development Centre, are currently seeking an Data Engineer to join our team. We develop, design and deliver high quality business applications, software solutions and services to meet J&J business technology requirements.

The offices are newly designed, specifically to accommodate Scrum development and are based on the University of Limerick Campus. It is an open and highly collaborative environment based on LEAN principles with a strong emphasis on continuous integration, automated testing and continuous delivery. Scrum teams are encouraged to be self-organising and autonomous.

Responsibilities:

Playing a lead role in software design, architecture, requirements analysis, investigation of leading edge technologies, and software development.

Collaborating with the core development team and the product owner to define and estimate business requirements and then translate these into specific software tasks.

Collaborate as a member of an agile team to get products developed and completed with best in class software development.

Design, build, and maintain high performance, reusable, and reliable ETL packages.

Ensure the best possible performance, quality, and responsiveness of applications developed.

Qualifications

Requirements:

5+ years’ experience of development of ETL packages.

Strong technical knowledge of Enterprise Data Warehouse, database design and Information Management.

Experience with Informatica Power Center in designing and developing complex ETL packages.

Experience with writing and debugging complex SQL queries

Experience in designing and developing data models

Experience in real/near time data load using Informatica CDC (Change Data Capture)

Knowledge and experience with Gemfire, IMDG, Big Data, Hadoop, Kafka and Spark.

Experience with Java and Spring – Spring Cloud, Spring XD and Spring Batch.

Strengths:

Possess a basic understanding of agile development methodologies, specifically Scrum and Kanban.

Excellent written and verbal English skills.

Preferred qualifications:

BSc. or Master's degree in Computer Science or related technical field.

Solid understanding of information management, data modeling, system integration, development methodologies (including unit testing) and web technologies.

Excellent interpersonal and communication skills and an ability to work effectively with teams.

Strong analytical skills and a demonstrable bias toward action.

Johnson & Johnson is an Affirmative Action and Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, colour, religion, sex, sexual orientation, gender identity, age, national origin, or protected veteran status and will not be discriminated against on the basis of disability.

INDHP

Primary Location

Ireland-Limerick-Limerick-

Organization

Janssen Pharmaceutical Ltd. (8170)

Job Function

Engineering (IT)

Requisition ID

1905717911W",Undefined,indeed,51eb55cbf005e15cc94db1dfe351eb4d
Senior Data Engineer,Computer,Johnson & Johnson Family of Companies,#N/A,#N/A,Ireland,2019-06-29,"The Johnson and Johnson, EMEA Software Development Centre, are currently seeking an Data Engineer to join our team. We develop, design and deliver high quality business applications, software solutions and services to meet J&J business technology requirements.

The offices are newly designed, specifically to accommodate Scrum development and are based on the University of Limerick Campus. It is an open and highly collaborative environment based on LEAN principles with a strong emphasis on continuous integration, automated testing and continuous delivery. Scrum teams are encouraged to be self-organising and autonomous.

Responsibilities:

Playing a lead role in software design, architecture, requirements analysis, investigation of leading edge technologies, and software development.

Collaborating with the core development team and the product owner to define and estimate business requirements and then translate these into specific software tasks.

Collaborate as a member of an agile team to get products developed and completed with best in class software development.

Design, build, and maintain high performance, reusable, and reliable ETL packages.

Ensure the best possible performance, quality, and responsiveness of applications developed.

Qualifications

Requirements:

5+ years’ experience of development of ETL packages.

Strong technical knowledge of Enterprise Data Warehouse, database design and Information Management.

Experience with Informatica Power Center in designing and developing complex ETL packages.

Experience with writing and debugging complex SQL queries

Experience in designing and developing data models

Experience in real/near time data load using Informatica CDC (Change Data Capture)

Knowledge and experience with Gemfire, IMDG, Big Data, Hadoop, Kafka and Spark.

Experience with Java and Spring – Spring Cloud, Spring XD and Spring Batch.

Strengths:

Possess a basic understanding of agile development methodologies, specifically Scrum and Kanban.

Excellent written and verbal English skills.

Preferred qualifications:

BSc. or Master's degree in Computer Science or related technical field.

Solid understanding of information management, data modeling, system integration, development methodologies (including unit testing) and web technologies.

Excellent interpersonal and communication skills and an ability to work effectively with teams.

Strong analytical skills and a demonstrable bias toward action.

Johnson & Johnson is an Affirmative Action and Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, colour, religion, sex, sexual orientation, gender identity, age, national origin, or protected veteran status and will not be discriminated against on the basis of disability.

INDHP

Primary Location

Ireland-Limerick-Limerick-

Organization

Janssen Pharmaceutical Ltd. (8170)

Job Function

Engineering (IT)

Requisition ID

1905717911W",Undefined,indeed,c1097d60c9dc62463e2745608b632fb6
Senior Data Engineer,Computer,Johnson & Johnson Family of Companies,#N/A,#N/A,Ireland,2019-06-29,"The Johnson and Johnson, EMEA Software Development Centre, are currently seeking an Data Engineer to join our team. We develop, design and deliver high quality business applications, software solutions and services to meet J&J business technology requirements.

The offices are newly designed, specifically to accommodate Scrum development and are based on the University of Limerick Campus. It is an open and highly collaborative environment based on LEAN principles with a strong emphasis on continuous integration, automated testing and continuous delivery. Scrum teams are encouraged to be self-organising and autonomous.

Responsibilities:

Playing a lead role in software design, architecture, requirements analysis, investigation of leading edge technologies, and software development.

Collaborating with the core development team and the product owner to define and estimate business requirements and then translate these into specific software tasks.

Collaborate as a member of an agile team to get products developed and completed with best in class software development.

Design, build, and maintain high performance, reusable, and reliable ETL packages.

Ensure the best possible performance, quality, and responsiveness of applications developed.

Qualifications

Requirements:

5+ years’ experience of development of ETL packages.

Strong technical knowledge of Enterprise Data Warehouse, database design and Information Management.

Experience with Informatica Power Center in designing and developing complex ETL packages.

Experience with writing and debugging complex SQL queries

Experience in designing and developing data models

Experience in real/near time data load using Informatica CDC (Change Data Capture)

Knowledge and experience with Gemfire, IMDG, Big Data, Hadoop, Kafka and Spark.

Experience with Java and Spring – Spring Cloud, Spring XD and Spring Batch.

Strengths:

Possess a basic understanding of agile development methodologies, specifically Scrum and Kanban.

Excellent written and verbal English skills.

Preferred qualifications:

BSc. or Master's degree in Computer Science or related technical field.

Solid understanding of information management, data modeling, system integration, development methodologies (including unit testing) and web technologies.

Excellent interpersonal and communication skills and an ability to work effectively with teams.

Strong analytical skills and a demonstrable bias toward action.

Johnson & Johnson is an Affirmative Action and Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, colour, religion, sex, sexual orientation, gender identity, age, national origin, or protected veteran status and will not be discriminated against on the basis of disability.

INDHP

Primary Location

Ireland-Limerick-Limerick-

Organization

Janssen Pharmaceutical Ltd. (8170)

Job Function

Engineering (IT)

Requisition ID

1905717911W",Undefined,indeed,2652224f5f962d079d0ec718f697402f
Senior Data Engineer,Computer,Johnson & Johnson Family of Companies,#N/A,#N/A,Ireland,2019-06-29,"The Johnson and Johnson, EMEA Software Development Centre, are currently seeking an Data Engineer to join our team. We develop, design and deliver high quality business applications, software solutions and services to meet J&J business technology requirements.

The offices are newly designed, specifically to accommodate Scrum development and are based on the University of Limerick Campus. It is an open and highly collaborative environment based on LEAN principles with a strong emphasis on continuous integration, automated testing and continuous delivery. Scrum teams are encouraged to be self-organising and autonomous.

Responsibilities:

Playing a lead role in software design, architecture, requirements analysis, investigation of leading edge technologies, and software development.

Collaborating with the core development team and the product owner to define and estimate business requirements and then translate these into specific software tasks.

Collaborate as a member of an agile team to get products developed and completed with best in class software development.

Design, build, and maintain high performance, reusable, and reliable ETL packages.

Ensure the best possible performance, quality, and responsiveness of applications developed.

Qualifications

Requirements:

5+ years’ experience of development of ETL packages.

Strong technical knowledge of Enterprise Data Warehouse, database design and Information Management.

Experience with Informatica Power Center in designing and developing complex ETL packages.

Experience with writing and debugging complex SQL queries

Experience in designing and developing data models

Experience in real/near time data load using Informatica CDC (Change Data Capture)

Knowledge and experience with Gemfire, IMDG, Big Data, Hadoop, Kafka and Spark.

Experience with Java and Spring – Spring Cloud, Spring XD and Spring Batch.

Strengths:

Possess a basic understanding of agile development methodologies, specifically Scrum and Kanban.

Excellent written and verbal English skills.

Preferred qualifications:

BSc. or Master's degree in Computer Science or related technical field.

Solid understanding of information management, data modeling, system integration, development methodologies (including unit testing) and web technologies.

Excellent interpersonal and communication skills and an ability to work effectively with teams.

Strong analytical skills and a demonstrable bias toward action.

Johnson & Johnson is an Affirmative Action and Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, colour, religion, sex, sexual orientation, gender identity, age, national origin, or protected veteran status and will not be discriminated against on the basis of disability.

INDHP

Primary Location

Ireland-Limerick-Limerick-

Organization

Janssen Pharmaceutical Ltd. (8170)

Job Function

Engineering (IT)

Requisition ID

1905717911W",Undefined,indeed,501cdd853ba49814a7bf77c7d931825a
Senior Data Engineer,Logistics,Johnson & Johnson Family of Companies,#N/A,#N/A,Ireland,2019-06-29,"The Johnson and Johnson, EMEA Software Development Centre, are currently seeking an Data Engineer to join our team. We develop, design and deliver high quality business applications, software solutions and services to meet J&J business technology requirements.

The offices are newly designed, specifically to accommodate Scrum development and are based on the University of Limerick Campus. It is an open and highly collaborative environment based on LEAN principles with a strong emphasis on continuous integration, automated testing and continuous delivery. Scrum teams are encouraged to be self-organising and autonomous.

Responsibilities:

Playing a lead role in software design, architecture, requirements analysis, investigation of leading edge technologies, and software development.

Collaborating with the core development team and the product owner to define and estimate business requirements and then translate these into specific software tasks.

Collaborate as a member of an agile team to get products developed and completed with best in class software development.

Design, build, and maintain high performance, reusable, and reliable ETL packages.

Ensure the best possible performance, quality, and responsiveness of applications developed.

Qualifications

Requirements:

5+ years’ experience of development of ETL packages.

Strong technical knowledge of Enterprise Data Warehouse, database design and Information Management.

Experience with Informatica Power Center in designing and developing complex ETL packages.

Experience with writing and debugging complex SQL queries

Experience in designing and developing data models

Experience in real/near time data load using Informatica CDC (Change Data Capture)

Knowledge and experience with Gemfire, IMDG, Big Data, Hadoop, Kafka and Spark.

Experience with Java and Spring – Spring Cloud, Spring XD and Spring Batch.

Strengths:

Possess a basic understanding of agile development methodologies, specifically Scrum and Kanban.

Excellent written and verbal English skills.

Preferred qualifications:

BSc. or Master's degree in Computer Science or related technical field.

Solid understanding of information management, data modeling, system integration, development methodologies (including unit testing) and web technologies.

Excellent interpersonal and communication skills and an ability to work effectively with teams.

Strong analytical skills and a demonstrable bias toward action.

Johnson & Johnson is an Affirmative Action and Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, colour, religion, sex, sexual orientation, gender identity, age, national origin, or protected veteran status and will not be discriminated against on the basis of disability.

INDHP

Primary Location

Ireland-Limerick-Limerick-

Organization

Janssen Pharmaceutical Ltd. (8170)

Job Function

Engineering (IT)

Requisition ID

1905717911W",Undefined,indeed,6340a19289eb2c914ae132dc5061646e
Senior Data Engineer,Computer,Johnson & Johnson Family of Companies,#N/A,#N/A,Ireland,2019-06-29,"The Johnson and Johnson, EMEA Software Development Centre, are currently seeking an Data Engineer to join our team. We develop, design and deliver high quality business applications, software solutions and services to meet J&J business technology requirements.

The offices are newly designed, specifically to accommodate Scrum development and are based on the University of Limerick Campus. It is an open and highly collaborative environment based on LEAN principles with a strong emphasis on continuous integration, automated testing and continuous delivery. Scrum teams are encouraged to be self-organising and autonomous.

Responsibilities:

Playing a lead role in software design, architecture, requirements analysis, investigation of leading edge technologies, and software development.

Collaborating with the core development team and the product owner to define and estimate business requirements and then translate these into specific software tasks.

Collaborate as a member of an agile team to get products developed and completed with best in class software development.

Design, build, and maintain high performance, reusable, and reliable ETL packages.

Ensure the best possible performance, quality, and responsiveness of applications developed.

Qualifications

Requirements:

5+ years’ experience of development of ETL packages.

Strong technical knowledge of Enterprise Data Warehouse, database design and Information Management.

Experience with Informatica Power Center in designing and developing complex ETL packages.

Experience with writing and debugging complex SQL queries

Experience in designing and developing data models

Experience in real/near time data load using Informatica CDC (Change Data Capture)

Knowledge and experience with Gemfire, IMDG, Big Data, Hadoop, Kafka and Spark.

Experience with Java and Spring – Spring Cloud, Spring XD and Spring Batch.

Strengths:

Possess a basic understanding of agile development methodologies, specifically Scrum and Kanban.

Excellent written and verbal English skills.

Preferred qualifications:

BSc. or Master's degree in Computer Science or related technical field.

Solid understanding of information management, data modeling, system integration, development methodologies (including unit testing) and web technologies.

Excellent interpersonal and communication skills and an ability to work effectively with teams.

Strong analytical skills and a demonstrable bias toward action.

Johnson & Johnson is an Affirmative Action and Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, colour, religion, sex, sexual orientation, gender identity, age, national origin, or protected veteran status and will not be discriminated against on the basis of disability.

INDHP

Primary Location

Ireland-Limerick-Limerick-

Organization

Janssen Pharmaceutical Ltd. (8170)

Job Function

Engineering (IT)

Requisition ID

1905717911W",Undefined,indeed,d408f28b3324f2502c9bac6200bc7f67
Senior Data Engineer,Customer-Service,Johnson & Johnson Family of Companies,#N/A,#N/A,Ireland,2019-06-29,"The Johnson and Johnson, EMEA Software Development Centre, are currently seeking an Data Engineer to join our team. We develop, design and deliver high quality business applications, software solutions and services to meet J&J business technology requirements.

The offices are newly designed, specifically to accommodate Scrum development and are based on the University of Limerick Campus. It is an open and highly collaborative environment based on LEAN principles with a strong emphasis on continuous integration, automated testing and continuous delivery. Scrum teams are encouraged to be self-organising and autonomous.

Responsibilities:

Playing a lead role in software design, architecture, requirements analysis, investigation of leading edge technologies, and software development.

Collaborating with the core development team and the product owner to define and estimate business requirements and then translate these into specific software tasks.

Collaborate as a member of an agile team to get products developed and completed with best in class software development.

Design, build, and maintain high performance, reusable, and reliable ETL packages.

Ensure the best possible performance, quality, and responsiveness of applications developed.

Qualifications

Requirements:

5+ years’ experience of development of ETL packages.

Strong technical knowledge of Enterprise Data Warehouse, database design and Information Management.

Experience with Informatica Power Center in designing and developing complex ETL packages.

Experience with writing and debugging complex SQL queries

Experience in designing and developing data models

Experience in real/near time data load using Informatica CDC (Change Data Capture)

Knowledge and experience with Gemfire, IMDG, Big Data, Hadoop, Kafka and Spark.

Experience with Java and Spring – Spring Cloud, Spring XD and Spring Batch.

Strengths:

Possess a basic understanding of agile development methodologies, specifically Scrum and Kanban.

Excellent written and verbal English skills.

Preferred qualifications:

BSc. or Master's degree in Computer Science or related technical field.

Solid understanding of information management, data modeling, system integration, development methodologies (including unit testing) and web technologies.

Excellent interpersonal and communication skills and an ability to work effectively with teams.

Strong analytical skills and a demonstrable bias toward action.

Johnson & Johnson is an Affirmative Action and Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, colour, religion, sex, sexual orientation, gender identity, age, national origin, or protected veteran status and will not be discriminated against on the basis of disability.

INDHP

Primary Location

Ireland-Limerick-Limerick-

Organization

Janssen Pharmaceutical Ltd. (8170)

Job Function

Engineering (IT)

Requisition ID

1905717911W",Undefined,indeed,625539ae40f33f6fd657efbd5ab5e8d1
Senior Data Engineer,Computer,Johnson & Johnson Family of Companies,#N/A,#N/A,Ireland,2019-06-29,"The Johnson and Johnson, EMEA Software Development Centre, are currently seeking an Data Engineer to join our team. We develop, design and deliver high quality business applications, software solutions and services to meet J&J business technology requirements.

The offices are newly designed, specifically to accommodate Scrum development and are based on the University of Limerick Campus. It is an open and highly collaborative environment based on LEAN principles with a strong emphasis on continuous integration, automated testing and continuous delivery. Scrum teams are encouraged to be self-organising and autonomous.

Responsibilities:

Playing a lead role in software design, architecture, requirements analysis, investigation of leading edge technologies, and software development.

Collaborating with the core development team and the product owner to define and estimate business requirements and then translate these into specific software tasks.

Collaborate as a member of an agile team to get products developed and completed with best in class software development.

Design, build, and maintain high performance, reusable, and reliable ETL packages.

Ensure the best possible performance, quality, and responsiveness of applications developed.

Qualifications

Requirements:

5+ years’ experience of development of ETL packages.

Strong technical knowledge of Enterprise Data Warehouse, database design and Information Management.

Experience with Informatica Power Center in designing and developing complex ETL packages.

Experience with writing and debugging complex SQL queries

Experience in designing and developing data models

Experience in real/near time data load using Informatica CDC (Change Data Capture)

Knowledge and experience with Gemfire, IMDG, Big Data, Hadoop, Kafka and Spark.

Experience with Java and Spring – Spring Cloud, Spring XD and Spring Batch.

Strengths:

Possess a basic understanding of agile development methodologies, specifically Scrum and Kanban.

Excellent written and verbal English skills.

Preferred qualifications:

BSc. or Master's degree in Computer Science or related technical field.

Solid understanding of information management, data modeling, system integration, development methodologies (including unit testing) and web technologies.

Excellent interpersonal and communication skills and an ability to work effectively with teams.

Strong analytical skills and a demonstrable bias toward action.

Johnson & Johnson is an Affirmative Action and Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, colour, religion, sex, sexual orientation, gender identity, age, national origin, or protected veteran status and will not be discriminated against on the basis of disability.

INDHP

Primary Location

Ireland-Limerick-Limerick-

Organization

Janssen Pharmaceutical Ltd. (8170)

Job Function

Engineering (IT)

Requisition ID

1905717911W",Undefined,indeed,c10ba6509d1dd30d6d4b1b4867921dfb
Senior Data Engineer,Architecture,Johnson & Johnson Family of Companies,#N/A,#N/A,Ireland,2019-06-29,"The Johnson and Johnson, EMEA Software Development Centre, are currently seeking an Data Engineer to join our team. We develop, design and deliver high quality business applications, software solutions and services to meet J&J business technology requirements.

The offices are newly designed, specifically to accommodate Scrum development and are based on the University of Limerick Campus. It is an open and highly collaborative environment based on LEAN principles with a strong emphasis on continuous integration, automated testing and continuous delivery. Scrum teams are encouraged to be self-organising and autonomous.

Responsibilities:

Playing a lead role in software design, architecture, requirements analysis, investigation of leading edge technologies, and software development.

Collaborating with the core development team and the product owner to define and estimate business requirements and then translate these into specific software tasks.

Collaborate as a member of an agile team to get products developed and completed with best in class software development.

Design, build, and maintain high performance, reusable, and reliable ETL packages.

Ensure the best possible performance, quality, and responsiveness of applications developed.

Qualifications

Requirements:

5+ years’ experience of development of ETL packages.

Strong technical knowledge of Enterprise Data Warehouse, database design and Information Management.

Experience with Informatica Power Center in designing and developing complex ETL packages.

Experience with writing and debugging complex SQL queries

Experience in designing and developing data models

Experience in real/near time data load using Informatica CDC (Change Data Capture)

Knowledge and experience with Gemfire, IMDG, Big Data, Hadoop, Kafka and Spark.

Experience with Java and Spring – Spring Cloud, Spring XD and Spring Batch.

Strengths:

Possess a basic understanding of agile development methodologies, specifically Scrum and Kanban.

Excellent written and verbal English skills.

Preferred qualifications:

BSc. or Master's degree in Computer Science or related technical field.

Solid understanding of information management, data modeling, system integration, development methodologies (including unit testing) and web technologies.

Excellent interpersonal and communication skills and an ability to work effectively with teams.

Strong analytical skills and a demonstrable bias toward action.

Johnson & Johnson is an Affirmative Action and Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, colour, religion, sex, sexual orientation, gender identity, age, national origin, or protected veteran status and will not be discriminated against on the basis of disability.

INDHP

Primary Location

Ireland-Limerick-Limerick-

Organization

Janssen Pharmaceutical Ltd. (8170)

Job Function

Engineering (IT)

Requisition ID

1905717911W",Undefined,indeed,918f7fd93e3d5bb046ff71e98b7e3515
Senior Data Engineer,Manufacturing,Johnson & Johnson Family of Companies,#N/A,#N/A,Ireland,2019-06-29,"The Johnson and Johnson, EMEA Software Development Centre, are currently seeking an Data Engineer to join our team. We develop, design and deliver high quality business applications, software solutions and services to meet J&J business technology requirements.

The offices are newly designed, specifically to accommodate Scrum development and are based on the University of Limerick Campus. It is an open and highly collaborative environment based on LEAN principles with a strong emphasis on continuous integration, automated testing and continuous delivery. Scrum teams are encouraged to be self-organising and autonomous.

Responsibilities:

Playing a lead role in software design, architecture, requirements analysis, investigation of leading edge technologies, and software development.

Collaborating with the core development team and the product owner to define and estimate business requirements and then translate these into specific software tasks.

Collaborate as a member of an agile team to get products developed and completed with best in class software development.

Design, build, and maintain high performance, reusable, and reliable ETL packages.

Ensure the best possible performance, quality, and responsiveness of applications developed.

Qualifications

Requirements:

5+ years’ experience of development of ETL packages.

Strong technical knowledge of Enterprise Data Warehouse, database design and Information Management.

Experience with Informatica Power Center in designing and developing complex ETL packages.

Experience with writing and debugging complex SQL queries

Experience in designing and developing data models

Experience in real/near time data load using Informatica CDC (Change Data Capture)

Knowledge and experience with Gemfire, IMDG, Big Data, Hadoop, Kafka and Spark.

Experience with Java and Spring – Spring Cloud, Spring XD and Spring Batch.

Strengths:

Possess a basic understanding of agile development methodologies, specifically Scrum and Kanban.

Excellent written and verbal English skills.

Preferred qualifications:

BSc. or Master's degree in Computer Science or related technical field.

Solid understanding of information management, data modeling, system integration, development methodologies (including unit testing) and web technologies.

Excellent interpersonal and communication skills and an ability to work effectively with teams.

Strong analytical skills and a demonstrable bias toward action.

Johnson & Johnson is an Affirmative Action and Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, colour, religion, sex, sexual orientation, gender identity, age, national origin, or protected veteran status and will not be discriminated against on the basis of disability.

INDHP

Primary Location

Ireland-Limerick-Limerick-

Organization

Janssen Pharmaceutical Ltd. (8170)

Job Function

Engineering (IT)

Requisition ID

1905717911W",Undefined,indeed,d569a9da2185dd1cf3b2ad52b8a16442
Senior Data Engineer,Computer,Johnson & Johnson Family of Companies,#N/A,#N/A,Ireland,2019-06-29,"The Johnson and Johnson, EMEA Software Development Centre, are currently seeking an Data Engineer to join our team. We develop, design and deliver high quality business applications, software solutions and services to meet J&J business technology requirements.

The offices are newly designed, specifically to accommodate Scrum development and are based on the University of Limerick Campus. It is an open and highly collaborative environment based on LEAN principles with a strong emphasis on continuous integration, automated testing and continuous delivery. Scrum teams are encouraged to be self-organising and autonomous.

Responsibilities:

Playing a lead role in software design, architecture, requirements analysis, investigation of leading edge technologies, and software development.

Collaborating with the core development team and the product owner to define and estimate business requirements and then translate these into specific software tasks.

Collaborate as a member of an agile team to get products developed and completed with best in class software development.

Design, build, and maintain high performance, reusable, and reliable ETL packages.

Ensure the best possible performance, quality, and responsiveness of applications developed.

Qualifications

Requirements:

5+ years’ experience of development of ETL packages.

Strong technical knowledge of Enterprise Data Warehouse, database design and Information Management.

Experience with Informatica Power Center in designing and developing complex ETL packages.

Experience with writing and debugging complex SQL queries

Experience in designing and developing data models

Experience in real/near time data load using Informatica CDC (Change Data Capture)

Knowledge and experience with Gemfire, IMDG, Big Data, Hadoop, Kafka and Spark.

Experience with Java and Spring – Spring Cloud, Spring XD and Spring Batch.

Strengths:

Possess a basic understanding of agile development methodologies, specifically Scrum and Kanban.

Excellent written and verbal English skills.

Preferred qualifications:

BSc. or Master's degree in Computer Science or related technical field.

Solid understanding of information management, data modeling, system integration, development methodologies (including unit testing) and web technologies.

Excellent interpersonal and communication skills and an ability to work effectively with teams.

Strong analytical skills and a demonstrable bias toward action.

Johnson & Johnson is an Affirmative Action and Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, colour, religion, sex, sexual orientation, gender identity, age, national origin, or protected veteran status and will not be discriminated against on the basis of disability.

INDHP

Primary Location

Ireland-Limerick-Limerick-

Organization

Janssen Pharmaceutical Ltd. (8170)

Job Function

Engineering (IT)

Requisition ID

1905717911W",Undefined,indeed,3e88486545861989f7863bd0f0104c40
Senior Data Engineer,Engineering,Johnson & Johnson Family of Companies,#N/A,#N/A,Ireland,2019-06-29,"The Johnson and Johnson, EMEA Software Development Centre, are currently seeking an Data Engineer to join our team. We develop, design and deliver high quality business applications, software solutions and services to meet J&J business technology requirements.

The offices are newly designed, specifically to accommodate Scrum development and are based on the University of Limerick Campus. It is an open and highly collaborative environment based on LEAN principles with a strong emphasis on continuous integration, automated testing and continuous delivery. Scrum teams are encouraged to be self-organising and autonomous.

Responsibilities:

Playing a lead role in software design, architecture, requirements analysis, investigation of leading edge technologies, and software development.

Collaborating with the core development team and the product owner to define and estimate business requirements and then translate these into specific software tasks.

Collaborate as a member of an agile team to get products developed and completed with best in class software development.

Design, build, and maintain high performance, reusable, and reliable ETL packages.

Ensure the best possible performance, quality, and responsiveness of applications developed.

Qualifications

Requirements:

5+ years’ experience of development of ETL packages.

Strong technical knowledge of Enterprise Data Warehouse, database design and Information Management.

Experience with Informatica Power Center in designing and developing complex ETL packages.

Experience with writing and debugging complex SQL queries

Experience in designing and developing data models

Experience in real/near time data load using Informatica CDC (Change Data Capture)

Knowledge and experience with Gemfire, IMDG, Big Data, Hadoop, Kafka and Spark.

Experience with Java and Spring – Spring Cloud, Spring XD and Spring Batch.

Strengths:

Possess a basic understanding of agile development methodologies, specifically Scrum and Kanban.

Excellent written and verbal English skills.

Preferred qualifications:

BSc. or Master's degree in Computer Science or related technical field.

Solid understanding of information management, data modeling, system integration, development methodologies (including unit testing) and web technologies.

Excellent interpersonal and communication skills and an ability to work effectively with teams.

Strong analytical skills and a demonstrable bias toward action.

Johnson & Johnson is an Affirmative Action and Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, colour, religion, sex, sexual orientation, gender identity, age, national origin, or protected veteran status and will not be discriminated against on the basis of disability.

INDHP

Primary Location

Ireland-Limerick-Limerick-

Organization

Janssen Pharmaceutical Ltd. (8170)

Job Function

Engineering (IT)

Requisition ID

1905717911W",Undefined,indeed,c684776fb1be2fcdfe9788d8a00561ca
Senior Data Engineer,Engineering,Johnson & Johnson Family of Companies,#N/A,#N/A,Ireland,2019-06-29,"The Johnson and Johnson, EMEA Software Development Centre, are currently seeking an Data Engineer to join our team. We develop, design and deliver high quality business applications, software solutions and services to meet J&J business technology requirements.

The offices are newly designed, specifically to accommodate Scrum development and are based on the University of Limerick Campus. It is an open and highly collaborative environment based on LEAN principles with a strong emphasis on continuous integration, automated testing and continuous delivery. Scrum teams are encouraged to be self-organising and autonomous.

Responsibilities:

Playing a lead role in software design, architecture, requirements analysis, investigation of leading edge technologies, and software development.

Collaborating with the core development team and the product owner to define and estimate business requirements and then translate these into specific software tasks.

Collaborate as a member of an agile team to get products developed and completed with best in class software development.

Design, build, and maintain high performance, reusable, and reliable ETL packages.

Ensure the best possible performance, quality, and responsiveness of applications developed.

Qualifications

Requirements:

5+ years’ experience of development of ETL packages.

Strong technical knowledge of Enterprise Data Warehouse, database design and Information Management.

Experience with Informatica Power Center in designing and developing complex ETL packages.

Experience with writing and debugging complex SQL queries

Experience in designing and developing data models

Experience in real/near time data load using Informatica CDC (Change Data Capture)

Knowledge and experience with Gemfire, IMDG, Big Data, Hadoop, Kafka and Spark.

Experience with Java and Spring – Spring Cloud, Spring XD and Spring Batch.

Strengths:

Possess a basic understanding of agile development methodologies, specifically Scrum and Kanban.

Excellent written and verbal English skills.

Preferred qualifications:

BSc. or Master's degree in Computer Science or related technical field.

Solid understanding of information management, data modeling, system integration, development methodologies (including unit testing) and web technologies.

Excellent interpersonal and communication skills and an ability to work effectively with teams.

Strong analytical skills and a demonstrable bias toward action.

Johnson & Johnson is an Affirmative Action and Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, colour, religion, sex, sexual orientation, gender identity, age, national origin, or protected veteran status and will not be discriminated against on the basis of disability.

INDHP

Primary Location

Ireland-Limerick-Limerick-

Organization

Janssen Pharmaceutical Ltd. (8170)

Job Function

Engineering (IT)

Requisition ID

1905717911W",Undefined,indeed,5edba2eb3b4b40c7676a7e03f8da7486
Senior Data Engineer,Engineering,Johnson & Johnson Family of Companies,#N/A,#N/A,Ireland,2019-06-29,"The Johnson and Johnson, EMEA Software Development Centre, are currently seeking an Data Engineer to join our team. We develop, design and deliver high quality business applications, software solutions and services to meet J&J business technology requirements.

The offices are newly designed, specifically to accommodate Scrum development and are based on the University of Limerick Campus. It is an open and highly collaborative environment based on LEAN principles with a strong emphasis on continuous integration, automated testing and continuous delivery. Scrum teams are encouraged to be self-organising and autonomous.

Responsibilities:

Playing a lead role in software design, architecture, requirements analysis, investigation of leading edge technologies, and software development.

Collaborating with the core development team and the product owner to define and estimate business requirements and then translate these into specific software tasks.

Collaborate as a member of an agile team to get products developed and completed with best in class software development.

Design, build, and maintain high performance, reusable, and reliable ETL packages.

Ensure the best possible performance, quality, and responsiveness of applications developed.

Qualifications

Requirements:

5+ years’ experience of development of ETL packages.

Strong technical knowledge of Enterprise Data Warehouse, database design and Information Management.

Experience with Informatica Power Center in designing and developing complex ETL packages.

Experience with writing and debugging complex SQL queries

Experience in designing and developing data models

Experience in real/near time data load using Informatica CDC (Change Data Capture)

Knowledge and experience with Gemfire, IMDG, Big Data, Hadoop, Kafka and Spark.

Experience with Java and Spring – Spring Cloud, Spring XD and Spring Batch.

Strengths:

Possess a basic understanding of agile development methodologies, specifically Scrum and Kanban.

Excellent written and verbal English skills.

Preferred qualifications:

BSc. or Master's degree in Computer Science or related technical field.

Solid understanding of information management, data modeling, system integration, development methodologies (including unit testing) and web technologies.

Excellent interpersonal and communication skills and an ability to work effectively with teams.

Strong analytical skills and a demonstrable bias toward action.

Johnson & Johnson is an Affirmative Action and Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, colour, religion, sex, sexual orientation, gender identity, age, national origin, or protected veteran status and will not be discriminated against on the basis of disability.

INDHP

Primary Location

Ireland-Limerick-Limerick-

Organization

Janssen Pharmaceutical Ltd. (8170)

Job Function

Engineering (IT)

Requisition ID

1905717911W",Undefined,indeed,a3ce51b64f16298992df264703577657
Senior Data Engineer,Customer-Service,Johnson & Johnson Family of Companies,#N/A,#N/A,Ireland,2019-06-29,"The Johnson and Johnson, EMEA Software Development Centre, are currently seeking an Data Engineer to join our team. We develop, design and deliver high quality business applications, software solutions and services to meet J&J business technology requirements.

The offices are newly designed, specifically to accommodate Scrum development and are based on the University of Limerick Campus. It is an open and highly collaborative environment based on LEAN principles with a strong emphasis on continuous integration, automated testing and continuous delivery. Scrum teams are encouraged to be self-organising and autonomous.

Responsibilities:

Playing a lead role in software design, architecture, requirements analysis, investigation of leading edge technologies, and software development.

Collaborating with the core development team and the product owner to define and estimate business requirements and then translate these into specific software tasks.

Collaborate as a member of an agile team to get products developed and completed with best in class software development.

Design, build, and maintain high performance, reusable, and reliable ETL packages.

Ensure the best possible performance, quality, and responsiveness of applications developed.

Qualifications

Requirements:

5+ years’ experience of development of ETL packages.

Strong technical knowledge of Enterprise Data Warehouse, database design and Information Management.

Experience with Informatica Power Center in designing and developing complex ETL packages.

Experience with writing and debugging complex SQL queries

Experience in designing and developing data models

Experience in real/near time data load using Informatica CDC (Change Data Capture)

Knowledge and experience with Gemfire, IMDG, Big Data, Hadoop, Kafka and Spark.

Experience with Java and Spring – Spring Cloud, Spring XD and Spring Batch.

Strengths:

Possess a basic understanding of agile development methodologies, specifically Scrum and Kanban.

Excellent written and verbal English skills.

Preferred qualifications:

BSc. or Master's degree in Computer Science or related technical field.

Solid understanding of information management, data modeling, system integration, development methodologies (including unit testing) and web technologies.

Excellent interpersonal and communication skills and an ability to work effectively with teams.

Strong analytical skills and a demonstrable bias toward action.

Johnson & Johnson is an Affirmative Action and Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, colour, religion, sex, sexual orientation, gender identity, age, national origin, or protected veteran status and will not be discriminated against on the basis of disability.

INDHP

Primary Location

Ireland-Limerick-Limerick-

Organization

Janssen Pharmaceutical Ltd. (8170)

Job Function

Engineering (IT)

Requisition ID

1905717911W",Undefined,indeed,e8ee8867e4fe12227095d4f77e5fed37
Junior Data Scientist - Talent Analytics,Computer-or-internet,WeWork,New york,New york,United states,2019-07-30,"About the Role:

The Talent Reporting & Analytics team provides people analytics that empowers leaders to make timely, informed, and future-focused business decisions. The team is responsible for development and delivery of Talent operational reporting; development, management, and support of surveys and assessments for all Talent process areas; and definition, development, and support of analytics supporting Talent.

Job Responsibilities:

Partner directly with the Talent Strategy & Operations to support any reporting requirements needs for projects, measuring or analysis

Build, develop & design dashboards to support Talent Metrics & KPIs.

Ad hoc data analysis & reporting for Talent programs and projects.

Weekly reporting on hiring and headcount stats within the organization.

Integrates multiple systems and data sets to build large and complex data sets and make them usable (e.g., transforming and cleaning data, working incomplete data sources, implementing and validating quality procedures).

Conducts scalable data research and off and ultimately on the cloud.

Implements automated processes for efficiently producing scale models.

Liaises and collaborates with other COEs, Business Advisor organizations and Core Talent Services on the whole analytics lifecycle (conceptualization, data collection, analysis, and recommendations) or when subject matter expertise is required

Develops compelling, logically structured presentations (including story-telling of research/analytics findings) that will be shared at the Talent and business leadership level

Requirements:

Undergraduate degree (4 years) in Computer Science, Statistics, Applied Math or related field. Master's degree preferred.

Use a broad range of analytical skills to discover, mine, and analyze data to precisely reflect the organization’s or client’s needs and improving deliverable quality through verification and validation of results

Ability to work independently and manage multiple task assignments

Skilled at communicating with a cross-functional team regarding deliverables, schedules, and issues

Creative problem-solving skills related to team, project, and cross-functional issues

Ability to maneuver in a matrix environment, leverage indirect reporting resources, and work well in ambiguous situation",Undefined,indeed,e402ad60d639bb964ef1c9b6c6238f58
Junior Data Scientist (m/w/d),Accounting,BARMER,Wuppertal,North rhine-westphalia,Germany,2019-07-30,"Wie Sie mit Ihrer Arbeit etwas Gutes tun

Sie

führen auf Basis (un-) strukturierter Daten Analysen durch

bringen Algorithmen, statistische Modelle und Verfahren wie Business Analytics und Predicitive Analytics zum Einsatz

entwickeln Abfragen und Analysetools / -verfahren bzw. optimieren diese

bereiten Ihre Analyseergebnisse zielgruppengerecht auf und leiten Handlungsempfehlungen ab

beraten mit Ihrer Methodenkompetenz zu fachlichen Fragestellungen aus dem Leistungs- und Vertragsbereich

entwickeln bestehende Prozesse weiter

Das zeichnet Sie aus

Sie

haben ein Studium der Mathematik, Statistik, Informatik, Gesundheitsökonomie mit den Schwerpunkten Controlling oder Informatik absolviert

können erste praktische Erfahrungen in statistischen Methoden (z. B. Predictive Analytics, Machine Learning, Data Mining) vorweisen

sind vertraut mit SQL-Programmierung und haben eine hohe Affinität zu Massendaten

besitzen sehr gute Kenntnisse in MS SQL-Server/MS Visual Studio DB2, sowie Excel und Access

verfügen über Erfahrungen mit Statistik-Anwendungen wie SPSS, „R“ oder „Phyton“

besitzen eine zielorientierte Arbeitsweise und können Ergebnisse adressatengerecht aufbereiten und präsentieren

sind hochmotiviert, Verbesserungspotenziale zu erkennen und aktiv zu realisieren 

Einsatzort

Wuppertal

Arbeitszeit

38,5 Stunden wöchentlich

Einstellungstermin

kurzfristig (zunächst befristet auf 24 Monate)

Ihr persönlicher Kontakt für Fragen

Michael Heimhardt

Telefon: 0800 333004 992-961

Haben wir Ihr Interesse geweckt?

Wir freuen uns auf Ihre Online-Bewerbung.",Undefined,indeed,3123a5b46ee805f30ed92c1c81a3c31d
Data Engineer,Engineering-or-architecture,"Company Info Follow Get job updates from Amazon Web Services, Inc. Amazon Web Services, Inc. 35,654 reviews Amazon is guided by four principles: customer obsession rather than competitor focus, passion for invention, commitment to operational ex...",Seattle,Washington,United states,2019-07-31,"BA/BS Degree required; advanced degree or certification preferred.

Custom SQL and ETL expertise required.

3+ years of hands-on experience with data visualization, data warehouse, data preparation, and analytics tools.

Practical experience with requirements gathering for BI Solutions (end-to-end), over multiple technologies, size, and scale of projects.

Self-starter who can operate independently.

Able to influence decisions through effective verbal and written communication and logical reasoning.

Demonstrated ability to manage multiple competing priorities simultaneously and drive projects to completion.

Sound business judgment, proven ability to influence others, and track record of taking ownership.

Demonstrated business acumen and the ability to apply technology solutions to solve business problems.

Amazon Web Services (AWS) is the leading cloud provider, offering virtualized infrastructure, storage, networking, messaging, analytics, and other web computing services to customers all over the world. AWS operates a globally distributed environment at massive levels of scale. Businesses, educational institutions and governments around the world depend on AWS for secure cloud services and solutions.

The Sales Systems and Data Team within AWS ensures that our Field Sales and Commercial Operations teams have the world-class data and analytics tools required to scale with our rapidly expanding business. We are seeking a Senior Data Engineer to support multiple projects and initiatives as we continue to build new capabilities around business analytics.

This individual will work closely with our Business Technology & Solutions (BTS) group while engaging directly with business leaders, operations leaders, and field users. In addition to having deep technical skills and a passion for learning the latest cutting edge tools, this individual will have demonstrated experience working on cross-functional teams to develop creative data and analytics solutions.

The ideal candidate will have strong analytical skills to critically evaluate information gathered from multiple sources, reconcile conflicts, decompose high-level information into details, and abstract up from low-level information to a more general understanding.

Necessary technical skills include a high level of expertise using SQL and Python to work with data warehouses like Redshift and familiarity with one or more cutting edge analytics tools like Tableau, Alteryx, Data Robot, and/or R.

Practical experience with requirements gathering for BI Solutions (end-to-end), over multiple technologies, size, and scale of projects.

Self-starter who can operate independently.

Able to influence decisions through effective verbal and written communication and logical reasoning.

Demonstrated ability to manage multiple competing priorities simultaneously and drive projects to completion.

Sound business judgment, proven ability to influence others, and track record of taking ownership.

Demonstrated business acumen and the ability to apply technology solutions to solve business problems.

Experience working within a high-growth, global technology company

Advanced degrees, certifications, or coursework in areas of business intelligence, computer science, or analytics

Experience with data storage and warehousing solutions such as S3 and Redshift.

Expertise developing custom SQL for developing data pipelines

Expertise in Tableau, Quicksight, or equivalent BI tool

Experience developing Python scripts to support data and analytics automation

Familiarity with Salesforce.com

Familiarity with AWS Platform

Amazon.com is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation / Age.",Undefined,indeed,4e127970401df809be05acd2df62e3ce
Data Scientist,Scientific,Lion Pty Ltd,#N/A,Queensland,Australia,2019-07-30,"We are now recruiting for a Data Scientist, to join Lion Beer Australia on a full time permanent basis. This role reports into our Supply Chain Insights Leader and will be located in our Milton Brewery in Brisbane.

As a Data Scientist, you will support Supply Chain decision making by providing insights from data using data mining and analytics solutions. This will involve supporting in the development of automated reporting systems and/or processes that enhance Supply Chain technical data analytics, diagnostics and decision support effectiveness.

You will also liaise with a number of internal stakeholders, so not only will you enjoy working with data and algorithms, but you will work cross functional stakeholders to identify opportunities for leveraging data to drive business improvements.

Day to day you will partner with the Digital Technology and Automation teams to ensure data collection includes the relevant information for building analytic systems.

This role would suit a natural problem solver with an inquisitive analytical mind, and we'd be keen to receive applications from recent Graduates.

We believe our people have it in them to be outstanding.

Empower yourself to achieve – start a conversation with us today.",Undefined,indeed,1b248ca44e78cf7f34ee578355004680
Data Scientist - Client Engagement,Hospitality-or-travel,LSQ,Orlando,Florida,United states,2019-07-21,"Job Title: Data Scientist (Client Engagement)

Location: Orlando, Florida

Manager: Head of Data Science

About LSQ

LSQ is a technology-driven provider of accounts receivable financing to companies who need working capital but may not be able to obtain sufficient financing from their bank. Our focus is to help businesses release the liquidity tied up in their accounts receivable. With financing from LSQ, a business can purchase more inventory, fill more orders, and take advantage of new growth opportunities. Our technology and data driven approach to providing working capital, along with our accounts receivable management services, allows our clients to driving business success.

Job Overview

LSQ is searching for a Data Scientist (Client Engagement) to join our growing team of analytics experts. The hire will be responsible for building data driven tools to automate and scale client service operations in areas of purchasing, client behavior, operations engagement, contact management and accounts receivable process modeling. The ideal candidate is an experienced researcher and data wrangler who enjoys applying complex theories to solve real world business problems. The Data Scientist will need to collaborate effectively with both technical (engineers, data experts) and non-technical (business users) colleagues to bring the data to life.

Responsibilities of Data Scientist (Client Service)

We have 20+ years of real-world commercial data – we’ve observed businesses and their interactions with other businesses across market cycles, industries, and catastrophic events. Build client service tools that optimize for velocity and scale.

Build client service tools that optimize science and art – you will work with client operations experts who have been in the business for a long time (and learned from client success stories). Augment human interactions and decisions with machine and cognitive computing.

Lay the foundation for scale. A data science framework for optimal data acquisition, model training and deployment. Don’t take short-cuts. Bring quantitative and statistical rigor to your body of work.

Lead by example. You are joining a data team at ground-level. Building and inserting a data team, into a 20+ year old company (organism) will be hard, but rewarding.

Qualifications for Client Engagement Data Scientist

Curiosity, Grit, and Humility

5+ years of experience of hands-on data science role

Previous experience of building real life demand forecasting, operations research, simulation and artificial intelligence tools should be beneficial, but not required

Bachelor or Masters degree in Data Science, Operations Research, Computer Science, Industrial Engineering, Statistics, or another quantitative field

A toolkit of modern data science techniques

Experience with any data science tools/packages: Python, R, SAS, XGBoost, TensorFlow, NLTK

Experience with any big data tools: Hadoop, Spark, Kafka, Data Bricks

Experience with any reporting tools: Tableau Server, Power BI, SSRS, Excel

Experience with any AWS cloud services: EC2, EMR, RDS, Redshift, Aurora, S3

Experience with any Stream-processing systems: Storm, Spark-Streaming

Position Type and Expected Hours of Work:

This is a full-time position. Days and hours of work are Monday through Friday, 8:00 a.m. to 5 p.m. Occasional evening and weekend work may be required as job duties demand.

Physical Demands:

While performing the duties of this job, the employee is regularly required to sit and use hands to finger, handle, or feel. The employee is frequently required to reach with hands and arms and talk or hear. The employee is occasionally required to stand; walk and stoop, kneel, crouch.

Travel:

There will be minimal travel required for this position.

LSQ is an Equal Opportunity Employer that does not discriminate on the basis of actual or perceived, race, religion, color, sex (including pregnancy and gender identity), sexual orientation, parental status, national origin, age, disability, family medical history or genetic information, political affiliation, military service, any other non-merit based factor or any other characteristic protected by applicable federal, state or local laws. Our leadership team is dedicated to this policy with respect to recruitment, hiring, placement, promotion, transfer, training, compensation, benefits, employee activities and general treatment during employment. If you’d like more information about your EEO rights as an applicant under the law, please click here http://www1.eeoc.gov/employers/poster.cfm",Undefined,indeed,79a51fe2201eea29b5164c7e8f12838d
Data scientist,Administrative,TOSS-EX PTE. LTD.,#N/A,#N/A,Singapore,2019-07-31,"Job Description and Responsibilities

Our products are focussed on Mobile Apps, IoT, Payment Gateway and many other innovative ideas that focus on Data Science, machine learning, AI, Cryptography and other niche technologies . We offer a range of solutions that bring immediate business benefits to our global customers leveraging big data, statistical and mathematical modelling techniques, social analytics, and mobile descriptive analytics for new business insights.

Role Description:

The role will participate in requirement gathering, system design, model implementation, code reviews, testing, and maintenance of the platform. You will be part of a highly focused development team that includes data scientists, data engineers and business analysts to help build products and specialized services on offer to clients across multi-platform environment. The role offers a high degree of challenge and provides opportunity to experiment offerings that speaks of innovation with a high velocity and quality

2+ years of Analytics experience in developing applications using Python, predictive modelling and analysis.

Experienced in writing a good, clean, testable, Python code.

Experience with MySQL, Django and git.

Knowledge of Image processing libraries such as OpenCV, PIL, and pytesseract would be an added advantage.

Basic knowledge of Agile development practices.

Good understanding of numpy, scipy, pandas and scikit-learn libraries.

Strong analytical and problem solving skills.

Familiarity with the fast-paced startup environment and culture.

A team player with excellent written and verbal communication skills.

Will be a plus if the Candidate has experience as a SQL Developer.

~",Undefined,indeed,d59d7bc3eac97321763ca9f7da7c387d
Data Scientist,Computer-or-internet,Company Info Follow Get job updates from Varen Technologies 5 reviews,Reston,Virginia,United states,2019-07-23,"At Varen, our performance is measured by the success of our clients, and our reputation for service, superior quality, objectivity, integrity and results. Our reputation is everything to us as we are committed to being a trusted advisor to our nation’s decision makers in a day in age that demands acute attention to detail in a fast-paced environment. Varen is seeking to add the sharpest technical professionals who share our passion for ensuring the mission success of our customers at all times.

POSITION DESCRIPTION:

Varen Technology is looking for a SI Expert/Data Scientist to join our growing company. This is an opportunity to take on new transformational support in the areas of Strategic Workforce Planning, Learning, Leadership and Employee Development, Diversity and Inclusion, Performance Management and Workforce Analytics. Responsibilities include, but are not limited to the following:

Provide workforce analytics support to the Sponsor

Analyze workforce data to provide insights and identify trends

Develop and refine workforce model(s) and accompanying data structures where needed to capture and report on the workforce composition in a consistent manner over time

Create data models to support informed executive-level decision making, scenario

planning, and workforce strategy development. Example areas of focus may include, but are not limited to: onboard personnel aligned with the new workforce construct, hiring/attrition projections and patterns, skills and learning assessments/needs, demand/capacity modeling, workforce engagement, and workforce alignment with mission priorities, digital technologies, and/or industry trends

Work collaboratively with individuals in other work units to develop integrated models

that integrate workforce data with other types of data to show linkages and patterns

Use an array of data analytics techniques to analyze and present workforce data

Respond to workforce data inquiries with creative visual data presentations

Independently conceive, prepare and communicate workforce analytics through complex graphics, computational models and tools, and written/oral assessments

Continually interface with executive level management requiring the planning, presentation and briefing of information

REQUIRED EXPERIENCE:

Extensive knowledge of workforce analytics

Proven experience in conducting advanced modeling and data analysis, applying varied mathematical and data analytics techniques and developing-models in support of organizational strategy and management.

Computer programming skills (languages, packages) as needed to support the management of data and application of tools/models.

Demonstrated success in developing strategic goals and leading complex programs and well as meaningful change.

Proven experience in designing, developing and delivering executive level

communications on organization transformation and business process changes. Ability to

prepare presentations and to present information to senior managers.

Experience with project development lifecyc1e and systems operations.

Proven experience leading and actively participating in project teams.

Proven ability to interact with customers, senior leadership and program managers in a highly matrixed environment.

Ability to translate complex findings into an easily understood narrative (i.e., tell a story with the data) in graphical, verbal, and written form.

Demonstrated excellent communication and customer support skills. The candidate will be supporting a high profile program that will require coordination across the organization and with front office/executive level management.

Demonstrated experience providing requirements gathering and analysis, configuration management, performance measurement and metrics.

Demonstrates excellent writing skills and ability to craft clear concise request for funding and responses to tasking.

Demonstrates excellent oral communication skills to brief management on resource issues.

Proven ability to interact with customers, senior leadership and program managers in a highly matrixed environment.

A Bachelor's degree (or equivalent experience (3 years for Bachelors) in Information Systems, or a scientific discipline

Minimum of 10 Years' relevant experience, 3 years in Intelligence Community

CLEARANCE REQUIREMENT:

TS/SCI w Poly Clearance

Varen Technologies, Inc. is an Equal Opportunity Employer and applicants receive lawful consideration for employment without regard to race, religion, color, gender, age, national origin, disability, or veteran status.",Undefined,indeed,023d85651acd3bd84ab710ee5144b766
"Lead Data Engineer- Raleigh, NC- $140K+",#N/A,Jefferson Frank,Raleigh,North carolina,United states,2019-07-31,"Lead Data EngineerAs a Lead Data Engineer, you will be implementing solutions for our clients customers. You will collaborate with customers, working on site when needed, to comprehend customer requirements and needs, translating these into specifications to develop the solutions from and delivering solutions to the customer. You will also be assessing customer needs, designing and developing data models, and sharing your expertise throughout the deployment process. Location: Raleigh, NCSalary: $140K+Roles and Responsibilities:Access, document and translate goals, objectives, problem statements to offshore and onshore managementInterface with Client project sponsors to interpret client needsAttend customer meetings as neededAsses use cases for numerous teams within the client companyDevelop data modelsAdvise on database performanceTeach technical data modeling concepts to a variety of audiences (i.e. developers, data architects, business users, and other IT professionals)Document and report product response in order to increase user experience Skills and Qualifications:Bachelor's degree in Computer science or equivalentExperience with Cloud Platforms (AWS, GCP, or Azure)Skilled with migrations from on premise to the cloud of choiceCustomer facing experience is nice to seeSkilled with Redshift, Snowflake, and/or BigQueryOn premise experience with Cloudera, Oracle, SQL Server, or similarCompany Rewards:Benefits packageSalary- $140K+Collaborative work environment401K matchBonus (Company & Performance Based)Generous PTO policyContact Details: Looking to fill this position immediately. If interested, please contact j.laroche2@jeffersonfrank.com or call 813-437-6879.Jefferson Frank is the Amazon Web Services (AWS) recruiter of choice. We work with organizations worldwide to find and deliver the best AWS professional on the planet. Back by private equity firm TPG Growth, we have a proven track record servicing the AWS permanent and contract recruitment market and, to date, have worked with over 30,000 organizations globally from our offices in North America, Europe, and Asia-Pacific.At Jefferson Frank, our mission is simple: we want happy customers. Whether you're an AWS professional walking into your dream AWS job, or an organization hiring an incredible contractor for your cloud migration project, our goal is to deliver an unrivaled customer experience. Work with us and you'll get the personalized experience you deserve- one you'll simply not find at any other recruitment agency. At Jefferson Frank, we find great people great jobs in AWS.",Full Time,careerbuilder,dce47327e82269c0bcdf72966a030d28
LEAD DATA ENGINEER - ATL - AZURE/ PYTHON + BONUS,#N/A,Nigel Frank International US,Atlanta,Georgia,United states,2019-07-31,"Key ResponsibilitiesCollaborate to architect and implement end-to-end cloud infrastructure (analytics, compute, databases, DevOps, identity, integration, management, networking, security, and storage)Leverage technologies such as the Azure BI Stack, BI and GIS visualization platforms, and modern developer tools to execute innovative solutions that facilitate data-driven analysis, automation, and data scienceApply dimensional data modeling to solve business problemsAnalyze, develop, and maintain data pipelines from internal and external sources, utilizing Python and Azure Data FactoryProfile and analyze data in designing scalable solutionsApply and build automated test-driven development, continuous integration/delivery, and version control best practicesPreferred QualificationsDegree in Computer Science, Engineering, Mathematics, Statistics or related quantitative field5+ years' experience in RDBMS systems, data warehousing, advanced SQL Server Analytical development, and sophisticated data analysisExpertise with Azure Cloud Technologies (Data Factory, PowerShell, Data Lake and Data Lake Analytics)Extensive experience with Data Modeling and ETL tools, Business Intelligence platforms, API Integration, and Object-Oriented Programming (OOP)Ability to thrive in a cross-functional environment utilizing modern technologies (Python, Git, Jenkins, Octopus Deploy, Tensorflow, Domo, ArcGIS, E/R Studio, RedGate DLM Automation and other tools)Experience with messaging/event processing tooling and frameworks such as Azure Event Hub, Kafka, KinesisWorking knowledge of Azure HDInsight + Spark, Azure Databricks, Azure Stream Analytics Job Requirements LEAD DATA ENGINEER - ATL - AZURE/ PYTHON - COMPETITIVE PAY + BONUS",Full Time,careerbuilder,46b5a339caf4f7ec0c74a671cd07f6b8
"Big Data Engineer (Snowflake) - Glendale, AZ",Computer-or-internet,"Cognizant Technology Solutions 11,603 reviews - Glendale, AZ 85301",Glendale,Arizona,United states,2019-07-27,"At Cognizant, we believe those who challenge the way they work

today will lead the way tomorrow. In the modern digital economy, our clients

are looking to differentiate their businesses and seize the enormous growth

opportunities that digital makes possible. At Cognizant, we help them do just

this. We engage clients in envisioning and building creative products and

experiences, delivered through a powerful digital-ready IT backbone. In

addition, we are hiring for various roles. If you are passionate and driven

about being involved in shaping next generation digital solutions, give us a

shout.

Title – Big Data Engineer (Snowflake)

Location – Glendale, AZ

Travel – No travel will be required for

this engagement as all work will be on onsite

Project – Writing SQL queries against Snowflake, Developing scripts suing UNIX, Python

etc to do Extract, Load and Transform data

Your Responsibilities:

Snowflake

Senior developer responsible for architecting and implementing very large scale

data intelligence solutions around Snowflake Data Warehouse

A

solid experience and understanding of architecting, designing and

operationalization of large scale data and analytics solutions on Snowflake

Cloud Data Warehouse SnowSQL

Writing

SQL queries against Snowflake Developing scripts Unix, Python etc to do Extract,

Load and Transform data

Provide

production support for Data Warehouse issues such data load problems,

transformation translation problems

Translate

requirements for BI and Reporting to Database design and reporting design

Understanding

data transformation and translation requirements and which tools to leverage to

get the job done

Excellent

presentation and communication skills, both written and verbal

Ability

to problem solve and architect in an environment with unclear requirements

Our strength is built on our ability to work together. Our diverse

backgrounds offer different perspectives and new ways of thinking. It

encourages lively discussions, inspires thought leadership, and helps us build

better solutions for our clients. We want someone who thrives in this setting

and is inspired to construct meaningful solutions through true collaboration.

If you are comfortable with ambiguity, excited by change, and

excel through autonomy, we would love to hear from you

Technical Skills SNo Primary Skill Proficiency Level * Rqrd./Dsrd. 1 Snowflake PL1 Required 2 Data Modeler PL1 Required 3 PL/SQL PL2 Required 4 Unix Shell Scripting PL1 Required

Proficiency Legends Proficiency Level Generic Reference PL1 The associate has basic awareness and comprehension of the skill and is in the process of acquiring this skill through various channels. PL2 The associate possesses working knowledge of the skill, and can actively and independently apply this skill in engagements and projects. PL3 The associate has comprehensive, in-depth and specialized knowledge of the skill. She / he has extensively demonstrated successful application of the skill in engagements or projects. PL4 The associate can function as a subject matter expert for this skill. The associate is capable of analyzing, evaluating and synthesizing solutions using the skill.

Employee Status : Fixed Term Contractor

Shift : Day Job

Travel : No

Job Posting : Jul 26 2019

About Cognizant Cognizant (Nasdaq-100: CTSH) is one of the world's leading professional services companies, transforming clients' business, operating and technology models for the digital era. Our unique industry-based, consultative approach helps clients envision, build and run more innovative and efficient businesses. Headquartered in the U.S., Cognizant is ranked 193 on the Fortune 500 and is consistently listed among the most admired companies in the world. Learn how Cognizant helps clients lead with digital at www.cognizant.com or follow us @Cognizant.

Cognizant is recognized as a Military Friendly Employer and is a coalition member of the Veteran Jobs Mission. Our Cognizant Veterans Network assists Veterans in building and growing a career at Cognizant that allows them to leverage the leadership, loyalty, integrity, and commitment to excellence instilled in them through participation in military service.",Undefined,indeed,8871d8f961f2c8761a782078508348b8
"Data Scientist - Round Rock, TX",Computer-or-internet,"DELL 9,525 reviews - Round Rock, TX 78682",Round rock,Texas,United states,2019-07-27,"Data Scientist

Competitive salary

Round Rock, TX

Dell provides the technology that transforms the way we all work and live. But we are more than a technology company — we are a people company. We inspire, challenge and respect every one of our over 100,000 employees. We also provide them with unparalleled growth and development opportunities. We can’t wait for you to discover this for yourself as a Data Scientist on our Global Process Engineering and Data Science team in Round Rock, TX.

Data Science is all about breaking new ground to enable businesses to answer their most urgent questions. Pioneering massively parallel data-intensive analytic processing, our mission is to develop a whole new approach to generating meaning and value from petabyte-scale data sets and shape brand new methodologies, tools, statistical methods and models. What’s more, we are in collaboration with leading academics, industry experts and highly skilled engineers to equip our customers to generate sophisticated new insights from the biggest of big data.

Key Responsibilities

Interact with business stakeholders, product managers, software engineers, data engineers, and data analysts to create data science products

Write SQL queries, python scripts to clean, wrangle data from multiple sources making them model ready

Use techniques which includes (but not limited to) Natural Language Processing, Machine Learning, Data Pipelining to build scalable models

Build Data Pipelines & platform to operationalize the models at scale using Domino Data-lab & Apache Airflow

Create Data Dictionary for the reusable data-sets and document as Knowledge Articles

Become a subject matter expert of the data to create and refine features for modeling

Evaluate data science models in terms of outcomes and computational performance

Able to troubleshoot software issues with 3rd party support

Essential Requirements

5+ years of related experience with a Bachelor’s degree; or 3+ years with a Master’s degree; or a PhD without experience; or equivalent experience

Strong database knowledge and expertise in SQL

Solid programming skills to retrieve, analyze and process data, and build machine learning models from the ground up (Python/R)

Data Science Platforms like Domino Data Lab, Apache Airflow, AWS and Google Cloud (working environment to build and deploy models)

Machine Learning techniques like Ranking, Classification, Clustering, Regression and Topic Modeling

Deep knowledge of machine learning, information retrieval, data mining, statistics, NLP or related field

Familiarity with Agile practices

Benefits

We offer highly competitive salaries, bonus programs, world-class benefits, and unparalleled growth and development opportunities — all to create a compelling and rewarding work environment.

If you share our passion for data and you’re keen to play a key role in driving progress, this is your opportunity to develop with Dell.

Dell is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at Dell are based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, national, social or ethnic origin, sex (including pregnancy), age, physical, mental or sensory disability, HIV Status, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, past or present military service, family medical history or genetic information, family or parental status, or any other status protected by the laws or regulations in the locations where we operate. Dell will not tolerate discrimination or harassment based on any of these characteristics. Learn more about Diversity and Inclusion at Dell here.",Undefined,indeed,202b48240c2e3e99fecae779ce64f047
"data scientist, Insights & Analytics - Seattle, WA",Computer-or-internet,"Starbucks 35,939 reviews - Seattle, WA 98134",Seattle,Washington,United states,2019-07-27,"Now Brewing – data scientist! #tobeapartner

From the beginning, Starbucks set out to be a different kind of company. One that not only

celebrated coffee and the rich tradition, but that also brought a feeling of connection. We are known for developing extraordinary leaders who share this passion and are guided by their service to others.

Are you a data scientist who thinks like a business owner? Are you passionate about solving business problems by designing optimal experiments and deploying solutions at scale using 1st, 2nd, and 3rd party customer data in a next generation analytics infrastructure to help Starbucks optimize digital engagements with our 75M customers?

If you answered “yes” to the questions above, please come and join our Data Science team. You will help optimize app-level product recommendations, digital menu board content, voice-order recommendations, drive-thru personalized menu board content, 1-1 and in-store marketing via personalized content on order labels and POS systems.

As a data scientist, your responsibilities and job functions will include…

Data Preparation:

Under direction of more senior data scientists, execute extraction and synthesis of data from Azure: data lake storage (ADLS), blob storage, SQL DW, SQL Server; and legacy systems: Oracle and its companion data lake storage

Under direction of more senior data scientists, process 1st 2nd, and 3rd party customer data in next generation privacy compliant infrastructure

Business Understanding & Provide Optimal Solutions:

Has minimal understanding of Starbucks business, and business acument in general. Requires mentoring and guidance

Machine Learning and Data Product Dev and Deployment:

Under direction of more senior data scientists, contribute to AI and Machine Learning models in batch, real-time

Develop data pipelines and scalable Restful APIs to create and enable analytical applications

Statistics and Model Development and Deployment:

Leverage the latest cloud technologies, existing and immerging statistical and machine learning techniques to identify data patterns and trends to solve business problems

With support from more senior data and decision scientists, build and deploy customer segments to facilitate optimal marketing targeting within channels

Via a ""feature factory"" approach, build large numbers of weak learners in a Customer 360 framework

Insights Operationalization:

Under the guidance of more senior data scientists, create clear and concise packaging and presentation of data products and insights to business stakeholders, leaders and the broader analytics community

Data Science Evangelism:

With support from more senior data scientists, establish and foster close collaboration between data and decision scientists, engineers, business and leadership teams to align on technical roadmaps for innovation

Establish brand and team as subject matter experts and trusted advisors for Analytics across departments

Project & Work Management:

Actively participate in an Agile team structure designed to create a bias for action (fail fast/often)

Utilize Wiki and GitHub to share standards and code

Present code to team for review compared to Best Practice

Actively participate in Agile-related meetings: stand-ups, sprint planning, retrospectives, showcases

Participate in Microsoft Azure and other trainings

We’d love to hear from people with:

Education: Min BS/BA with concentration in quantitative discipline - Stats, Math, Comp Sci, Engineering, Econ or similar discipline

1+ years’ professional data science experience

Demonstrated experience with one programming language such as Scala, Java, C++, C#

Demonstrated experience with scripting languages such as Unix Shell (ksh, csh, bash, sh), PowerShell, ARM

Demonstrated experience with cloud tech for data and analytics solutions (Azure, AWS)

Demonstrated experience building and deploying AI / Machine Learning solutions, at scale

Demonstrated familiarity with Web application security, SSL OAuth

Demonstrated self-sufficiency with R or Python (or equivalent)

Retail, customer loyalty, or eCommerce experience preferred

Join us and be part of something bigger. Apply today!

Starbucks and its brands are an equal opportunity employer of all qualified individuals, including minorities, women, veterans and individuals with disabilities. Starbucks will consider for employment qualified applicants with criminal histories in a manner consistent with all federal, state, and local ordinances.",Undefined,indeed,62a1f2856b12d9432d109330252e8687
Data Engineer,Sicherheit,"Die Mobiliar 5 Bewertungen - Bern, BE",#N/A,#N/A,Switzerland,2019-07-15,"Sie wollen auf grüner Wiese bauen und so die Systemlandschaft der Mobiliar nachhaltig prägen? Dann gestalten Sie mit uns die Zukunft – per sofort oder nach Vereinbarung bis 31.12.2019 mit Aussicht auf Verlängerung als Data Engineer Metadaten am Direktionsstandort in Bern mit einem Arbeitspensum von 60-80%.

Ihre Aufgaben

Sie helfen uns das Datenmanagement auszubauen und entwickeln Datenzugriffsapplikationen für das Meta-Datenmanagement.

Bei der Entwicklung und Visualisierung von Datenkatalogen helfen Sie mit.

Mit den Spezialisten für Datenqualität, Data Curation, Informationssicherheit und Datenlogistik arbeiten Sie eng zusammen.

Sowohl auf Stufe der Software-Entwicklung als auch mit dem Management kommunizieren Sie zielgruppengerecht.

Ihr Profil

Eine höhere Aus- oder Weiterbildung in Informatik (oder vergleichbar) haben Sie abgeschlossen.

Sie haben Kenntnisse im Datenmanagement.

Erfahrungen in der Software-Entwicklung mit besonderem Fokus auf Daten haben Sie bereits gesammelt.

Die deutsche Sprache beherrschen Sie in Wort und Schrift.

Ihr analytisches Denken und gute Kommunikations- und Präsentationsfähigkeiten zeichnen Sie aus und Sie behalten auch in einem komplexen Umfeld den Durchblick.

Haben wir Ihre Neugier geweckt? Sprechen Sie diese Herausforderungen an? Dann freuen wir uns, Sie kennen zu lernen.

Bei Fragen stehen Ihnen Frau Andrea Küffer, Recruiting & Sourcing, Telefon 031 389 63 43 oder Bruno Russiniello, Systemplattform und Daten-Architektur, Telefon 031 389 71 67 gerne zur Verfügung.",Undefined,indeed,c03a5d95e8bfe8bea3af13f1b2cebcdb
Senior Data Engineer,Computer,Holiday Extras,#N/A,#N/A,United kingdom,2019-07-16,"At Holiday Extras we believe that time is precious and that holidays are some of the most precious times we have. We’re building the future of travel using innovative technology, a wide choice of products and unbeatable prices. We are looking for an experienced Senior Data Engineer to come and use cutting edge technology to help us revolutionise how customers (7 million and growing) have 
 less hassle, more holiday.    

We make 200,000 travel insurance sales a year at Holiday Extras and it’s our mission to be a UK market leading provider of ‘non standard’ Travel Insurance, offering bespoke cover for customers with medical conditions, alongside a range of niche or bolt on products.The Data team work closely with Insurance to make sure everyone has access to the right data, at the right time. 

We’re in the process of moving our data storage to a scalable environment using 
Google Cloud Services . We are experimenting with live 
streaming data  and improving our 
batch processing. We are continuously 
collecting and exposing data sources to feed new data sets, empowering the business continue to learn and grow. 

We pride ourselves on being able to offer exciting challenges, whilst also providing a flexible, fulfilling environment in which to work, in the heart of the Kent countryside, 5 minutes from the beach. Our Learning Academy, quiet Lounge, supportive environment and focus on personal development, help our team members grow and become experts in their field! We have fortnightly “Project Lounge” days where you have the chance to work on anything extending your knowledge in different business areas or simply collaborate in a project to make a difference to the business. 

You will be joining at an exciting period of exceptional projected growth; Our people move fast and deliver excellence at pace, never accepting second best. We may have been in business 34 years, but Holiday Extras is an innovative and entrepreneurial travel-tech business with a startup mentality. 


Here’s what we’re looking for:   
 


A versatile and experienced data engineer with expertise in writing advanced SQL.  

Experience in at least one other popular programming language such as Python, Bash Shell, Java. You’ll need more than one tool in your toolbox! 

Demonstrable ability to work with a variety of data infrastructure, including relational databases (e.g. DB2, MySQL), and column store (e.g. Google Big Query, Redshift) 

Expertise in building and maintaining reliable ETL jobs 

Experience designing new data models based on multiple data sources. 

Experience with version control software, e.g. Git 

A desire to understand the business and where it’s heading. 

A track record of being solutions focussed and an excellent problem solver, not afraid to make decisions and act quickly. 

A proactive communicator 

Always determined to acquire new skills and learn. 

You’ll have good numerical skills and approach every task with a flexible ‘can do’ attitude. 
 


Desirable Skills:   
 

Experience working with Talend, Luigi or Apache Airflow. 

Exposure to business intelligence tools and dashboards (we use Looker). 

Knowledge of the Insurance industry. 
 


Here’s what you’ll be doing:   
 

You will have autonomy and responsibility to deliver the insurance data requirements to the business. 

You will learn where our data is stored and processed to do this job well. You will have the opportunity to work on new stimulating projects as well as using our existing platforms. 

You will be migrating Insurance data pipelines from legacy platforms to our new cloud based data stack. 

You will be learning and working with cutting-edge tech and solutions. 

You will develop your career in a strong team with a well-defined culture, that is building a fast-moving, disruptive business. 

You will lead in solving Insurance specific challenges and delivering innovative solutions for the business. 

You will be responsible for making data accessible to Insurance users in our business and engaging with the users to understand what their data requirements are. 

You will be supporting end-users to get the most from the data and tools available. 

You will be a self-organised individual who can follow processes well, whilst collaborating with your teams. 

You’re going to have a lot of fun! 
 

If you’ve got a few minutes check out our blogand see what our engineers have to say - tech.holidayextras.com 

Job Type: Full-time 

Flexible Working Options Available: 
 

Flexitime 

Work from home 

Job share 

Part-time",Undefined,indeed,ad68f7b6829bbeab9fb86f6a49b3bf6c
Data Scientist,"[""IT Software - Application Programming"", "" Maintenance""]",ACG Inspection Systems Pvt. Ltd.,Mumbai,Maharashtra,India,2019-07-19,"&lt;ul&gt; &lt;li&gt; Search out and evangelize new and emerging technologies including open source tools&lt;/li&gt; &lt;li&gt;  As Data scientist apply analytical Mindset with a strong statistical background and good knowledge of data structures and machine learning algorithms.&lt;/li&gt; &lt;li&gt;  System design through well-defined interfaces across multiple components, code reviews, leveraging data / telemetry to make decisions&lt;/li&gt; &lt;li&gt;  Actively explore, design, architect, and develop technologies that enable product enhancement, efficiency, update and optimization of real-world systems.&lt;/li&gt; &lt;li&gt;  Work with a talented scrum team to develop and test key product features.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;b&gt;Required Candidate profile&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Hands-on Python along with Java, Perl, or C/C++. ...&lt;/li&gt;&lt;li&gt; Hadoop Platform.&lt;/li&gt;&lt;li&gt; Hands-on SQL Database/Coding.&lt;/li&gt;&lt;li&gt; Apache Spark.&lt;/li&gt;&lt;li&gt; Machine/Deep Learning&lt;/li&gt;&lt;li&gt; Data Visualization, Unstructured data, image processing.&lt;/li&gt;&lt;li&gt; Fair understanding with Image Processing, Embedded Windows/Linux, microcontrollers and/or FPGAs&lt;/li&gt;&lt;li&gt; Hands-on experience with a Secure Development Lifecycle&lt;/li&gt;&lt;li&gt; Experience with MQTT, DDS, OPC-UA, and REST Protocols&lt;/li&gt;&lt;li&gt; Effective communication and interpersonal skills&lt;/li&gt;&lt;li&gt; Demonstrated capability to thrive in a matrixed team environment&lt;/li&gt;&lt;/ul&gt;",Full Time,naukri_com,aedc351f8682eefb3481acecfb40f80a
Data Scientist - Python - BFS - IIT/ DSE/ IIM/ NIT,"[""IT Software - DBA"", "" Datawarehousing""]",Huquo Consulting Pvt. Ltd,Delhi,Delhi,India,2019-07-19,"Data Scientist-IIT/ DSE/ IIMS     Looking for self-driven Python data scientists having 1-4 years of experience of coding in Python.     Must have knowledge in the following areas :     - Data Structures, Lists, Tuples &amp; Dictionaries     - Familiarity with pandas, numpy, scikit-learn &amp; scipy     - Basics of Visualization tools &amp; techniques - maptlotlib, seaborn     - Text mining techniques and libraries in Python, e.g. NLTK basics     - Modelling techniques e.g. Regression (Linear and logit), Classification (SVM, NaiveBayes,etc.)     - Knowledge of PySpark and Hbase.",Full Time,naukri_com,6a83c92e252f7f7468156ba762508590
Agricultural / Environmental Data Scientist,"[""Medical"", "" Healthcare"", "" R&D"", "" Pharmaceuticals"", "" Biotechnology""]",cimmyt,Delhi,Delhi,India,2019-07-19,"Collection ,  assembly ,  processing and visual representation of large datasets to describe patterns in agricultural productivity ,  resilience of cropping systems and corresponding explanatory factors using data mining and machine learning. 
 
Conduct research to identify agricultural ,  climate ,  environmental ,  market and socioeconomic data sources (structured and unstructured) and automate data collection /processing into structured databases with standard meta - data. 
 
Develop and/or adapt seamless ICT - based tools for field data collection ,  passive data capture ,  and cloud - based processing for primary data. 
 
Collaborate with CIMMYT scientists to estimate greenhouse gas emissions from observations of cereal - based farming systems. 
 
Collaborate with CIMMYT scientists and CIMMYT s partners to develop user - friendly decision support tools (dashboards and/or web apps) and ICT - based agricultural advisory systems ,  including back - end design and contributions to front - end architecture ,  as well as training in tool use and efforts to assure dissemination. 
 
Develop and lead an active training program for CIMMYT s partners in South Asia to increase data analytical skills and to institutionalize big - data capacity. 
 
Work with CIMMYT scientists to collaboratively develop a portfolio of high - profile peer - reviewed publications. 
 
Contribute to project design ,  development ,  and implementation. 
 
Perform other duties as requested by the supervisor(s).Required academic qualifications ,  skills and attitudes:  
 
PhD degree in Computer Science ,  Statistics ,  Computer Engineering or similar discipline with application in and/or strong knowledge of agricultural and environmental issues. Candidates may also have a PhD in Agricultural or Environmental Science (or related discipline) with strong evidence of Computer Science ,  Statistics or Computer Engineering skills. 
 
Proficiency in computer programming and statistical computing (e.g. Python ,  R ,  MATLAB ,  FORTRAN). Knowledge of JAVA is beneficial. 
 
Demonstrated experience using machine learning with deep neural architectures to identify patterns in agricultural ,  climate ,  environmental and remotely sensed data ,  and to make practical inferences from research results. 
 
Practical experience and working knowledge in distributed computing system such as Spark ,  Hadoop and ability to build automate workflows across machines and platforms in cloud computing environments. 
 
Knowledge of hardware set - up ,  integration ,  server set - up and maintenance is beneficial. 
 
Demonstrated ability to publish peer - reviewed papers. 
 
The selected candidate should exhibit the following core skills and interests: a) ability to work cooperatively in an interdisciplinary environment and within multi - stakeholder partnerships ,  b) strong interest in assuring development impact from research activities ,  c) organizational skills and delivery orientation ,  d) an interest in training young scientists and national research partners. 
 
The selected candidate must exhibit the following competencies: Teamwork ,  Communication ,  Proactivity ,  Collaboration and Multi - Cultural Awareness.The position is for an initial fixed - term of three (3) years ,  after which further employment is subject to performance and the continued availability of funds. CIMMYT s internationally competitive salary and benefits include housing allowance ,  comprehensive health and life insurance ,  assistance for children s education ,  paid vacation ,  annual airfare ,  contribution to a retirement plan ,  and generous assistance with relocation shipment.",Full Time,naukri_com,de312c1d08f937102876769a73784211
Sr. Data Engineer,"[""Analytics & Business Intelligence""]",TVS Credit Services Limited,Chennai,Tamil nadu,India,2019-07-19,"Job Purpose    This position is responsible to gather and analyze data to solve and address highly complex business problems and evaluate scenarios to make predictions on future outcomes and support decision making. Also responsible to apply ML/AI technologies across the Portfolio to drive greater business value and competitive differentiation to achieve business goals      Key Responsibilities    Gather and process raw data at scale (including writing scripts, web scraping, calling APIs write SQL queries, etc.)    Design, implement and maintain high performance big data infrastructure /systems, &amp; big data processing pipelines scaling to structured and unstructured business requirements    Create web services / API based interfaces to modularize capabilities across lending products    Developing prototypes and proof of concepts for the selected solutions, and implementing complex big data projects    Drive data investigations across organizations and deliver resolution of technical, procedural, and/or operational issues to completion    Conduct timely and effective research in response to specific requests (e.g. data collection, summarization, analysis, and synthesis of relevant data and information)    Adapting and learning new technologies surrounding Big Data ecosystems and ensure learning and growth of team members    Enhance/optimize data migration procedures to include data that is relevant for building analytic systems    Work with business domain experts, data scientists and application developers to identify data relevant for analysis and develop the Big Data solution     Required Candidate profile Qualifications: Masters / Graduate in Computer science, Engineering (CS, ECE, IT etc.), Mathematics, Computational physics  Experience  4+ years in data engineering and warehousing roles  Functional Competencies   Big data tech: Hbase, MapReduce, Flume, Sqoop, Oozie, Zeppelin etc  Data pipelines with Kafka streams, RESTful APIs with SpringBoot, API gateways etc  Heterogeneous data environments: Cloud (AWS, Azure), Relational, NoSQL, GraphDBs in production  SQL and scripting languages like Python, Java / JS, Perl etc  S/w development practices: Agile, devOps CI/CD, automated testing / deployments, WebServices  Behavioral Competencies   Hands-on contributor, passionate about applying tech in businesses  Strong Analytical &amp; Interpersonal skill  Eye for detail     Perks and Benefits  Not Disclosed by Recruiter",Full Time,naukri_com,9aea5e76cb15a2fedb40a2ae23496e66
Data Scientist,"[""IT Software - eCommerce"", "" Internet Technologies""]",The Data Team,Chennai,Tamil nadu,India,2019-07-15,"Experience in Performance tuning of big data applications Data Scientist Location:  Bangalore /  Chennai /  Mumbai 
 
 Role Description TheDataTeam is a boutique consulting firm with strong expertise in big data and data science.  TheDataTeam has a pedigree of implementing advanced analytics solutions for high profile clients,  including award winning solutions.   
 
The Data Scientist is a key role in the organization,  and will be responsible for project delivery on data science projects and data products.  Data scientists are expected to be excellent critical thinkers,  able to reason about business problems and think through them using the tools of statistics,  machine learning and data visualization.  Theyre expected to have breadth of knowledge in statistical analysis,  machine learning,  deep learning and related topics,  with deep expertise in one of the following areas:  computer vision techniques,  sensor data analysis,  recommender systems,  or natural language processing.   
 
The Data Scientist will be expected to be a hands - on practitioner of hypothesis generation,  data preparation,  relational modelling,  statistical modelling,  algorithm design and scalable machine learning.  Theyre expected to prototype applications and develop analyses based on large data sets,  and to be able to present their findings effectively.  The Data Team offers high - impact work with diverse opportunities in the areas of data science.   
 
Some prior experience in doing data science and advanced analytics  (machine learning,  deep learning)  is required.  Skills such as ability to work on large scale Hadoop databases,  bot development,  test driven development and client - facing skills will be considered a plus.  
 
 Required Technical and Business Skills Sound statistics and machine learning fundamentals and ability to perform thorough analyses and evaluate results critically Excellent practitioners with critical thinking skills in data,  machine learning and statistical analysis Good working knowledge of SQL and NoSQL databases,  algorithms and programming paradigms Knowledge of popular cloud platforms such as Azure and ability to build APIs on them Excellent working knowledge of machine learning on technology stacks such as Python,  Numpy,  Scipy,  Scikit - Learn,  Apache Spark and R using libraries such as e1071 and caret Excellent fluency in data manipulation tasks using frameworks such as pandas,  plyr,  Spark Good working knowledge of deep learning frameworks such as Tensorflow,  PyTorch,  Keras,  Caffe and an ability to work with frameworks such as Tesseract,  OpenCV,  etc.  Ability to work effectively in a Linux environment,  on cloud - based virtual machines and containers Excellent interpersonal,  presentation and written communication skills are a must Good to have skills:  business analysis,  business intelligence,  bot development experience,  TDD,  CI/ CD methods,  Scala,  industry exposure to manufacturing,  BFSI or e - commerce Education and Work Experience Requirements Bachelors degree in computer science,  engineering or applied mathematics Masters degree in statistics,  business or analytics PhD or other research expertise seen favourably but not strictly required Between 4 and 6 years of demonstrated data science experience in the industry Relevant certifications in data science are good to have Beginners in data science without experience need not apply Senior Data Scientist Location:  Chennai /  Bangalore 
 
 The Data Team is a boutique consulting firm with strong expertise in big data and data science.  The Senior Data Scientist is a key role in the organization,  and will be leading project delivery on data science projects or data products.  The Senior Data Scientist is an important role within the organization responsible for providing expertise,  thought leadership,  mentorship and leadership in the area of statistical analysis,  data analysis and data science.  Accordingly senior data scientists are expected to a hands - on practitioners in business analysis,  hypothesis generation,  data preparation,  relational modelling,  statistical modelling,  algorithm design and scalable machine learning and deep learning.  Theyll be expected to provide deep expertise in these areas.  In addition,  Senior Data Scientists are expected to mentor data analysts and data scientists on project deliverables,  and ensure quality and timeliness in the output.  The Data Team offers high - impact work with diverse opportunities in the areas of data science for Senior Data Scientists to grow into roles such as business consulting.  Prior experience in doing data science and managing data science teams is required for this role.  Experience in working on large scale Hadoop databases is required for this role.  Past experience in bots and API development,  test driven development,  continuous delivery are preferred.  Client facing skills are considered a plus.  
 
 Required Skills True depth of knowledge in statistics,  machine learning,  cloud platforms and databases Critical thinking skills in business with the ability to confidently face clients and mentor data scientists A highly imaginative mind set and the ability to formulate new and relevant hypotheses from the data Ability to perform advanced statistical analysis on diverse data sets in Python,  R,  Scala and Java Ability to implement scalable machine learning and statistical analysis algorithms with frameworks such as Spark,  Tensorflow or Torch Current knowledge of cloud technologies and architectures such as on Azure,  and hands on skills in implementing machine learning algorithms at scale Expertise validating and critically evaluating machine learning algorithms and their performance Ability to work in a Linux environment,  on cloud - based virtual machines and containers Should have managed a team in past roles in a managerial setting,  or directly faced clients Excellent interpersonal,  presentation and written communication skills Education and Work Experience Requirements Bachelors degree in computer science or applied mathematics  (Masters degree or PhD preferred)  Higher degree in business,  statistics,  machine learning or computer science is a plus Between 8 and 10 years of demonstrated experience in the industry including significant prior experience in data analysis and data science Relevant certifications in data science will be considered favorably UI Developer Location:  Chennai/ Bangalore 
 
 Role Description The Data Team is looking for User Interface Developer to join its ranks.  The User Interface Developer is primarily responsible for implementation of design concepts,  collaterals,  intuitive interfaces presentations,  and be a part of engineering team to deliver engaging collateral and user interfaces.  The role seeks to please human beings by understanding how computers are used and how the experience could be streamlined to create a better end result.  This requires some analytical thought processes.  The UI Developer is a Graphic Designer and a people pleaser.  Their designs are practical and focused on engaging the user of an app or website or program.  
 
 Responsibilities Create Web application front end as per design Integrate front - end application with the application business layer Follow best practices and standards for accessibility and cross - browser compatibility Collect feedback from design and technical staff on Website development needs Understand executing accessibility and progressive enhancement presentation Coordinate with Interface Design Architects for meeting accessibility standards at code level Create conceptual diagrams,  visual mock - ups,  and manage detailed user interface specifications Conduct usability testing to resolve interface problems Engage in requirement specification process for new software functionality Ensure design consistency with clients development standards and guidelines Design and build UIs on any server platform in a team environment Required Skills 2+ years of experience developing intuitive products Excellent understanding of HTML5,  JavaScript,  CSS,  Ajax and JSON Excellent understanding of at least one JavaScript framework like AngularJS or React Good understanding of NodeJS Experience on working with Github/ Bitbucket,  Jira Extensive use of APIs and understanding of HTTP, REST and Swagger API.  Experience with building web - based mobile applications Others Good communication and interpersonal skills Ability to understand technical concepts into intuitive designs Collaboration skills to coordinate with product management and marketing teams Preferred Qualifications Experience Bachelors degree in Computer Science,  Design Engineering or related technical discipline Experience of working in a start - up environment Passionate about all things UX and other areas of design and innovation Marketing Trainee TheDataTeam is an AI solutions company helping businesses achieve unparalleled agility by building AI solutions - built Data - Native with RoboticDataScience.  The company has successfully implemented over 30 enterprise AI solutions across India and APAC nations.  TheDataTeam specializes in building scalable turnkey AI solutions with quick turnaround and ease in business process integration.  TheDataTeams Cadence suite comprises a specialized set of turnkey AI solutions designed to enable cognitive customer experiences across the entire lifecycle,  starting from customer acquisition and onboarding,  cross - selling and up - selling to grow revenue per customer,  and to service customers as they mature significantly reducing incidents of dissatisfaction and churn.  
 
 Role Description and Responsibilities Own content coordination,  management and publishing execution and drive content marketing consistency Coordinate with agency,  freelance content writers,  video makers and other stakeholders Take complete responsibility of social media marketing and employ marketing analytics techniques to gather important data  (social media,  web analytics,  rankings etc.  
 
 Compose and post online content on the companys website and social media accounts Help create marketing literature  (brochures,  press releases etc)  to augment the companys presence in the market Support marketing executives in organizing various projects Conduct market research and analyse consumer rating reports/  questionnaires Update spreadsheets,  databases and inventories with statistical,  financial and non - financial information Assist in the organizing of promotional events and traditional or digital campaigns and attend them to facilitate their success Prepare and deliver promotional presentations 
 
 Required Technical and Business Skills Exquisite communication and people skills Fluency in written English Proven experience as a marketing assistant or currently pursuing specialization in Marketing Good understanding of office management and marketing principles Demonstrable ability to multi - task and adhere to deadlines Well - organized with a customer - oriented approach Good knowledge of market research techniques and databases Excellent knowledge of MS Office,  marketing computer software and online applications  (CRM tools,  Online analytics,  Google AdWords etc. )  Exquisite communication and people skills Education and Work Experience Requirements Masters degree in Marketing 0 - 1 - year work experience Relevant certifications in google AdWords",Full Time,naukri_com,436ac6d065e15be4116c563e8f84c85e
Data Scientist - Java/c++/python,"[""IT Software - DBA"", "" Datawarehousing""]",HungryBIrd Consulting Services,Secunderabad,Andhra pradesh,India,2019-07-19,"Duties and responsibilities:    - They are looking for a Data Scientists to develop and enhance our fraud prediction models.    Preferred:    - You can scale offline models to the online world. You are able to aggregate, slice and dice large and wide data sets from public and customer sources to generate invaluable insights. You are obsessed over data cleanliness and canonicalization. You love to find data insights that solve critical problems in a complex data environment. Required Candidate profile Qualifications &amp; Experience:  - MS or PhD in Computer Science, Engineering, Operational Research, Statistics, Mathematics or another quantitative field of study  - 2-7 years experience in machine learning, statistics, or data mining  - Data analysis and exploration skills in R, Scala, Matlab, Excel, Weka and other tools  - Production experience in mix of: Java, C++, Python, Pig, Hive, SQL, Hadoop  - Knowledge of Javascript, jQuery, Tableau for a rich and interactive result visualization is a plus  - Interest in the latest techniques in feature representation and learning algorithms is a plus  Working conditions:  - No of Employees: 0-50  - Work Time: 10am to 7Pm  - Monday to Saturday  - Sunday Off",Full Time,naukri_com,42c08b3d65d6e26ab310db14c2d1cc63
GCP Data Engineer | Piscataway NJ | Urgent Need,#N/A,Virtusa,Piscataway,New jersey,United states,2019-07-29,"GCP Data Engineer | Piscataway NJ |Rate: Open Must Have: Professional data engineer certification in GCP 3 Years Hands-On Experience working on GCP data related services Expert level knowledge on Cloud DataFlow, DataProc, Cloud storage, Cloud SQL Hands-on experience on bash/java/python/ruby scripting Hands-on experience on BigQuery, Pub/Sub, Cloud Spanner Building data migration and data integration utilities/accelerators from on-prem to Cloud databases Designing and building complex dataflows (ETL routines) within GCP cloud environment Re-engineering existing RDMS databases to fit the target database standards of Cloud SQL, BigQuery Hands-on experience with Security principles on public clouds, Encryption, Compute, Identity & Access Management Documenting design and source to target mapping documents Designing and building orchestration framework for complex workloads within GCP Designing cloud system applications within the most optimal cost and performance benchmarks Hands-on experience on Jenkins, Chef/Ansible/Puppet & Terraform Hands-on experience on DBs: Oracle, MS SQL, MongoDB Hands-on experience on Cloud composer or similar tool for workflow orchestration Good to Have: Professional cloud developer certification in GCP Docker/Kubernetes hands-on experience Hands-on experience on Web Applications Experience on ELK/EFK, Machine Learning, Data Analytics Data warehousing experience on traditional database environments",Contract,dice,c53ad8f136180d9d1eb57588008f9d16
Data Scientist,#N/A,Perspecta,Washington,District of columbia,United states,2019-07-25,"Business Group Highlights Civilian, State and Local Perspecta's Civilian, State and Local segment partners with the U.S. Federal Civilian State and Local governments to provide infrastructure services, business solutions, and digital transformation services that help them achieve policy objectives and integrate citizen-centric services. Responsibilities Candidate will use SQL, power pivot, excel, pyramid analytics and/or other similar software to analyze data to support business decisions. Effectively collaborates with others to identify/clarify data needs, operationalize data elements, and format/display the data in order for it to become useful. Qualified candidates will be able to develop computer code to support data modeling and simulation/resampling techniques and to store, manipulate, transform or present information/data. Develop, analyze and present data model and modeling results to the customer. Qualifications Degree from an accredited college or university in Computer Science, Information Systems, a Physical Science, Engineering or a Mathematics-Intensive discipline. Bachelor's degree and 6 years of experience, or Master's and 4 years of experience, or PhD and 2 years of general IT experience (including formal training and 1 years' experience in Business Process Reengineering (BPR) methods, plus 1 year training and experience in enterprise applications). Applicable training certificate from an accredited training institution. Qualified candidates will possess substantial knowledge useful in managing large, complex AIS projects, closely related to the work to be automated. 5 years of increasingly complex and progressive experience in performing systems analysis, development, and implementation of business, mathematical, or scientific settings using a variety of information technology resources. Has experience with current technologies and, where required for the task, emerging technologies. About Perspecta What matters to our nation, is what matters to us. At Perspecta, everything we do, from conducting innovative research to cultivating strong relationships, supports one imperative: ensuring that your work succeeds. Our company was formed to bring a broad array of capabilities to all parts of the public sector-from investigative services and IT strategy to systems work and next-generation engineering. Our promise is simple: never stop solving our nation's most complex challenges. And with a workforce of approximately 14,000, more than 48 percent of which is cleared, we have been trusted to just that, as a partner of choice across the entire sector. Perspecta is an AA/EEO Employer - Minorities/Women/Veterans/Disabled and other protected categories. Options Apply for this job onlineApply Share Email this job to a friendRefer Sorry the Share function is not working properly at this moment. Please refresh the page and try again later. Share on your newsfeed As a government contractor, Perspecta abides by the following provision PAY TRANSPARENCY NONDISCRIMINATION PROVISION The contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor's legal duty to furnish information. 41 CFR 60-1.35(c)",Full Time,dice,d8bc3a88c29bcec81d8e8e9b97d69015
Data Scientist,Medical,In2M Technologies Pvt Ltd,Mumbai,Maharashtra,India,2019-07-22,"Job Description:&lt;br&gt;&lt;br&gt;Finicity s Data Innovation Lab is currently seeking a Senior Data Scientist to join our rapidly growing team. The Data Lab is focused on applied research that can be quickly brought to market as production services and new financial services products.&lt;br&gt;&lt;br&gt;This is an outstanding opportunity to be a part of a very small and talented team,  giving you the ability to help pioneer the usage of consumer financial data science techniques,  on data that is vastly more valuable and complicated.&lt;br&gt;&lt;br&gt;What you will do:&lt;br&gt;&lt;br&gt;As a Data Scientist,  you will take lead on exploring and creating business value from data science operations in new business data domains,  working with other data science and machine learning professionals,  you will formulate strategies for Exploratory Data Analysis (EDA) and follow- on data science processes and architectures,  including statistical analysis,  machine learning modeling etc. You will help ensure understanding of the business objectives and help invent new ways to analyze,  visualize,  and derive value from enterprise and financial services data.&lt;br&gt;&lt;br&gt;Key Qualifications:&lt;br&gt;&lt;br&gt;Master s Degree in Computer Science,  Mathematics,  Statistics or similar field of study required. Phd preferred.&lt;br&gt;&lt;br&gt;5+ years commercial machine learning experience.&lt;br&gt;&lt;br&gt;A strong understanding of machine learning theory.&lt;br&gt;&lt;br&gt;Mid- level programming experience. Python,  Java or C++ experience is highly desired.&lt;br&gt;&lt;br&gt;A principled approach to solving algorithmic problems with a focus on what will make users happy.&lt;br&gt;&lt;br&gt;A pragmatic approach to rapidly evaluating new algorithmic ideas.&lt;br&gt;&lt;br&gt;A very high attention to detail and ability to thoroughly think through problems.&lt;br&gt;&lt;br&gt;Excellent written and oral communication skills on both technical and non- technical topics.&lt;br&gt;&lt;br&gt;Strong understanding of R or python ML packages and statistics.&lt;br&gt;&lt;br&gt;Proven ability to mine a new data area and derive business value.",Full Time,naukri_com,4d79e8e8a7ae2b89468aac619550ec82
Big Data Engineer,IT,Zone IT Solutions,,,Australia,2019-06-05,"We are looking for Big Data Engineer on Permanent role for Melbourne. You will be a part of a Global Consulting Firm for one of their major projects.  Requirements    Passionate about driving business value and customer insight through data by leveraging industry leading big data and cloud technologies.   Open minded, curious, a problem solver and loves working in the agile scrum/team environment.   Willingness to “own” and contribute to the culture they want to work in.   Have at least a high level understanding of and ideally some exposure to the application of distributed file systems (e.g. HDFS, S3, Azure Blob), NoSQL (Cassandra, HBase,DynamoDB, Azure Table Storage, DocumentDB/CosmosDB…), relational &amp; graph databases, distributed execution frameworks (e.g. MapReduce, Apache Spark) as well as queuing and event processing to create efficient, scalable fit-for-purpose data-driven solutions.   Have exposure to a a variety of programming languages, e.g. Scala, Python, Ruby, Java, C#, C++, F#, Clojure, JavaScript, Go, Swift.   Strong skills in SQL and at least one of the above languages highly regarded.   Have an awareness of Machine Learning techniques and supporting system designs   Proficiency in test driven development and supporting automation of testing would be highly valued.   Effective communication skills with both technical and non-technical audiences.   Tertiary qualification in computer engineering, computer science or equivalent industry experience.       Benefits  About Us  Zone IT Solutions is Australia based Recruitment company. We specialize in ERP and larger IT Services. We offer flexible, efficient and collaborative solutions to any organization that requires IT, experts. Our agile, agnostic and flexible solutions will help you source the IT Expertise you need. Our delivery Offices are in Melbourne, Sydney, Singapore, and India. If you are looking for new opportunities your profile at Careers@zoneitsolutions.com or contact us at 0434189909  Also follow our LinkedIn page for new job opportunities and more.    Zone IT Solutions is an equal opportunity employer and our recruitment process focuses on essential skills and abilities. We welcome applicants from a diverse range of backgrounds, including Aboriginal and Torres Strait Islander peoples, people from culturally and linguistically diverse (CALD) backgrounds and people with disabilities.",Contract,adzuna_com_au,87575a2c72ce05d417440405fd9dd870
Data Scientist / Machine learning Expert,IT Software - Application Programming,Analytics Vidhya Educon Pvt. Ltd,Bangalore,Karnataka,India,2019-06-26,"&lt;br&gt;&lt;br&gt;Job description:&lt;br&gt;&lt;br&gt;Research and develop advanced statistical and machine learning models for analysis of large- scale,  high- dimensional data.&lt;br&gt;&lt;br&gt;Dig deeper into data,  understand characteristics of data,  evaluate alternate models and validate hypothesis through theoretical and empirical approaches.&lt;br&gt;&lt;br&gt;Productize proven or working models into production quality code.&lt;br&gt;&lt;br&gt;Collaborate with product management,  marketing and engineering teams in Business Units to elicit  understand their requirements  challenges and develop potential solutions&lt;br&gt;&lt;br&gt;Stay current with latest research and technology ideas; share knowledge by clearly articulating results and ideas to key decision makers.&lt;br&gt;&lt;br&gt;File patents for innovative solutions that add to company s IP portfolioResponsibilities&lt;br&gt;&lt;br&gt;Qualification and Skills Required&lt;br&gt;&lt;br&gt;2 to 8+ years of strong experience in data mining,  machine learning and statistical analysis.&lt;br&gt;&lt;br&gt;Experience in productizing models to code in fast paced start- up environment.&lt;br&gt;&lt;br&gt;Fluency in analytical tools such as Matlab,  R,  Weka etc.&lt;br&gt;&lt;br&gt;Fluency in programming languages like C/ C++/ Java.&lt;br&gt;&lt;br&gt;Strong intuition for data and Keen aptitude on large scale data analysis&lt;br&gt;&lt;br&gt;Strong communication and collaboration skills.",Full Time,naukri_com,da8a78e536a124cb0a73eef5a3ac2449
Staff Data Engineer,IT Software - Application Programming,Analytics Vidhya Educon Pvt. Ltd,Bangalore,Karnataka,India,2019-06-26,"&lt;br&gt;&lt;br&gt;Job description:&lt;br&gt;&lt;br&gt;Responsibilities&lt;br&gt;&lt;br&gt;Designing and developing ETL jobs across multiple platforms and tools including Vertica,  Netezza and Hadoop.&lt;br&gt;&lt;br&gt;Gathering functional requirements,  developing technical specifications,  and project  test planning.&lt;br&gt;&lt;br&gt;Work with business users to develop and refine analytical requirements for quantitative data (view- through,  click stream,  acquisition,  product usage,  and transactions),  qualitative data (survey,  market research) and unstructured data (blog,  social network).&lt;br&gt;&lt;br&gt;Designing and developing schema definitions and support data warehouse/ mart to enable integration of disparate data sources from within Intuit and outside,  aggregate it and make it available for analysis.&lt;br&gt;&lt;br&gt;Support large data volumes and accommodate flexible provisioning of new sources.&lt;br&gt;&lt;br&gt;As a key member of the team drive adoption of new technologies,  tools,  and process improvements to build world class analytical capabilities for web analytics,  optimization,  experimentation and personalization.&lt;br&gt;&lt;br&gt;Resolve defects/ bugs during QA testing,  pre- production,  production,  and post- release patches.&lt;br&gt;&lt;br&gt;Work cross- functionally with various Intuit teams: Product Management,  Project Management,  Data Architects,  Data Scientists,  Data Analysts,  Software Engineers,  and other Data Engineers.&lt;br&gt;&lt;br&gt;Contribute to the design and architecture of project across the data landscape.&lt;br&gt;&lt;br&gt;Experience with Agile Development,  SCRUM,  or Extreme Programming methodologies.&lt;br&gt;&lt;br&gt;Helps to align to overall strategies and reconcile competing priorities across organizationQualification and Skills Required&lt;br&gt;&lt;br&gt;BS/ MS in computer science or equivalent work experience.&lt;br&gt;&lt;br&gt;8 to 12 years experience in developing DB schemas,  creating ETLs,  and familiar with MPP/ Hadoop systems.&lt;br&gt;&lt;br&gt;Must have mastery of data warehousing technologies including data modeling,  ETL and reporting. Ideal candidate to have 5 years of experience in end- to- end data warehouse implementations and at least 2 projects with 4TB data volume.&lt;br&gt;&lt;br&gt;Extensive experience with databases (Vertica,  Netezza or oracle).&lt;br&gt;&lt;br&gt;Good knowledge of Operating Systems (UNIX or Linux).&lt;br&gt;&lt;br&gt;Good understanding of Data ware House methodologies.&lt;br&gt;&lt;br&gt;Hands on experience in any of the programming languages (Shell scripting,  Python,  Java,  etc).&lt;br&gt;&lt;br&gt;Must have been through several full life cycle Data Warehousing implementations and involved in scalability and performance related design aspects in Database and ETL.&lt;br&gt;&lt;br&gt;Solid communication skills: Demonstrated ability to explain complex technical issues related to technical and non- technical audiences.&lt;br&gt;&lt;br&gt;Demonstrated understanding of the Software design and architecture process.&lt;br&gt;&lt;br&gt;Experience with unit testing and data quality automation checks&lt;br&gt;&lt;br&gt;Should be results oriented,  self- motivated,  and accountable and work under minimal supervision.&lt;br&gt;&lt;br&gt;Excellent written,  oral communication and presentation Skills.&lt;br&gt;&lt;br&gt;Knowledge of Big Data eco system like Hadoop M/ R,  Pig and Hive is a strong plus.&lt;br&gt;&lt;br&gt;Experience in design,  development and deployment of one or more tools ETL (Informatica,  OWB,  ODI),  reporting (Business Objects,  QlikView,  Tableau)",Full Time,naukri_com,ba3daaf4e7f2817f4f451860e1210e2d
